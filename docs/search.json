[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Estadística a vista de pájaro",
    "section": "",
    "text": "PRESENTACIÓN\nTodo esto son pruebas.\nDe qué va este libro\nQué pretende\nCuales son sus peculiaridades\nA quien va dirigido. Lo empezamos a escribir pensando en los profesores de enseñanza secundaria, con la idea de dar una visión general de la estadística, más amplia de la que ellos deben enseñar, que les diera perspectiva y seguridad transmitiendo las ideas clave que deben quedar en los alumnos, evitando planteamientos o enfoques exclusivamente matemáticos.\nAlgunas ideas clave:\n\nDistinguir el conocimiento basado en tradiciones, suposiciones o en el “siempre se ha considerado así” del conocimiento científico basado en datos.\nRecoger datos con la calidad y la representatividad requerida no es fácil. Conviene conocer algunas ideas clave a este respecto.\nLa información que contienen los datos se puede dar con medidas estadísticas o con representaciones gráficas.\nLos datos siempre están afectados por una cierta variabilidad aleatoria. Hay técnicas para separar la señal del ruido. Tan malo es perderse la señan como sobreinterpretar el ruido.\n\nAunque el contenido de este texto es de un nivel más básico que el habitual de los cursos generales de estadística que se imparten en muchos grados universitarios, creemos que si se entienden y se interiorizan estas ideas podemos considerar que se han cumplido los objetivos que se plantean en estos cursos.\n\nTodos los datos que se usan están aquí\n\nLicencia\n\nLA PORTADA ES DE OTRO LIBRO. Solo para ver como queda."
  },
  {
    "objectID": "presentacion.html",
    "href": "presentacion.html",
    "title": "1  Presentación",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. «Literate Programming». Comput. J. 27 (2): 97-111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "Parte_Descriptiva.html",
    "href": "Parte_Descriptiva.html",
    "title": "ESTADÍSTICA DESCRIPTIVA",
    "section": "",
    "text": "Síntesis numérica de datos y representaciones gráficas.\nIdeas de:\n\nLibro Preguntas frecuentes: Media, mediana, por qué dividimos por n-1, como calcular los cuartiles.\nArtículo analogías: Síntesis numérica y retrato robot, el rio tiene una profundidad media de 1,5 m\nLibro matemáticas en primera plana: Buenos y malos usos de las representaciones gráficas."
  },
  {
    "objectID": "sintesisNumerica.html",
    "href": "sintesisNumerica.html",
    "title": "1  Síntesis numérica de datos",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n\n\n\n\n\n#    \n\n\nSample  \n\n\nIQR’s from Q\n\n\n\n\n\n\n1\n\n\n3\n\n\n3.3\n\n\n\n\n\n\n2\n\n\n2\n\n\n2.8\n\n\n\n\n\n\n3\n\n\n3\n\n\n2.7\n\n\n\n\n\n\n4\n\n\n4\n\n\n2.6\n\n\n\n\n\n\n5\n\n\n4\n\n\n2.4\n\n\n\n\n\n\n6\n\n\n3\n\n\n1.9\n\n\n\n\n\n\n7\n\n\n2\n\n\n1.7\n\n\n\n\n\n\n8\n\n\n1\n\n\n1.6\n\n\n\n\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. «Literate Programming». Comput. J. 27 (2): 97-111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "graficos.html",
    "href": "graficos.html",
    "title": "2  Representaciones gráficas",
    "section": "",
    "text": "Todavía no he hecho nada sobre esto, pero tengo mucho material y las ideas claras."
  },
  {
    "objectID": "Parte_Corre_Regre.html",
    "href": "Parte_Corre_Regre.html",
    "title": "CORRELACIÓN Y REGRESIÓN",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n\nCódigo\n1 + 1\n\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. «Literate Programming». Comput. J. 27 (2): 97-111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "correlacion.html",
    "href": "correlacion.html",
    "title": "12  Medidas de relación lineal",
    "section": "",
    "text": "APÉNDICE 9.1"
  },
  {
    "objectID": "regresion.html",
    "href": "regresion.html",
    "title": "11  Regresión",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. «Literate Programming». Comput. J. 27 (2): 97-111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Referencias",
    "section": "",
    "text": "El País, 2024. https://elpais.com/economia/negocios/2024-05-04/mi-jefe-cobra-77-veces-mas-que-yo-estas-son-las-empresas-espanolas-con-mayor-desigualdad-salarial-entre-directivos-y-empleados.html.\n\n\nDraper, N. R., and H. Smith. 1998. Applied Regression Analysis.\n3rd ed. USA: John Wiley & Sons, Inc.\n\n\nINE. 2023. “Encuesta Anual de Estructura Salarial. Año\n2021.” Instituto Nacional de EStadística (INE), España. https://www.ine.es/prensa/ees_2021.pdf.\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.\n\n\nMontgomery, D. C., and E. A. Peck. 1992. Introduction to Linear\nRegression Analysis. 2nd ed. USA: John Wiley & Sons, Inc.\n\n\nNavidi, W. 2010. Statistics for Engineers and Scientists. 3rd\ned. USA: McGraw Hill.\n\n\nPeña, D. 2002. Regresión y Diseño de Experimentos. 1st ed.\nMadrid: Alianza Editorial.\n\n\nRyan, T. A., B. L Joiner, and B. F. Ryan. 1976. The Minitab Student\nHandbook. 1st ed. USA: Duxbury Press.\n\n\nWeisberg, S. 2014. Applied Linear Regression. 4th ed. USA: John\nWiley & Sons, Inc.\n\n\nWilson, M. E., and L. E. Mather. 1974. “Lefe Expectancy.”\nJournal of the American Medical Association 229 (11): 1421–22.\n\n\nWolfram_Data_Repository. 2016. Sample Data: Black Cherry Trees. https://doi.org/10.24097/wolfram.76288.data."
  },
  {
    "objectID": "correlacion.html#necesidad-de-una-medida-de-relación",
    "href": "correlacion.html#necesidad-de-una-medida-de-relación",
    "title": "10  Correlación",
    "section": "10.1 Necesidad de una medida de relación",
    "text": "10.1 Necesidad de una medida de relación\nSee Knuth (1984) for additional discussion of literate programming."
  },
  {
    "objectID": "correlacion.html#la-covarianza",
    "href": "correlacion.html#la-covarianza",
    "title": "3  Correlación",
    "section": "3.2 La covarianza",
    "text": "3.2 La covarianza"
  },
  {
    "objectID": "correlacion.html#de-la-covarianza-al-coeficiente-de-correlación",
    "href": "correlacion.html#de-la-covarianza-al-coeficiente-de-correlación",
    "title": "3  Correlación",
    "section": "3.3 De la covarianza al coeficiente de correlación",
    "text": "3.3 De la covarianza al coeficiente de correlación"
  },
  {
    "objectID": "correlacion.html#propiedades-del-coeficiente-de-correlación",
    "href": "correlacion.html#propiedades-del-coeficiente-de-correlación",
    "title": "3  Correlación",
    "section": "3.4 Propiedades del coeficiente de correlación",
    "text": "3.4 Propiedades del coeficiente de correlación\n\n3.4.1 Acotado entre 0 y 1.\n\n\n3.4.2 Correlación no implica relación causa-efecto\n\n\n3.4.3 Correlación estadísticamente significativa\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. «Literate Programming». Comput. J. 27 (2): 97-111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "correlacion.html#covarianza",
    "href": "correlacion.html#covarianza",
    "title": "12  Medidas de relación lineal",
    "section": "12.2 Covarianza",
    "text": "12.2 Covarianza\nAparece como en las calculadoras con funciones estadísticas, en los paquetes de software y también en las hojas de cálculo, aunque en la práctica resulta poco útil como medida de relación lineal. Aquí la incluimos porque su expresión es fácil de justificar y ayuda a entender la fórmula del coeficiente de correlación.\n\nDeducción de la fórmula\nLa figura 12.3 muestra la relación entre dos variables \\(X\\) e \\(Y\\). En la derecha el diagrama se ha dividido en cuatro cuadrantes trazando una línea vertical que pasa por la media de los valores de \\(X\\) y una horizontal por la media de los valores de \\(Y\\). A estos valores medios los designamos \\(\\bar{x}\\) e \\(\\bar{y}\\) respectivamente. Los cuadrantes van del I al IV en el sentido de las agujas del reloj.\n\n\n\nFigura 12.3: Deducción de la fórmula de la covarianza\n\n\nEn todos los puntos del primer cuadrante la distancia \\(x - \\bar{x}\\) es positiva, ya que todos se encuentran a la derecha de \\(\\bar{x}\\). También será positiva la distancia \\(y - \\bar{y}\\) ya que todos están por encima de \\(\\bar{y}\\). Por tanto, el producto de ambas distancias \\((x - \\bar{x})(y - \\bar{y})\\) será positivo para todos los puntos que se hayan en el primer cuadrante.\nPara los del segundo cuadrante este producto es negativo ya que la distancia \\(x - \\bar{x}\\) sigue siendo positiva (todos los puntos se encuentran a la derecha de \\(\\bar{x}\\)), pero \\(y - \\bar{y}\\) será negativo (todos están por debajo de \\(\\bar{y}\\)).\nEn el tercer cuadrante el producto de las distancias es positivo porque ambas distancias son negativas y en el cuarto vuelve a ser negativo ya que \\(y - \\bar{y}\\) es positivo pero \\(x - \\bar{x}\\) es negativo.\nCon \\(n\\) puntos, la suma de todos estos productos será \\(\\sum_{i=1}^{n} (x_i -\\bar {x})(y_i -\\bar {y})\\). Si la mayoría se encuentra en los cuadrantes I y III, tal como ocurre en la figura 12.3, el resultado del sumatorio será un valor positivo, mientras que si están en los cuadrantes II y IV el resultado será negativo. Si no existe ninguna relación entre \\(X\\) e \\(Y\\) los puntos se repartiran de forma más menos equilibrada, tendiendo a compensarse los productos positivos con los negativos y dando un resultado alrededor de cero.\nLa covarianza es el valor de ese sumatorio dividido por el número de puntos que intervienen en su cálculo, algo así como el promedio de los productos \\((x_i -\\bar {x})(y_i -\\bar {y})\\). Si nuestro interés no es conocer la covarianza de los datos disponibles, sino estimar su valor en la población, dividimos por \\(n-1\\) en vez de por \\(n\\), por la misma razón que lo hacemos cuando estimamos el valor de la varianza. Como lo habitual es esto último, escribimos la fórmula de la forma:\n\\[ \\widehat{\\text{Cov}}(X,Y) = \\frac{\\sum_{i=1}^{n} (x_i -\\bar {x})(y_i -\\bar {y})}{n-1} \\]\n\n\nPropiedades\nLa covarianza tiene un gran protagonismo en el terreno de los modelos teóricos, pero apenas se usa para valorar la relación lineal en un conjunto de datos. Para este menester tiene el inconveniente de que su valor depende de las unidades utilizadas.\nSi se calcula la covarianza entre la estatura de madres e hijas con los datos representados en la figura 12.1 cuyas unidadess son pulgadas (in) se obtiene un valor de 3,005 in2. Sin embargo, si cambiamos las unidades a cm (1 pulgada = 2,54 cm) el gráfico tiene el mismo aspecto y el grado de relación sigue siendo exactamente el mismo, pero ahora el valor obtenido es 19,39 cm2, y si las estaturas se expresan en metros tenemos que la covarianza es igual a 0,0019 m2.\nPor otra parte, para su valoración no tenemos ningún marco de referencia que nos permita evaluar si el valor obtenido es grande o pequeño. Todos estos problemas quedan resueltos con el uso del coeficiente de correlación.\n\n\n\n\n\n\nMalas noticias para la covarianza\n\n\n\nDados unos valores de \\(X\\), la máxima covarianza no se obtiene cuando los valores de \\(Y\\) se alinean según una recta. Por ejemplo, sean los valores de \\(X\\) = 1, 2, 3, 4 y 5, si los de \\(Y\\) son: 2, 4, 6, 8, y 10 (relación lineal perfecta) la covarianza entre \\(X\\) e \\(Y\\) es igual a 5 pero si sustuimos el último 10 por 15, la covarianza aumenta y pasa a valer 7,5. Esto no deja en muy buen lugar a la covarianza como medida de relación lineal."
  },
  {
    "objectID": "correlacion.html#coeficiente-de-correlación",
    "href": "correlacion.html#coeficiente-de-correlación",
    "title": "12  Medidas de relación lineal",
    "section": "12.3 Coeficiente de correlación",
    "text": "12.3 Coeficiente de correlación\nPara calcular el coeficiente de correlación, \\(r\\), entre dos variables \\(X\\) e \\(Y\\) basta con calcular su covarianza y dividirla por el producto de las desviaciones típicas de \\(X\\) e \\(Y\\), es decir:\n\\[ r  = \\frac{\\frac{\\sum_{i=1}^{n} (x_i -\\bar {x})(y_i -\\bar {y})}{n-1}}\n        {\\sqrt \\frac {{\\sum_{i=1}^n \\left ( x_i - \\bar{x} \\right )^2}}{n-1} \\sqrt{ \\frac {\\sum_{i=1}^n \\left ( y_i - \\bar{y} \\right )^2 }{n-1}}} \\]\nEs fácil comprobar que desaparecen los denominadores tanto de la covarianza como de las desviaciones típicas, quedando:\n\\[ r  = \\frac{\\sum_{i=1}^n \\left ( x_i - \\bar{x} \\right ) \\left ( y_i - \\bar{y} \\right ) }\n        {\\sqrt {\\sum_{i=1}^n \\left ( x_i - \\bar{x} \\right )^2}  \\sqrt{\\sum_{i=1}^n \\left ( y_i - \\bar{y} \\right )^2 }} \\]\nCon esta sencilla transformación se resuelven los problemas de la covarianza:\n\nEs un valor adimensional y, por tanto, no depende de las unidades utilizadas.\nSu valor está acotado entre -1 y 1 (correlación perfecta negativa y positiva repectivamente).\n\nQue es adimensional es evidente, puesto que el numerador tiene las mismas unidades que el denominador. Que es igual a 1 o -1 cuando la relación lineal es perfecta lo demostramos en un apéndice de este capítulo usando álgebra elemental. Que está acotado entre -1 y 1 no es trivial, pero lo demostramos en un apéndice del siguiente capítulo usando el concepto de coeficiente de determinación de la recta ajustada (también se puede demostrar como consecuencia directa de la desigualdad de Cauchy-Schwarz, pero eso no son matemáticas elementales) .\n\n\n\n\n\n\nCoeficiente de correlación “de Pearson”\n\n\n\nA la denominación del coeficiente de correlación a veces se le añade “de Pearson” porque fue este estadístico el que lo desarrolló. Aunque existen otros coeficientes de correlación de mucho menor uso, no es necesario el añadido. Si no se dice de que tipo es siempre entendemos que se refiere al de Pearson.\n\n\n\nCoeficiente de correlación y diagrama bivariante\nEl valor del coeficiente de correlación no sustituye la información que proporciona el diagrama bivariante. Un mismo coeficiente de correlación puede corresponder a situaciones muy distitnas y si solo nos dan el valor de \\(r\\) es imposible saber a cual de ellas corresponde.\nUna demostración de la importancia de no descuidar el análisis gráfico de los datos lo constituye el llamado “cuarteto de Anscombe”, formado por cuatro conjuntos de datos que presentan el mismo coeficiente de correlación y la misma recta ajustada pero que al analizarlos gráficamente muestran situaciones claramente distintas (figura 12.4).\n\n\n\nFigura 12.4: Cuarteto de Anscombe. Cuatro situaciones muy distintas pero todas ellas con el mismo coeficiente de correlación (\\(r = 0,816\\)) y la misma recta ajustada (\\(y = 3+0,5x\\))\n\n\n\n\nCorrelación estadísticamente significativa\nEl diagrama bivariante de la figura 12.5 está construido con los datos de 29 plantas y muestra la relación entre el peso de los frutos obtenidos y el tiempo transcurrido entre la plantación y la recolección. Se ha añadido la recta de regresión ajustada a estos puntos.\n\n\n\nFigura 12.5: Relación entre el peso de los frutos recogidos en 22 plantas y el tiempo transcurrido desde su plantación hasta la recolección\n\n\nParece dar la sensación de que cuanto más se tarda en recoger los frutos mayor peso se obtiene. El coeficiente de correlación es positivo y está bastante alejado de cero, \\(r=0,323\\). ¿Quiere esto decir que para maximizar el peso de la cosecha vale la pena esperar a los 150 días?\nSi dos variables son totalmente independientes, como dos conjuntos de números aleatorios, no por ello hay que esperar que su coeficiente de correlación sea igual a cero. Para que esto ocurra también la covarianza debe ser igual a cero y para ello se debe dar un equilibrio perfecto en los puntos de cada cuadrante para que se compensen perfectamente los productos de las distancias, lo cual es muy difícil que se dé en la práctica.\nPor tanto, cuando tenemos dos conjuntos de datos que provienen de poblaciones independientes, no hay que esperar que su coeficiente de correlación sea exactamente igual a cero. Estará en torno a cero.\n¿Qué significa “en torno a”? La distancia que exigimes respecto a cero para tomarnos en serio la correlación depende del número de datos de que se disponga. Si solo tenemos dos datos (dos puntos sobre el diagrama) el coeficiente de correlación valdrá -1 o 1 con independencia de la relación que haya entre esas variables, por tanto, ese resultado no tiene ningún valor. Si se tienen pocos datos se exige más distancia que si se tienen muchos porque es más fácil que -por casualidad- se obtengan valores extremos.\nEn nuestro caso de 22 datos ¿cuál es la distancia exigida? Vamos a generar 22 números aleatorios de una distribución Normal con media \\(\\mu = 137\\) y \\(\\sigma = 6.5\\) que podemos considerar que son los parámetros de la población de la que provienen los valores de los pesos, y otros 22 números aleatorios, totalmente independientes de los anteirores, en este caso también de una distribución Normal, pero con parámetros \\(\\mu = 6\\) y \\(\\sigma = 0.5\\) para simular los valores del tiempo hasta la recogida. Cuando se calcula el coefiente de correlación con ese conjunto de datos simulados se obtiene un valor que corresponde a muestras de poblaciones independientes. Este proceso se puede repetir muchas veces y cada vez se obtiene un valor del coeficiente de correlación que corresponde a una situación de variables independientes.\nHemos repetido este proceso 100.000 veces, de manera que hemos obtenido 100.000 valores del coefiente de correlación entre dos conjuntos de datos de origen similar a los nuestros y que son absolutamente independientes. Los resultamos obtenidos se resumen en el histograma de la figura 12.6 ===Esto hay que explicarlo mejor===\n\n\n\nFigura 12.6: Valores del coeficiente de correlación obtenidas por simulación\n\n\nA la vista de este histograma, podemos afirmar que si nos hubiera salido un coeficiente de correlación de, por ejemplo 0,8, podríamos afirmar con un riesgo de equivocarnos muy pequeño que nuestras variables estan correlacionadas porque si fueran independientes un valor como ese o mayor prácticamente no se da nunca. Sin embargo, si nuesto valor fuera \\(r=0,2\\) no podríamos decir que existe correlación porque valores como ese, e incluso mayores, son muy habituales entre variables independientes cuando se calcula con muestras de \\(n=22\\) observaciones. ===todo esto hay que redactarlo mejor===\nEn nuestro caso tenemos \\(r=0,323\\) se trata de una distancia de cero “normal” si no hay relación entre ambas variables…\nHablar de las tablas, de sus características básicas y de que trataremos de como se han construido en el siguiente capítulo.\n===Esto hay que explicarlo mejor===\n\n\nCorrelación no implica relación causa-efecto\n===empezar comentando el gráfico===\nQue dos variable presenten un coeficiente de correlación estadísticamente significativo (esten correlacionadas) no significa que el cambio en una provoque -sea la causa- del cambio en la otra.\nPuede ocurrir que haya una tercera variable no considerada relacionada con las dos que se observan, por ejemplo, se dice que hay una alta correlación entre el número de bomberos que acuden a apagar un incendio y los daños que ese incendio causa, pero, naturalmente, a nadie se le ocurre enviar menos bomberos para que haya menor daños porque estas dos variables, aunque están correlacionadas y en el diagrama bivariante se observe una nube de puntos que marca una clara tendencia de que al aumentar el número de bomberos aumentan los daños, en este caso la variable oculta relacionada con las dos que observamos es la magnitud del incencdio, relacionada con los daños y con el número de bomberos. Existen numerosos ejemplos chistosos de este tipo de situaciones…\n\n\n\nFigura 12.7: Cuatro situaciones que muestran diferentes grados de relación\n\n\nTambién puede ocurrir que la relación sea debida al azar. Si exploramos muchos pares de variables, seguro que algunas apareceran con una relación estrecha, aunque en realidad no tengan nada que ver. La página web https://www.tylervigen.com/spurious-correlations contiene muchos ejemplos de este tipo.\n\n\nCuriosidad sobre el coeficiente de correlación\nSi solo tenemos n = 2 puntos sobre el diagrama bivariante, el coeficiente de correlación solo puede tomar los valores -1 y 1, ambos con la misma probabilidad . Si tenemos n = 3 aparece una distribución muy rara tanto para explicar la variabidad ligada a fenómenos naturales como en los modelos teóricos que usamos habitualmente: los valores más frecuentes están en los extremos (-1 y 1) mientras que en torno al centro (alrededor de cero) se dan los de menor probabilidad.Para n = 4 todos los valores del coeficiente de correlación son igualmente probables , para n = 5 la distribución de probabilidad tiene forma de semielipse, y a media que aumenta el valor de n va apareciendo la típica forma de campana. (figura).\n\n\n\nFigura 12.8: Distribución del coeficiente de correlación según el tamaño, \\(n\\), de la muestra considerada\n\n\nLas distribuciones de la figura +++ se puede reproducir por simulación o directamente usando la función densidad de probabilidad de coefiente de correlación, aunque su expresión es un poco aparatosa:\n\\[ f(r \\mid \\rho =0) = \\frac{ \\Gamma \\left [\\frac{1}{2} (n-1) \\right ]} { \\Gamma \\left [\\frac{1}{2} (n-2) \\right ] \\sqrt{\\pi}\n} (1-r^2)^{\\frac{1}{2}(n-4)} \\]\nAclarar la notación Esta función no converge a la distribución Normal cuando n se hace grande, ya que está definida solo entre -1 y 1 mientras que el dominio de la distribución Normal no está acotado."
  },
  {
    "objectID": "variablesAleatorias.html",
    "href": "variablesAleatorias.html",
    "title": "3  Variables aleatorias",
    "section": "",
    "text": "Importancia, tipos, propiedades."
  },
  {
    "objectID": "distribucionesProbabilidad.html",
    "href": "distribucionesProbabilidad.html",
    "title": "4  Distribuciones de probabilidad",
    "section": "",
    "text": "Binomial, Poisson, Normal, otras (uniforme, equiprobable, curiosidades: unif+unif = triangular)"
  },
  {
    "objectID": "Proporciones.html",
    "href": "Proporciones.html",
    "title": "5  Estadística descriptiva",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n\nCódigo\n1 + 1\n\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. «Literate Programming». Comput. J. 27 (2): 97-111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "tamañoPoblacion.html",
    "href": "tamañoPoblacion.html",
    "title": "6  Estadística descriptiva",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n\nCódigo\n1 + 1\n\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. «Literate Programming». Comput. J. 27 (2): 97-111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "Parte_Variabilidad.html",
    "href": "Parte_Variabilidad.html",
    "title": "SOBRE LA VARIABILIDAD",
    "section": "",
    "text": "Importancia de saberse mover en un contexto de variabilidad. No todas las variabilidades son iguales.\nEstoy pensando en empezar planteando el tema de la fecha de nacimiento de los futbolistas profesionales y a partir de ahí introducir la distribución binomial y su utilidad para separar señal y ruido.\nSiguiendo con el mundo de futbol, podría introducir la distribución de Poisson con el ejemplo del número de goles por partido.\nLa distribución Normal se puede introducir como límite de histograma. También partiendo de la distribución Normal.\nNo creo que -al menos aquí- haya que hablar de distribuciones de referencia teóricas: t-Student, Chi-cuadrado, F de Snededor."
  },
  {
    "objectID": "Parte_Estimacion.html",
    "href": "Parte_Estimacion.html",
    "title": "ESTIMACIÓN",
    "section": "",
    "text": "Lo típico. Como estimar las características de una población a partir de los datos de una muestra.\nPropiedades que deseamos tener en los estimadores\nEstimación de proporciones. Intervalo de confianza, margen de error, etc.\nEstimación de medias\nEstimación del tamaño de una población (peces y taxis)\nAnexo: Sondeos electorales."
  },
  {
    "objectID": "Parte_Experimentos.html",
    "href": "Parte_Experimentos.html",
    "title": "DISEÑO DE EXPERIMENTOS",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n\nCódigo\n1 + 1\n\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. «Literate Programming». Comput. J. 27 (2): 97-111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "floresAspirina.html",
    "href": "floresAspirina.html",
    "title": "10  Estadística descriptiva",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n\nCódigo\n1 + 1\n\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. «Literate Programming». Comput. J. 27 (2): 97-111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "duracionPilas.html",
    "href": "duracionPilas.html",
    "title": "11  Regresión",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n\nCódigo\n1 + 1\n\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. «Literate Programming». Comput. J. 27 (2): 97-111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "sintesisNumerica.html#medidas-de-tendencia-central",
    "href": "sintesisNumerica.html#medidas-de-tendencia-central",
    "title": "1  Síntesis numérica de datos",
    "section": "1.1 Medidas de tendencia central",
    "text": "1.1 Medidas de tendencia central\n\nMedia aritmética\nTanto el cálculo como el significado de la media aritmética son bien conocidos por los estudiantes. Seguramente ayuda su utilidad para saber si se aprobará una asignatura a la vista de los resultados obtenidos durante el curso.\nCuando los datos se presentan tabulados hay que tener presente que estos se repiten tantas veces como indica su frecuencia absoluta. Por ejemplo, en la Tabla 1.1, el número de hijos (X) es la variable considerada y el número de familias (n) que tienen ese número de hijos es su frecuencia absoluta.\n\n\nTabla 1.1: Número de hijos por familia\n\n\nNúm de hijos (X):\n0\n1\n2\n3\n4\n5\n\n\nNúm de familias (n):\n13\n21\n15\n8\n1\n2\n\n\n\n\nEl valor medio (\\(\\bar{X}\\)) del número de hijos por famila es igual a:\n\\[\n\\bar{X} = \\frac{\\sum_{i} n_i X_i }{N} \\:  = \\:  1,48\n\\] Donde \\(N\\) es el número total de datos disponibles (\\(N=60\\)) e \\(i\\) es el índice que en nuestro caso va de 1 a 6 (para valores de \\(X\\) de 0 a 5).\nPara cada valor de X (X_i), su frecuencia relativa es igual a \\(n_i/N\\). También podemos calcular la media usando la expresión:\n\\[\n\\sum_{i} f_i X_i \\:  = \\:  1,48\n\\] Esta expresión es análoga a la de la esperanza matemática para una variable aleatoria (cambiando frecuencia relativa por probabilidad) que veremos más adelante.\n=====\nNotación: Media, promedio, esperanza matemática pros y contras\n=====\n\n\nMediana\nEn una empresa con 500 trabajadores y la siguiente distribución de salario mensual:\n\n\nTabla 1.2: Distribución de salarios\n\n\n\n\n\n\n\n\n\n\n\n\nSalario mensual (€):\n1134\n1200\n2500\n3500\n5000\n7000\n10000\n\n\nNúm de trabajadores\n240\n97\n60\n50\n43\n8\n2\n\n\n\n\ntexto\n\n\nModa\ntexto"
  },
  {
    "objectID": "sintesisNumerica.html#medidas-de-dispersión",
    "href": "sintesisNumerica.html#medidas-de-dispersión",
    "title": "1  Síntesis numérica de datos",
    "section": "1.2 Medidas de dispersión",
    "text": "1.2 Medidas de dispersión\ntexto sobre la importancia de la dispersión y de medirla para valorarla\n\nRango\ntexto\n\n\nVarianza\ntexto\n\n\nDesviación típica\ntexto\ntexto\ntexto\ntexto\ntexto\ntexto\ntexto\ntexto"
  },
  {
    "objectID": "sintesisNumerica.html#medidas-de-posición",
    "href": "sintesisNumerica.html#medidas-de-posición",
    "title": "1  Síntesis numérica de datos",
    "section": "1.3 Medidas de posición",
    "text": "1.3 Medidas de posición\ntexto\ntexto\n\nCuartilas\ntexto\ntexto\n\n\nDeciles. Percentiles\ntexto\ntexto"
  },
  {
    "objectID": "sintesisNumerica.html#porcentajes",
    "href": "sintesisNumerica.html#porcentajes",
    "title": "1  Síntesis numérica de datos",
    "section": "1.4 Porcentajes",
    "text": "1.4 Porcentajes\ntexto\ntexto\ntexto\ntexto\ntexto\ntexto\ntexto\ntexto\ntexto\ntexto\ntexto\ntexto\ntexto\ntexto\ntexto\ntexto\ntexto\n¿Qué hace esto aquí?"
  },
  {
    "objectID": "conceptosGenerales.html",
    "href": "conceptosGenerales.html",
    "title": "1  Conceptos generales",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n\nCódigo\n1 + 1\n\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. «Literate Programming». Comput. J. 27 (2): 97-111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "regresion.html#cálculo-de-los-coeficientes",
    "href": "regresion.html#cálculo-de-los-coeficientes",
    "title": "11  Regresión",
    "section": "11.2 Cálculo de los coeficientes",
    "text": "11.2 Cálculo de los coeficientes\nSe realiza con el objetivo de minimizar la suma de los cuadrados de los residuos. Pero existen otros métodos. Veamos algunos.\n\nA ojo\nSe traza la recta directamente sobre el papel o se identifican dos puntos de paso y a partir de ellos se calculan los coeficientes del modelo.\n\n\n\n\n\n\n\nPROS \n\nIntuitivo. Muy fácil de entender\nNo se comenten errores de mucho bulto\n\n\n\nCONS \n\nNo se logra el ajuste “perfecto” de acuerdo con el criterio establecido\nNo se tienen medidas de calidad del ajuste ni de significación de los coeficientes\nSolo sirve para regresión simple\n\n\n\n\nA pesar de sus evidentes limitaciones, si solo se trata de tener la recta no es un método tan malo como parece. Con un poco de práctica el ajuste no será muy distinto del “perfecto” y no se cometeran errores de mucho bulto debido a la presencia de valroes anómalos, cosa que sí puede ocurrir si se tratan los datos de forma automática sin mnirarlos.\n\n\nMétodo de Ishikawa\n\n\n\n\n\n\n\nPROS \n\nFácil de entender\nRobusto frente a la presencia de valores anómalos o con excesiva influencia\n\n\n\nCONS \n\nNo se tienen medidas de calidad del ajuste\nSolo sirve para regresión simple\n\n\n\n\n\n\nMinimizando la suma de los residuos\nEntendemos que se trata de minimizar la suma en valor absoluto, ya que un valor muy grande con signo negativo se logra simplemente aumentando los valores de \\(b_0\\) y de \\(b_1\\). Por tanto, se trata de minimizar \\(\\sum [\\, Y_i - (b_0 - b_1 X_i)]\\,\\). haciendo esta expresión igual a cero (mínimo valor posible), tenemos:\n\\[ n\\bar{Y} - nb_0 - b_1 n \\bar{X} = 0\\] Por tanto, con cualquier par de valores \\(b_0\\) y \\(b_1\\) que verifiquen la expresión \\(\\bar{Y} = b_0 + b_1 \\bar{X}\\) tendremos una suma de residuos en valor absoluto igual a cero.\nQue haya infinitas rectas que cumplan esa condición ya es mala señal, porque seguro que no todas son la más adecuada. Para los valores representados en la figura X tenemos que \\(\\bar{X}= 3\\frac{1}{3}\\) y \\(\\bar{Y}= 8\\frac{2}{3}\\). Rectas que cumplen la condicion de minimizar la suma de los residuos son, por ejemplo, la que tiene coeficientes \\(b_0=8\\frac{2}{3}\\) y \\(b_1=0\\), es decir: \\(Y = 8\\frac{2}{3}\\), o también \\(b_0 = 12\\) y \\(b_1 = -1\\)\nAQUÍ GRÁFICO\n\n\nMinimizando la suma de los residuos en valor absoluto\n\n\n\nMinizando la suma de los cuadrados de los residuos\n\n\nCon fuerza bruta\nCuriosidad con el redondeo\nSee Knuth (1984) for additional discussion of literate programming.\n\n\n\n\nKnuth, Donald E. 1984. «Literate Programming». Comput. J. 27 (2): 97-111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "regresion.html#definiciones",
    "href": "regresion.html#definiciones",
    "title": "11  Regresión",
    "section": "11.1 Definiciones",
    "text": "11.1 Definiciones\nResiduos\nNormalidad de la respuesta\nEstimación de los parámetros\nModelo, no ecuación"
  },
  {
    "objectID": "regresion.html#determinación-de-la-recta-ajustada",
    "href": "regresion.html#determinación-de-la-recta-ajustada",
    "title": "11  Regresión",
    "section": "11.2 Determinación de la recta ajustada",
    "text": "11.2 Determinación de la recta ajustada\nSe realiza con el objetivo de minimizar la suma de los cuadrados de los residuos. Pero existen otros métodos. Veamos algunos.\n\nA ojo\nSe traza la recta directamente sobre el papel o se identifican dos puntos de paso y a partir de ellos se calculan los coeficientes del modelo.\nA pesar de sus evidentes limitaciones, si solo se trata de tener la recta no es un método tan malo como parece. Con un poco de práctica el ajuste no será muy distinto del “perfecto” y no se cometeran errores de bulto debido a la presencia de valores anómalos, cosa que sí puede ocurrir si se tratan los datos de forma automática sin mnirarlos.\n\n\n\nFigura 11.1: Ajuste a ojo y el que minimiza la suma de los cuadrados de los residuos.\n\n\n\n\n\n\n\n\n\nPROS \n\nIntuitivo. Muy fácil de entender\nNo se comenten errores de mucho bulto\n\n\n\nCONS \n\nNo se logra el ajuste “perfecto” de acuerdo con el criterio establecido\nNo se tienen medidas de calidad del ajuste ni de significación de los coeficientes\nSolo sirve para regresión simple\n\n\n\n\n\n\nMétodo de Ishikawa\nAquí texto,\n\n\n\nFigura 11.2: Ajuste a ojo y el que minimiza la suma de los cuadrados de los residuos.\n\n\n\n\nTabla 11.1: Método de Ishikawa. Ventajas e inconvenientes\n\n\n\n\n\n\nPROS \n\nFácil de entender\nRobusto frente a la presencia de valores anómalos o con excesiva influencia\n\n\n\nCONS \n\nNo se tienen medidas de calidad del ajuste\nSolo sirve para regresión simple\n\n\n\n\n\n\n\nMinimizando la suma de los residuos\nEntendemos que se trata de minimizar la suma en valor absoluto, ya que un valor muy grande con signo negativo se logra simplemente aumentando los valores de \\(b_0\\) y/o de \\(b_1\\). Por tanto, se trata de minimizar \\(|\\sum(Y_i - (b_0 - b_1 X_i))|\\). Haciendo esta expresión igual a cero (mínimo valor posible), tenemos:\n\\[ n\\bar{Y} - nb_0 - b_1 n \\bar{X} = 0\\] Por tanto, con cualquier par de valores \\(b_0\\) y \\(b_1\\) que verifiquen la expresión \\(\\bar{Y} = b_0 + b_1 \\bar{X}\\), es decir, con cualquier recta que pase por (\\(X_0\\), \\(Y_0\\)) tendremos una suma de residuos en valor absoluto igual a cero.\nQue haya infinitas rectas que cumplan esa condición ya es mala señal, porque seguro que no todas son adecuadas. Para los valores representados en la figura X tenemos que \\(\\bar{X}= 6\\) y \\(\\bar{Y}= 9\\). Rectas que cumplen la condicion de minimizar la suma de los residuos son, por ejemplo, la que tiene coeficientes \\(b_0=9\\) y \\(b_1=0\\), es decir: \\(Y = 9\\), o también \\(b_0 = 12\\) y \\(b_1 = -0.5\\), es decir: \\(Y = 12 -0.5X\\).\n\n\n\nFigura 11.3: Dos ajustes -claramente muy malos- con suma de residuos igual a cero.\n\n\n\n\nTabla 11.2: Minimizar la suma de los residups. Ventajas e inconvenientes\n\n\n\n\n\n\nPROS \n\nNinguna\n\n\n\nCONS \n\nDa un número infinito de soluciones (una de ellas coincide con el ajuste por mínimos cuadrados)\n\n\n\n\n\n\n\nMinimizando la suma de los residuos en valor absoluto\nDe entrada parece bastante más razonable que el anterior. Puede no tener solución única, pero los resultados que da no son disparados como en el caso anterior *referencia a figura*. Tiene solución única pero no existen expresiones para los coeficientes debido a las dificultades en el manejo de la función “valor absoluto”.\n\n\n\nDos ajustes -claramente muy malos- con suma de residuos igual a cero.\n\n\nMas información: Wikipedia\n\n\nMinizando la suma de los cuadrados de los residuos\naquí texto\n\n\n\nDos ajustes -claramente muy malos- con suma de residuos igual a cero."
  },
  {
    "objectID": "regresion.html#mínimos-cuadrados.-cálculo-de-los-coeficientes",
    "href": "regresion.html#mínimos-cuadrados.-cálculo-de-los-coeficientes",
    "title": "11  Regresión",
    "section": "11.3 Mínimos cuadrados. Cálculo de los coeficientes",
    "text": "11.3 Mínimos cuadrados. Cálculo de los coeficientes\nAquí texto\n\nCon fuerza bruta\n\n\nUsando las expresiones de \\(b_0\\) y \\(b_1\\) que minimizan la suma de los cuadrados de los residuos\nCuriosidad con el redondeo\nSee Knuth (1984) for additional discussion of literate programming.\n\n\n\n\nKnuth, Donald E. 1984. «Literate Programming». Comput. J. 27 (2): 97-111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "regresionSimple.html#definiciones",
    "href": "regresionSimple.html#definiciones",
    "title": "10  Regresión Simple",
    "section": "10.1 Definiciones",
    "text": "10.1 Definiciones\nResiduos\nIntercepto\nModelo, no ecuación\nRegresión simple vs. múltiple"
  },
  {
    "objectID": "regresionSimple.html#determinación-de-la-recta-ajustada",
    "href": "regresionSimple.html#determinación-de-la-recta-ajustada",
    "title": "10  Regresión Simple",
    "section": "10.1 Determinación de la recta ajustada",
    "text": "10.1 Determinación de la recta ajustada\nSi entre la respuesta y la variable regresora se observa una relación lineal se determina la ecuación de la recta que mejor se adapta a los puntos disponibles. Lo que significa “mejor” es discutible. Veamos algunas formas de hacerlo.\n\nA ojo\nSe traza la recta directamente sobre el papel o se identifican dos puntos de paso y a partir de ellos se calculan los coeficientes del modelo.\nA pesar de sus evidentes limitaciones, si solo se trata de tener la recta no es un método tan malo como parece. Con un poco de práctica el ajuste no será muy distinto del “perfecto” y no se cometeran errores de bulto debido a la presencia de valores anómalos, cosa que sí puede ocurrir si se tratan los datos de forma automática sin mnirarlos.\n\n\n\nFigura 10.2: Ajuste a ojo y el que minimiza la suma de los cuadrados de los residuos.\n\n\n\n\n\n\n\n\n\nPROS \n\nIntuitivo. Muy fácil de entender.\nNo se comenten errores de mucho bulto.\n\n\n\nCONS \n\nNo se logra el ajuste “perfecto” de acuerdo con el criterio establecido. |\nNo se tienen medidas de calidad del ajuste. |\nSolo sirve para regresión simple.\n\n\n\n\n\n\nMétodo de Ishikawa\nSe identifica el primer y el tercer cuartil de los valores de \\(X\\) \\((X_{Q1}\\) y \\(X_{Q3})\\), e igual para los valores de \\(Y\\) \\((Y_{Q1}\\) y \\(Y_{Q3})\\). Se traza la recta por los puntos \\((X_{Q1}\\) y \\(Y_{Q1})\\) y \\((X_{Q3}\\) y \\(Y_{Q3})\\). Se obtiene una recta muy razonable sin necesidad de realizar cálculos ni de aplicar fórmulas de las que se desconoce su lógica.\n\n\n\nFigura 10.3: Ajuste por el método de Ishikawa y el que minimiza la suma de los cuadrados de los residuos.\n\n\n\n\nTabla 10.1: Método de Ishikawa. Ventajas e inconvenientes\n\n\n\n\n\n\nPROS \n\nFácil de entender\nRobusto frente a la presencia de valores anómalos o con excesiva influencia\n\n\n\nCONS \n\nNo se tienen medidas de calidad del ajuste\nSolo sirve para regresión simple\n\n\n\n\n\n\n\n\n\n\n\nKaoru Ishikawa (1915-1989)\n\n\n\nFue un ingeniero japonés, considerado uno de los artífices del llamado “milagro japonés” que condujo los productos japoneses desde la mediocridad hasta arrasar en los mercados mundiales (electrónica, fotografía, automoción,…). Una de las claves del éxito fue el uso intensivo de técnicas estadísticas para el control y la mejora de la calidad. Ishikawa es conocido por proponer el uso de herramientas sencillas, que todos puedan entender y aplicar de forma habitual.\n\n\n\n\nHaciendo que la suma de los residuos sea igual a cero\nSe trata de obtener los valores de \\(b_0\\) y \\(b_1\\) que cumplen la expresión:\n\\[\\sum_{i=1}^n \\left[ Y_i - (b_0 - b_1 X_i) \\right]= 0\\] qye es equivalente a:\n\\[ n\\bar{Y} - nb_0 - b_1 n \\bar{X} = 0\\] Por tanto, con cualquier par de valores \\(b_0\\) y \\(b_1\\) que verifiquen la expresión \\(\\bar{Y} = b_0 + b_1 \\bar{X}\\), es decir, con cualquier recta que pase por (\\(\\bar{X}\\), \\(\\bar{Y}\\)) tendremos una suma de residuos igual a cero.\nQue haya infinitas rectas que cumplan esa condición es una mala señal, porque seguro que no todas son adecuadas. Para los valores representados en la figura 10.4 tenemos que \\(\\bar{X}= 6\\) y \\(\\bar{Y}= 9\\). Rectas que hacen que la suma de los residuos sea igual a cero son, por ejemplo, la que tiene coeficientes \\(b_0=9\\) y \\(b_1=0\\), es decir: \\(Y = 9\\), o también \\(b_0 = 12\\) y \\(b_1 = -0.5\\), es decir: \\(Y = 12 -0.5X\\) y ambos son claramente muy malos ajustes.\n\n\n\nFigura 10.4: Dos ajustes -claramente muy malos- con suma de residuos igual a cero.\n\n\n\n\nTabla 10.2: Suma de los residuos igual a cero. Ventajas e inconvenientes\n\n\n\n\n\n\nPROS \n\nNinguna\n\n\n\nCONS \n\nDa un número infinito de soluciones (una de ellas coincide con el ajuste por mínimos cuadrados)\n\n\n\n\n\n\n\nMinimizando la suma del valor absoluto de los residuos\nSe trata de minimizar:\n\\[S=\\sum_{i=1}^n \\left| Y_i - (b_0 - b_1 X_i) \\right|= 0\\]\nPuede no tener solución única, pero los resultados posibles son mucho más razonables que en el caso anterior. Un problema específico de este caso es que no existen expresiones analíticas para los coeficientes debido a las dificultades en el manejo de la función “valor absoluto”.\nLa figura 10.5 muestra dos diagramas con los mismos 4 puntos y ñas rectas que cumplen el criterio estableciso, en todas ellas la suma del valor absoluto de los residuos es igual a 2. La línea azul, que es la misma en los dos diagramas, es la que también minimiza la suma de los cuadrados de los residuos.\n\n\n\nFigura 10.5: Posibles opciones para minimizar la suma de los residuos en valor absoluto.\n\n\n\n\nTabla 10.3: Suma de los residuos igual a cero. Ventajas e inconvenientes\n\n\n\n\n\n\nPROS \n\nPoco sensible a la presencia de valores anómalos\n\n\n\nCONS \n\nNo da un ajuste equilibrado entre todos los puntos\nNo existe expresión analítica para el cálculo de los coeficientes\n\n\n\n\n\n\n\n\nMinimizando la suma de los cuadrados de los residuos\nElevamos los residuos al cuadrado en vez de usar su valor absoluto jpara evitar que al realizar la suma se compensen los positivos y negativos.\nPor tanto, ahora se trata de minimizar:\n\\[S=\\sum_{i=1}^n \\left[ Y_i - (b_0 - b_1 X_i) \\right]^2= 0\\] Dedicamos el próximo apartado al cálculo de los coeficientes \\(b_0\\) y \\(b_1\\). En este caso la solución es única y existen soluciones analíticas.\nEn vez de decir que el criterio de ajuste ha sido “minimizar la suma de los cuadrados de los residuos”, decimos que hemos ajustado por “mínimos cuadrados”. Este es el método de ajuste utilizado en la inmensa mayoría de los casos, produce un ajsute equilibrado entre todos los puntos y tienen importantes propiedades. Medidas como la dfesviación típica, o técnicas de análisis de datos como el análisis de la varianza están basados en un criterio similar. Un inconveniente es que el modelo obtenido es bastante sensible a los valores anómalos, cosa que no ocurre si se minimiza la suma de valores absolutos.\nEn la figura 10.6 (primera fila) tenemos una situación típica en que el ajuste por mínimo cuadrados es claramente mejor que minimizando la suma del valor absoluto de los residuos, pero en la segunda fila vemos un caso en que hay un valor que no sigue el patrón de comportamiento general. Este punto, probablemente un error, afecta de forma notable al ajuste por mínimos cuadrados pero no lo hace si se usa el valor absoluto.\n\n\n\nFigura 10.6: **** y ajuste minimizando la suma de los cuadrados de los residuos.\n\n\n\n\nTabla 10.4: Minimizar la suma de los cuadrados de los residuos. Ventajas e inconvenientes\n\n\n\n\n\n\nPROS \n\nNinguna\n\n\n\nCONS \n\nDa un número infinito de soluciones (una de ellas coincide con el ajuste por mínimos cuadrados)"
  },
  {
    "objectID": "regresionSimple.html#mínimos-cuadrados.-cálculo-de-los-coeficientes",
    "href": "regresionSimple.html#mínimos-cuadrados.-cálculo-de-los-coeficientes",
    "title": "13  Regresión Simple",
    "section": "13.2 Mínimos cuadrados. Cálculo de los coeficientes",
    "text": "13.2 Mínimos cuadrados. Cálculo de los coeficientes\nExiste una fórmula cerrada y con solución única para cada coeficiente, pero vamos a empezar identificando el valor de los coeficientes sin hacer uso de las fórmulas. Naturalmente, es mucho más rápido y más práctico usarlas o -mejor todavía- usar un paquete de software estadístico o una hoja de cálculo, pero hacerlo sin fórmulas permite entender perfectamente qué es lo que se está haciendo, y también descubrir algún detalle interesante.\n\nSin fórmulas\nRealizamos a ojo una primera estimación del valor de los coeficientes. A continuación, mediante un pequeño programa -o también usando una hoja de cálculo-, hacemos un barrido de los valores de \\(b_0\\) y \\(b_1\\) en torno a los estimados, identidicando el par que minimiza la suma de los cuadrados de los residuos.\nVayamos al diagrama de la figura 13.7 (izquierda) que ya habíamos visto en las figuras 13.2 y 13.3. La recta ajustada a ojo pasa por los puntos (-4,75; 0) y (5,75, 60) por lo que sus coeficientes son: \\(b_1\\) = 5,71 y \\(b_0\\) = 27,14. Sería mucha casualidad que esos fueran los valores exactos que estamos buscando, pero no andarán muy lejos. Vamos a crear una malla de valores de \\(b_0\\) y \\(b_1\\). Los valores de \\(b_0\\) variarán de 2 a 8 con incrementos de 0,1 y para cada uno de esos, los de \\(b_0\\) irán de 20 a 35 también en saltos de 0,1. A cada combinación de esos dos valores corresponde a una recta, y a cada recta una suma de los cuadrados de los residuos. El par de valores que minimizan esa suma de cuadrados son: \\(b_0\\) = 27,0 y \\(b_1\\) = 4,8.\n\n\n\nFigura 13.7: Recta ajustada a ojo (izq.) y suma de los cuadrados de los residuos para cada par de valores \\(b_0\\) y \\(b_1\\). En rojo, valores que la minimizan (der.).\n\n\n\n\n\n\n\n\nParaboloide de la suma de cuadrados\n\n\n\nCon los datos de nuestro ejemplo, la superficie que representa la suma de los cuadrados de los residuos es un paraboloide donde la localización del mínimo es visulamente muy clara. Pero lo nomal es que las curvas de nivel sean muy elípticas de manera que la representación no queda tan clara. Nosotros hemos logrado esa forma regular haciendo que la media de los valores de \\(X\\) sea igual a cero. De esta forma, los coeficientes son independientes y las curvas de nivel apararecen como círculos prácticamente concéntricos quedando más clara la idea que queremos representar.\n\n\n\n\nUsando las fórmulas\nEn el diagrama que representa la relación entre \\(X\\) e \\(Y\\) cada punto puede ser identificado por sus coordenadas \\((x_i, y_i)\\) con \\(1 \\leq i \\leq n\\) siendo \\(n\\) el número total de puntos. [creo que esto es redundante y habría que mejorarlo]\nCada uno de los puntos tiene un residuo asociado \\(e_i\\) y ese residuo es la diferencia entre el valor real de \\(y\\), es decir, \\(y_i\\) y su valor estimado \\(\\hat{y}_i\\), el que estará sobre la recta y que será igual a \\(b_0 + b_1 x_i\\). Por tanto, el valor del residuo asociado al punto \\(i\\) lo podemos escribir de la forma:\n\\[ e_i = y_i - \\left( b_0 + b_1 x_i \\right) \\] Por tanto, la suma de los cuadrados de los residuos, \\(S\\), será:\n\\[ S = \\sum_{í=1}^n \\left(y_i - b_0 - b_1 x_i \\right )^2 \\]\nTanto los valores de \\(y_i\\) como los de \\(x_i\\) vienen dados. La suma de cuadrados \\(S\\) es función de los valores de \\(b_0\\) y de \\(b_1\\). Se trata de hallar los valores de \\(b_0\\) y de \\(b_1\\) que minimizan esa suma de cuadrados. El mínimo lo tendremos en el punto en que la derivada de \\(S \\left(b_0, b_1 \\right )\\) respecto a \\(b_0\\) y respecto a \\(b_1\\) es igual a cero. Seguro que es un mínimo porque el máximo no está definido.\n\\[ \\frac{\\partial S}{\\partial b_0} = -2 \\sum_{í=1}^n \\left(y_i - b_0 - b_1 x_i \\right ) \\]\n\\[ \\frac{\\partial S}{\\partial b_1} = -2 \\sum_{í=1}^n \\left(y_i - b_0 - b_1 x_i \\right ) x_i \\]\nIgualando a cero estas expresiones:\n\\[ \\sum_{í=1}^n y_i - nb_0 - b_1 \\sum_{í=1}^n x_i = 0  \\tag{13.1}\\]\n\\[ \\sum_{í=1}^n x_i y_i - b_0 \\sum_{í=1}^n x_i - b_1 \\sum_{í=1}^n  x_i^2  = 0  \\tag{13.2}\\]\nDividiendo por \\(n\\) todos los términos de la ecuación 13.1 tenemos:\n\\[ b_0 = \\bar{y} - b_1 \\bar{x} \\]\n\n\n\n\n\n\nLa recta ajustada pasa por el punto \\((\\bar{x}, \\bar{y})\\)\n\n\n\nDe la anterior expresón para \\(b_0\\) también se decude que \\(\\bar{y} = b_0 + b_1\\bar{x}\\). Es decir, la recta ajustada minimizando la suma de los cuadrados de los residuos siempre pasa por el punto \\((\\bar{x}, \\bar{y})\\) .\n\n\nSustituyendo la expresión de \\(b_0\\) en la ecuación 13.2 tenemos:\n\\[ \\sum_{í=1}^n x_i y_i - \\bar{y} \\sum_{í=1}^n x_i +  b_1\\bar{x} \\sum_{í=1}^n x_i- b_1 \\sum_{í=1}^n  x_i^2  = 0 \\]\nPara aligerar la notación no pondremos los límites a los sumatorios, que siempre son desde \\(i=1\\) hasta \\(n\\). Despejando \\(b_1\\) llegamos a:\n\\[ b_1 = \\frac{\\sum x_i y_i - \\bar{y} \\sum x_i}{\\sum x_i^2 - \\bar{x} \\sum x_i} \\] También la expresión de \\(b_1\\) se suele dar de la forma (ver Apéndice 10.1):\n\\[ b_1 = \\frac{\\sum (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum (x_i - \\bar{x})^2}  \\tag{13.3}\\]\nA partir de la ecuación 13.3 y recordando las expresiones de la covarianza y del coeficiente de correlación, llegamos a una expresión que también se ve con frecuencia en los libros de texto, seguramente porque una calculadora sencilla da directamente los tres valores que intervienen:\n\\[ b_1 = \\frac{Cov(XY)}{s_X^2} = \\frac{r_{XY} s_X s_Y}{s_X^2} = r_{XY} \\frac{s_Y}{s_X} \\] Calculando los coeficientes que corresponden a los datos de la figura 13.7 se obtiene:\n\\[ b_0 = 26,9615 \\qquad  \\qquad b_1 = 4,8616 \\] Ahora sí, con todos los decimales que queramos, aunque dar más decimales de los que tienen los datos es añadir números que no aportant ninguna información, dan una falsa sensación de precisión y complican la lectura del resultado.\n\n\n\n\n\n\n\nPor qué le llamamos modelo de regresión\n\n\n\nSean, por ejemplo, los puntos: (4; 3), (6; 8), (8; 12), (10; 10), (12; 12). La recta ajustada es: \\(y = 1+x\\). Si en vez de ajustar \\(y = f(x)\\) se ajusta \\(x=f(y)\\) ¿se obtendrá la ecuación resultante de despejar \\(x\\) en \\(y=f(x)\\), es decir: \\(x = -1 + y\\)? Si ajustamos \\(x=f(y)\\) la ecuación será: \\(x=1,57+0,714x\\). No es lo mismo minimizar la suma de los cuadrados de los residuos medidos en dirección vertical que en dirección horizontal (esto último no son los residuos)."
  },
  {
    "objectID": "regresionMultiple.html#necesidad-de-una-medida-de-relación",
    "href": "regresionMultiple.html#necesidad-de-una-medida-de-relación",
    "title": "11  Regresión Múltiple",
    "section": "11.1 Necesidad de una medida de relación",
    "text": "11.1 Necesidad de una medida de relación\nSee Knuth (1984) for additional discussion of literate programming."
  },
  {
    "objectID": "regresionMultiple.html#covarianza",
    "href": "regresionMultiple.html#covarianza",
    "title": "11  Regresión Múltiple",
    "section": "11.2 Covarianza",
    "text": "11.2 Covarianza\nCon mucho protagonismo en la explicación del comportamiento de variables aleatorias a nivel teórico, pero prácticamente no se usa para cuantificar la relación de dos variables a partir de dos conjuntos de datos.\n\n11.2.1 Deducción de la fórmula\nAquí deducción de la fórmula\n\n\n11.2.2 Propiedades\nAquí propiedades"
  },
  {
    "objectID": "regresionMultiple.html#coeficiente-de-correlación",
    "href": "regresionMultiple.html#coeficiente-de-correlación",
    "title": "11  Regresión Múltiple",
    "section": "11.3 Coeficiente de correlación",
    "text": "11.3 Coeficiente de correlación\nEste sí se usa.\n\n11.3.1 De la covarianza al coeficiente de correlación\nDividir por el producto de las desviaciones típicas.\n\n\n11.3.2 Propiedades del coeficiente de correlación\nAcotado entre 0 y 1.\n\n\n11.3.3 Correlación no implica relación causa-efecto\n\n\n11.3.4 Correlación estadísticamente significativa\n\n\nCódigo\n1 + 1\n\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. «Literate Programming». Comput. J. 27 (2): 97-111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "regresionSimple.html#medida-de-calidad-del-ajuste",
    "href": "regresionSimple.html#medida-de-calidad-del-ajuste",
    "title": "11  Regresión Simple",
    "section": "11.4 Medida de calidad del ajuste",
    "text": "11.4 Medida de calidad del ajuste\nR2"
  },
  {
    "objectID": "regresionSimple.html#lo-que-tenemos-es-una-muestra",
    "href": "regresionSimple.html#lo-que-tenemos-es-una-muestra",
    "title": "11  Regresión Simple",
    "section": "11.5 Lo que tenemos es una muestra",
    "text": "11.5 Lo que tenemos es una muestra\nSee Knuth (1984) for additional discussion of literate programming.\n\n\n\n\nKnuth, Donald E. 1984. «Literate Programming». Comput. J. 27 (2): 97-111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "regresionSimple.html#las-cosas-se-complican-lo-que-tenemos-es-una-muestra",
    "href": "regresionSimple.html#las-cosas-se-complican-lo-que-tenemos-es-una-muestra",
    "title": "13  Regresión Simple",
    "section": "13.6 Las cosas se complican: Lo que tenemos es una muestra",
    "text": "13.6 Las cosas se complican: Lo que tenemos es una muestra\nLa interpretación de los resultados se complica cuando caemos en la cuenta de que los datos disponibles son solo una muestra de la población de interés. Supongamos que deseamos estudiar la relación entre peso y estatura en los jóvenes de cierta edad (haríamos bien en separar hombres y mujeres, pero aquí vamos a ignorar ese aspecto que trataremos en el siguiente capítulo) y que disponemos de una muestra de -pongamos- 20 jóvenes. Con los datos de esa muestra ajustamos una recta pero, en realidad, esa no es la recta que andamos buscando. Si hubiéramos tomado otra muestra la recta sería otra -distitnta- pero tan válida como la primera. Entonces, ¿cómo se interpreta la recta obtenida?\nComo en otros casos, una forma de ver lo que ocurre es simulando. En los diagramas de la figura 13.14 las estaturas (\\(X\\)) se han generado aleatoriamente de una distribución N(170; 8) y a cada estatura se le ha asignado un peso (\\(Y\\)) mediante la expresión \\(Y = X -100 +e\\), donde \\(e\\) un valor también generado aleatoriamente de una distribución N(0; 5). Tanto los valores de la estatura (en cm) como los obtenidos para los pesos (en kg) son valores razonables para una población joven. Hemos repetido la simulación 6 veces y, como es natural, cada vez hemos obtenido unos datos distintos y, por tanto, también una recta ajustada distinta.\n\n\n\nFigura 13.14: Rectas ajustadas a partir de muestras de n=20 datos de una misma población. La línea negra representa el modelo teórico\n\n\nEn la figura 13.15 (izq.) se han superpuesto los 6 diagramas anteriores pudiéndose observar el haz de rectas que se obtiene. A la derecha tenemos la misma situación superponiendo 50 simulaciones (cada una con 20 datos) añadiendo, de color verde, la recta que representa el modelo teórico, es decir, la población.\n\n\n\nFigura 13.15: Superposición de 6 (izq.) y 50 (der.) simulaciones de conjuntos de 20 datos del modelo representado con una línea verde en el gráfico de la derecha.\n\n\n\nDistribución de los coeficientes\nLa buena noticia es que si los datos cumplen unas ciertas condiciones –que en general se cumplirán– los valores de los coeficientes pertenecen a distribuciones Normales con parámetros conocidos. Siguiendo con el ejemplo anterior hemos repetido 10.000 veces la simulación obteniendo otras tantas rectas ajustadas. La 13.16 muestra los histogramas de los 10.000 valores obtenidos para \\(b_0\\) y \\(b_1\\).\n\n\n\nFigura 13.16: Distribución de los coeficientes.\n\n\nObserve que las medias de las distribuciones coinciden con verdadero valor del parámetro estimado (estamos de suerte). Las desviaciones típicas dependen de:\n\nNúmero de datos: Cuanto más datos mayor información y menos incertidumbre, por tanto, menos desviación típica en la distribución de los coeficientes.\nDesviación típica de la respuesta: A mayor variabilidad de la respuesta mayor incertidumbre y mayor variabilidad en la distribución del los coeficientes.\nEl rango de variación de los valores de la variable regresora: Si los valores de \\(x\\) están muy próximos a su media habrá mayor variabilidad en los distribución de los coeficientes. Quizá este aspecto no es tan intuitivo como los anteriores, pero se entiende muy bien a la vista de un gráfico como el de la figura 13.16. En la izquierda tenemos el mismo gráfico que en la figura 13.15 con valores de X generados de una distribución N(170; 8) mientras que en el de la derecha se ha construido de la misma forma pero los valores de X se han generadod de una N(170; 3). Al tener menos variabilidad los valores de X tenemos mayor variabilidad en los valroes de los coeficientes.\n\n\n\n\nFigura 13.17: Distribución de los coeficientes.\n\n\nConocer la distribución de los coeficientes hace posible calcular intervalos de confianza o realizar constrastes de hipótesis sobre sus valores.\n\n\nCondiciones que deben reunir los datos\nPara que los coeficientes tengan las distribuciones descritas anteriormente los datos utilizados para ajustar el modelo deben cumplir las siguientes condiciones:\n\nDistribución de \\(Y\\): Dado un valor de \\(X\\), los valores de \\(Y\\) deben seguir una distribución Normal. Si \\(X\\) es la estatura e \\(Y\\) es el peso, no hace falta suponer que el peso –globalmente– sigue un distribución Normal, pero sí que los pesos para las personas de una determinada estatura siguen esa distribución (figura 13.18).\n\n\n\n\nFigura 13.18: Los valores del peso (en general, \\(Y\\)) siguen una distribución Normal para cada valor de la estatura (en general, \\(X\\)). Observe que hay una mayor densidad de puntos –observaciones– en torno a la línea verde que representa el modelo teórico.\n\n\n\nVariabilidad de \\(Y\\): Supondremos que la variabilidad de \\(Y\\) no depende del valor de \\(X\\). En nuestro ejemplo sería suponer que la variabilidad en el peso de las personas que miden 1,60 es la misma que en las personas que miden 1,80 m. Es decir, las dos “campanas” que aparecen en la figura 13.18, y las correspondientes a cualquiera de las estaturas, tienen la misma anchura. Es posible que esto no sea exactamente así porque es habitual que cuando aumenta el nivel de la respuesta aumente también su variabilidad. Si esto ocurre lo veremos en el diagrama bivariante: la nube de puntos se irá ensanchando a medida que aumenta el valor de \\(X\\). En este caso quizá convenga transformar los datos, aunque ya estaríamos ante una situación más complicada que las que pretendemos tratar aquí.\nValores de \\(X\\): No hay ninguna exigencia especial sobre estos valores. Solo es necesario que la variable sea cuantitativa. Es decir, el día de la semana, codificado como: lunes = 1, martes = 2, … no puede ser una variable regresora porque el modelo entedería que el domingo es igual a 7 veces el lunes. Aun así, también hay formas de incluir este tipo de variables. Lo veremos en el próximo capítulo en el caso de que solo puedan tomar dos valoros posibles.\nIndependencia de los residuos: La desviación respecto al valor previsto (valor sobre la recta) en en un punto no da ninguna pista sobre la desviación en el punto siguiente. Esto no ocurre con las variables que evolucionan en el tiempo, como la temperatura o la cotización de acciones en la bolsa, en que el valor de un día está influenciado por el valor de día anterior.\n\nCuando se ajustan modelos de regresión simple, la observación del diagrama bivariante de \\(Y\\) frente a \\(X\\) ya permite valorar si es razonable suponer que se cumplen los supuestos requeridos. SI nada hace suponer lo contrario, supondremos que las condiciones se cumplen. Si no se cumplen exactamente (en realidad, nunca se cumpliran “exactamente”) los intervalos de confianza y las pruebas de significación en que estamos interesdos, seguirán siendo válidos a efectos prácticos.\n\n\nPruebas de significación e intervalos de confianza\nHemos visto que si se cumplen determinadas condiciones podemos considerar que los coeficientes del modelo son valores de una distribución Normal centrada en el verdadero valor del parámetro estimado (el coeficiente en la población) y desviación típica conocida.\nEsto nos permite realizar pruebas de significación para los coeficientes del modelo.\n\nContraste \\(H_0: \\beta_0=0\\) frente a \\(H_1: \\beta_0 \\neq 0\\). Observe que el contraste se realiza sobre el valor teórico, no sobre el valor obtenido que ya vemos cual es. Este contraste tiene interés cuando se tienen razones para pensar que la recta pasa por el origen y se desea verificar que los resultados obtenidos no están en contradicción con ese supuesto.\nContraste \\(H_0: \\beta_1=0\\) frente a \\(H_1: \\beta_1 \\neq 0\\). Este es el contraste que tiene más interés. Se trata de verificar que la pendiente de la recta es significativamente distinta de cero. Si no lo es, una recta horizontal es compatible con los da5tos por lo que 5no se puede descartar que la variable regrora no sirvwe para explicar el comportaminto de la respuersta.\n\nHemos comentado anteriormente que la desviación típica de los coeficientes depende de la varianza de los errores, es decir, de la variabilidaed que presentan los puntos en torno a la recta ajustada. La varianza de los errores no se conoce, se estima a través de la varianza de los residuos. Esto provoca que los valroes que tenemos de la desciaciín típica de los coeficientes sea también un valro estimado y, por tanto +++++\nTenemos que :\n\\[\\begin{equation}\n    \\begin{aligned}\n        b_0 &\\sim N \\left(\\beta_0; \\; \\sigma_{\\beta_0} \\right) \\\\[5pt]\n        b_1 &\\sim N \\left(\\beta_1; \\; \\sigma_{\\beta_0} \\right)\n    \\end{aligned}\n\\end{equation}\\]\nPor tanto, si contrastamos \\(H_0: \\beta_0=0\\) frente a \\(H_1: \\beta_0 \\neq 0\\) a partir del valor obtenido para \\(b_0\\) tendremos:\n\\[ \\frac{b_0-0}{\\sigma_{\\beta_0}} \\sim N (0; 1) \\] y analogamente para \\(b_1\\):\n\\[ \\frac{b_1-0}{\\sigma_{\\beta_1}} \\sim N (0; 1) \\]\nPero los valroes de \\(\\sigma_{\\beta_0}\\) y los de \\(\\sigma_{\\beta_1}\\) no se conocen exactamente, pero se pueden estimar a partir de los datos disponibles. En la estimación de la desviación típica de los coeficientes aparece la variaza de los residuos. Los residuos tienen dos restricciones por lo que la t-Student tiene \\(n-2\\) grados de libertad.\n-Pruebas de significación para \\(b_1\\)\nTiene especial interés contrastar la hipótesis nula de que la pendiente de la recta (\\(\\beta_1\\)) es igual a cero.\n-Intervalos de confianza para las predicciones.\n\nSalida paquete de software\n\n-IC para las observaciones.\n\n\n\n\n\n\nLigando las pruebas se significación para \\(r\\) y para \\(b_1\\)\n\n\n\nAquí texto"
  },
  {
    "objectID": "regresionSimple.html#calidad-del-ajuste",
    "href": "regresionSimple.html#calidad-del-ajuste",
    "title": "13  Regresión Simple",
    "section": "13.3 Calidad del ajuste",
    "text": "13.3 Calidad del ajuste\nEl gráfico de la izquierda de la figura 13.8 muestra la relación entre la longitud de la circunferencia (X) de los troncos de un determinado tipo de árbol y el volumen de madera (Y) que se puede obtener de ellos (Fuente: Wolfram_Data_Repository 2016). Se observa que a más circunferencia mayor volumen de madera, tal como era de esperar, y la ecuación de la recta ajustada es útil para estimar cuanta madera se obtendrá de un tronco de determinado diámetro. Sin embargo, el gráfico de la derecha se ha realizado con los datos de un estudio publicado por Wilson y Mather (1974) citado por Draper y Smith (1998) donde se analiza la relación entre la edad al morir y la longitud de cierta línea de la mano a partir de una muestra de 50 personas fallecidas. A la vista del diagrama queda claro que no hay ninguna relación entre ambas variables. En este caso el modelo ajustado no sirve absolutamente para nada. Pero los dos modelos tienen el mismo aspecto y solo a la vista del valor de sus coeficientes es imposible saber cual de los dos es útil.\n\n\n\nFigura 13.8: Relación muy clara y relación inexistent, situaciones que no pueden distinguirse solo a la vista del modelo ajustado.\n\n\nEs necesario, por tanto, completar el modelo con una medida que informe de la calidad del ajuste obtenido. Esa medida es el coeficiente de determinación \\(R^2\\).\nPara calcular el valor de \\(R^2\\) empezamos poniéndonos en el peor de los casos: suponemos que \\(X\\) e \\(Y\\) son independientes, es decir, que el valor de \\(X\\) no aporta ninguna información sobre el valor de \\(Y\\). En este caso, la recta que muestra la relación entre ambas variables es una recta horizontal: la estimación del valor de \\(Y\\) es siempre la misma, sin importar el valor de \\(X\\), y la mejor apuesta para ese valor de \\(Y\\) -a falta de cualquier otra información- es su valor medio \\(\\bar{y}\\). A la suma de los cuadrados de los residuos correspondientes a esa recta horizontal que pasa por \\(\\bar{y}\\) le llamamos \\(Q_Y\\).\nA continuación calculamos la suma de los cuadrados de los residuos correspondientes a nuestra recta ajustada (la que minimiza la suma de los cuadrados de los residuos) y le llamaremos \\(Q_R\\). Cuanto mejor sea el ajuste menor será el valor de \\(Q_R\\) y mayor la diferencia entre \\(Q_Y\\) y \\(Q_R\\).\nEl valor de \\(R^2\\) es igual a la proporción de \\(Q_Y\\) explicada por \\(X\\), es decir, la proporción en que disminuye \\(Q_Y\\) gracias a la introducción de \\(X\\) como variable explicativa, es decir:\n\\[ R^2 = \\frac{Q_Y - Q_R}{Q_Y} \\]\nVeamos este cálculo en un ejemplo con datos sencillos. En la figura 13.9 tenemos 5 puntos que podrían representar la relación entre el peso y la estatura de 5 individuos. Si, ignorando la información aportada por la estatura, siempre damos una estimación del peso igual a su valor medio, será como ajustar a una recta horizontal y tendremos una suma de los cuadrados de los residuos \\(Q_Y = 56\\). Sin embargo, si utilizamos la información que aporta la estatura y realizamos el ajuste minimizando la suma de los cuadrados de los residuos tenemos \\(Q_R = 16\\).\n\n\n\nFigura 13.9: Múltiples opciones para minimizar la suma de los residuos en valor absoluto.\n\n\nHemos reducido la suma de los cuadrados de los residuos de 56 a 16, por tanto:\n\\[ R^2 = \\frac{Q_Y - Q_R}{Q_Y} = \\frac{56 - 16}{56} = 0.7143 \\]\nNormalmente nos referimos a este valor como un porcentaje. En este caso sería el 71.43%. En los ejemplos de la figura 13.8 estos valores son del 93,5% (volumen de madera) y 1,5% (edad al morir).\n\n\n\n\n\n\n\\(R^2\\) es el cuadrado del coeficiente de correlación \\(r\\)\n\n\n\nEfectivamente, en el caso que estamos considerando de regresión simple, el coeficiente de determinación \\(R^2\\) es igual al cuadrado del coeficiente de correlación \\(r\\). Este último puede variar entre \\(-1\\) y \\(1\\) por lo que, obviamente, \\(R^2\\) varía entre 0 y 1. La demostración es corta y fácil de encontrar en internet. Por ejemplo en:"
  },
  {
    "objectID": "regresionSimple.html#relación-polinómica-entre-x-e-y",
    "href": "regresionSimple.html#relación-polinómica-entre-x-e-y",
    "title": "11  Regresión Simple",
    "section": "11.5 Relación polinómica entre \\(x\\) e \\(y\\)",
    "text": "11.5 Relación polinómica entre \\(x\\) e \\(y\\)\nLa relación entre \\(X\\) e \\(Y\\) puede no ajustarse a una recta pero sí a una parábola o, en general, a un modelo polinómico. También se puede ajustar a otro tipo de modelo que se puede linealizar transformando los valores de X, los de Y, o ambos. Por ejemplo, nuestros datos se podrían adaptar al modelo \\(y = \\beta_0 e^{\\beta_1 x}\\) y realizando el cambio \\(y' = \\ln y\\) se obtiene el modelo lineal: \\(y' = \\ln \\beta_0 + \\beta_1 x\\) a partir del cual se deducen de forma inmediata los coeficientes del modelo original. El ejemplo que vamos a ver se ajusta aun modelo polinómino de segundo gramdo. Interesados en otras transformaciones para lienealizar la relación pueden consultar Montgomery y Peck (1992), pág. 90.\n\n\n\nFigura 11.8: Múltiples opciones para minimizar la suma de los residuos en valor absoluto.\n\n\nAquí más texto\n\n\n\nFigura 11.9: Múltiples opciones para minimizar la suma de los residuos en valor absoluto."
  },
  {
    "objectID": "regresionSimple.html#caso-particular-recta-por-el-origen",
    "href": "regresionSimple.html#caso-particular-recta-por-el-origen",
    "title": "11  Regresión Simple",
    "section": "11.5 Caso particular: Recta por el origen",
    "text": "11.5 Caso particular: Recta por el origen\nEn algunos casos, cuando por nuestro conocimiento del fenómeno que estudiamos sabemos que si \\(x=0\\) entonces seguro que \\(y=0\\), y la zona que estamos estudiando (nuestro rango de valroes) está próximo al origen, podemos forzar que la recta pase por el punto \\((0, 0)\\) para íncluya el conocimiento que ya tenemos del fennómeno que estamos estudiando. Conviene insistir en que también es necesario que los valores disponibles estén cerca del origen. Por ejemplo, al modelar el peso en función de la estatura sabemos que si la estatura es cero, el peso también será cero, pero no ajustamos a una recta por el origen porque los valores que se ajustan están lejos del origen y no se puede extrapolar la relación.\nSi la recta debe pasar por el origen su ecuación será: \\(y = b_1 X\\). Para deducir la expresión de \\(b_1\\) solo hay que minimizar: \\(S = \\sum (y_i -b_1x_i)^2\\) y siguiendo el procedimiento habitual tenemos: \\[ \\frac{\\mathrm{d}S}{\\mathrm{d}b_1}  = \\frac{\\mathrm{d}(\\sum y_i^2-\\sum 2y_ib_1x_i+ \\sum b_1^2x_i^2)} {\\mathrm{d} b_1} = -2 \\sum x_iy_i +2 \\sum x_i^2b_1\\]\nEstá claro que la segunda derivada es positiva (es una suma de cuadrados) por lo que tendremos un mínimo. Igualando a cero y despejando el valor de \\(b_1\\) se obtiene: \\[b_1 = \\frac{\\sum x_iy_i}{\\sum x_i^2} \\]\nEn este caso la recta no se ha ajustado con el método de los mínimos cuadrados (minimizando la suma de los cuadrados de los residuos) y algunas propiedades que se derivan esa formad e ajuste no se cumplen en este caso. Por ejemplo, el valor de \\(R^2\\) no es el cuadrado del coeficiente de correlación. R2 no es una buena medida de la calidad del ajuste."
  },
  {
    "objectID": "regresionSimple.html#relación-no-lineal-entre-x-e-y",
    "href": "regresionSimple.html#relación-no-lineal-entre-x-e-y",
    "title": "13  Regresión Simple",
    "section": "13.4 Relación no lineal entre \\(X\\) e \\(Y\\)",
    "text": "13.4 Relación no lineal entre \\(X\\) e \\(Y\\)\nSi a la vista del diagrama bivariante se observa que la relación entre \\(X\\) e \\(Y\\) no es lineal, se puede utilizar el aspecto de la nube de puntos y el conocimiento del fenómeno que se estudia para plantear un modelo que se ajuste a los datos. Los modelos polinómicos de segundo grado son muy versátiles y pueden ser una buena opción. También se puede ajustar a modelos linealizables transformando los valores de \\(X\\), los de \\(Y\\), o ambos. Si nuestros datos se ajustan a una función del tipo \\(y = \\beta_0 e^{\\beta_1 x}\\), podemos realizar el cambio \\(y' = \\ln y\\) obteniendo el modelo lineal: \\(y' = \\ln \\beta_0 + \\beta_1 x\\) a partir del cual se deducen de forma inmediata los coeficientes del modelo original. Interesados en este tipo de transformaciones para linealizar la dependencia pueden consultar Montgomery y Peck (1992) pág. 90. o Peña (2002) pág. 314.\nLa figura 13.10 (izquierda) muestra los datos de producción de electricidad de un aerogenerador según sea la velocidad del viento (datos en: Montgomery y Peck (1992), pág. 92). Se observa una relación no lineal ya que cuando la velocidad del viento es baja, pequeños incrementos en la velocidad tienen un impacto importante en la producción de electricidad, mientras que para velocidades altas la producción tiende a estabilizarse. Ajustando a una parábola se obtiene \\(y = -1,156 + 0,7229x -0,03812x^2\\) con un coeficiende de determinación \\(R^2 = 96,8%\\), lo cual no está nada mal.\nOtra opción es estudiar la producción de electricidad en función de la inversa de la velocidad del viento (figura de la derecha). Creamos la variable \\(X' = 1/X\\) y obtenemos el ajuste: \\(y = 2,979 - 6,935/x\\) con un \\(R^2 = 97,9%\\) que es también un valor excelente y, además, con un modelo más compacto. En general, trabajar con la inversa de \\(X\\) puede ser una buena alternativa al modelo cuadrático.\n\n\n\nFigura 13.10: Texto figura.\n\n\nHay que tener en cuenta que el modelo más adecuado no necesariamente es el que tiene el \\(R^2\\) más elevado. Nos interesa que el modelo sea compacto y que pueda interpretarse y sea coherente con nuestro conocimiento del fenómeno en estudio. Si vamos aumentando el grado del polinomio ajustado cada vez tendremos un mayor valor de \\(R^2\\) incluso, si tenemos pocos datos, podemos llegar a un \\(R^2\\) del 100% siendo el modelo obtenido totalmente inútil.\nVolviendo a los datos de la figura 13.9 donde a partir de los pesos de 5 personas (efectivamente son muy pocas, es solo un ejemplo) queremos modelar la relación entre peso y estatura, el modelo lineal es el más razonable. Si ajustamos los datos a un modelo cuadrático se tiene un máximo de peso en torno a una estatura de 175 cm que no tiene sentido. El polinomio de tercer grado presenta una forma que tampoco parece razonable y el de cuarto grado es un modelo con 5 parámetros (los 4 coeficientes y la ordenada en el origen) y como tenemos 5 puntos ajusta perfectamente, pero ni es un modelo razonable ni sirve en absoluto para estimar el peso de un individuo a partir de su altura (sí lo explica para los 5 individuos usados para construir el modelo, pero para esos ya lo sabíamos). Recuerde que dos puntos se ajustan perfectamente a un modelo con dos parámetros (una recta) tres puntos a un modelo con tres parámetros, … etc. Estos son modelos que explican muy bien lo que ya se sabe, pero son totalmente inútiles para hacer predicciones que es lo que -en general- se pretende.\n\n\n\nFigura 13.11: Aumentando el grado del polinomio la curva de adapta a los puntos pero solo explica lo que ya sabemos."
  },
  {
    "objectID": "regresionSimple.html#transformación-logarítmica",
    "href": "regresionSimple.html#transformación-logarítmica",
    "title": "13  Regresión Simple",
    "section": "13.5 Transformación logarítmica",
    "text": "13.5 Transformación logarítmica\nEn algunos casos, los valores de \\(X\\), los de \\(Y\\), o ambos, siguen una distribución asimétrica, con valores que aparecen agrupados cerca del origen y muy dispersos hacia los valores altos. Un ejemplo típico de esta situación se da al analizar la relación entre el peso del cerebro y el peso de cuerpo en 62 especies de mamímeros (Weisberg 2014, pág. 186). La mayoria de esos mamíferos pesan poco –la mediana es de 3,34 kg– pero algunos, como los elefantes, pesan varias toneladas y algo similar ocurre con el peso de los cerebros. Al realizar el diagrama bivariante del peso del cerebro (\\(Y\\)) frente al peso de cuerpo (\\(X\\)) prácticamente todos los puntos aparecen amontonados en la zona próxima al origen, En estas condiciones ajustar un modelo de regresión no tiene sentido, porque la mayoría de datos actúan como un solo punto y los que estan alejados tienen una gran influencia sobre la recta ajustada.\n\n\n\nFigura 13.12: Relación entre el peso del cerebro y el peso del cuerpo en 62 especies de mamíferos.\n\n\nUno puede caer en la tentación de considerar a los elefantes como valores anómalos y eliminarlos, pero esa no es una buena decisión por dos razones:\n\nRestringe la validez del modelo, ya no valdrá para todos los mamíferos considerados.\nAl eliminar esos valores y reescalar el gráfico aparecen otros valores anómalos: la persona humana (que da más reparo eliminar), la jirafa, el caballo, la vaca… y al final nos vamos quedando sin puntos.\n\nEn casos como este, la transformación logarítmica “estira” los datos permitiendo un ajuste en el que todos los puntos tienen una influencia similar. Realizando esta transformación en nuestros datos se obtiene -casi parece un milagro- una nube de puntos tal como esperamos tener cuando ajustamos a una recta.\n\n\n\nFigura 13.13: Peso del cerebro frente al peso del cuerpo antes y después de la transformación logarítmica.\n\n\nEl modelo obtenido es:\n\\[\\log(Y) = 0,9271 + 0,7517 \\log(X) \\quad \\text{con} \\quad R^2 = 91,95\\%\\] Volviendo a las variable soriginales nos queda (el cuerpo está en kg y el del cerebro en g):\n\\[Y = 8,45 · X^{3/4}\\] La transformación logarítmica de los datos es, sin duda, una buena opción en casos como este, pero también tiene efectos secundarios no deseados.\nEn primer lugar hay que tener en cuenta que los residuos (diferencia entre el valor real y el valor previsto) también están en escala logarítmica. POr ejemplo, para el elefante africano (el mayor, parece que la recta pasa por el punto) el valor real del peso del cerebro es de 5712 g y la previsión es de 6229 (+9%) y para el elefante asiático el valor real es de 4603 g mientras que el valor previsto es de 3031 g (-34%). El mamífero que presenta mayor residuo positivo es la persona humana (valor real: 1320, previsto: 185, -86%) mientras que el de mayor residuo negativo corresponde al Yapok (en inglés: Water opossum). Seguramente más interesante que el modelo en sí es conocer qué animales se separan más -por encima y por debajo- del patrón general. Sobre este tema existen muchas publicaciones. Los interesados pueden empezar explorando la Wikipedia y las referencias que incluye.\n\n\n\n\n\n\nTransformación logarítmica: No importa la base\n\n\n\nEn efecto, sea \\(y = \\ln (x)\\) y \\(z = \\log_{10}(x)\\). Tendremos que \\(e^y = x\\) y también que \\(10^z = x\\), luego \\(e^y = 10^z\\). Por tanto, \\(\\ln(e^y) = \\ln(10^z)\\) y es inmediato que: \\(y = \\ln(10)·z\\).\nPor tanto, cambiar la base del logaritmo equivale a multiplicar por una constante. En particular, para pasar del logaritmo neperiano al decimal basta con multiplicar por \\(\\ln(10)\\). El aspecto del diagrama bivariante es el mismo con independencia de la base utilizada para la transformación logarítmica, solo cambian las escalas, aunque para que al volver a las variables originales la expresión sea más compacta puede interesar elegir una base u otra.\n\n\nPosibilidad de usar los datos de Hooker, parece relación lineal pero no lo es y la transformación logarítmica da buen resultado"
  },
  {
    "objectID": "correlacion.html#necesidad-de-una-medida-de-la-relación",
    "href": "correlacion.html#necesidad-de-una-medida-de-la-relación",
    "title": "10  Medidas de relación lineal",
    "section": "10.1 Necesidad de una medida de la relación",
    "text": "10.1 Necesidad de una medida de la relación\nVeamos los cuatro casos de la figura 11.10. El primero muestra la relación entre la presión atmosférica (en pulgadas de Hg) y la temperatura de ebullición del agua (en ºF). Los datos fueron tomados por el botánico Joseph D. Hookeren en distintos puntos de la cordillera del Himalaya a mediados del siglo XIX. Si la presión atmosférica, y a partir de ella la altitud, se podía evaluar a partir de la temperatura de ebullición del agua (muy fácil de medir) se podía evitar el uso de los frágiles y difíciles de transportar barómetros que entonces se usaban. Fue un éxito, porque entre las dos variables se observa una relación casi perfecta.\nEl diagrama 2 muestra la relación entre la longitud de la circunferencia de los troncos de un determinado tipo de árbol el volumen de madera que se puede obtener de ellos (Fuente: Wolfram_Data_Repository 2016). Se observa una estrecha relación entre ambas variables. El diagrama 3 se ha obtenido con datos de esos mismos árboles pero representa el volumen de madera en función de la altura del arbol. EN este caso también se observa una relación, pero no tan clara como en el caso anterior.\nFinalmente, el diagrama 4 se ha realizado con los datos de un estudio publicado por Wilson y Mather (1974) citado por Draper y Smith (1998) donde se analiza la relación entre la edad al morir y la longitud de cierta línea de la mano a partir de una muestra de 50 personas fallecidas. A la vista del diagrama queda claro que no hay ninguna relación entre ambas variables.\n\n\n\n\n\n\n\n\n\n\n\nFigura 10.2: Múltiples opciones para minimizar la suma de los residuos en valor absoluto.\n\n\n\n\n\nAunque la información fundamental queda reflejada en el diagrama bivariante, en algunos casos, especialmente cuando es dudosa solo a la vista del gráfico, también resulta útil cuantificarla con una medida objetiva de relación lineal. Vamos a ver de donde sale y como se interpreta la covarianza y el coeficiente de correlación (a veces se añade “de Pearson” porque fue este estadístico el que lo desarrolló. Existen otros coeficientes de correlación de mucho menor uso, si no se dice de que tipo es siempre entendemos que se refiere al de Pearson)."
  },
  {
    "objectID": "correlacion.html#observación-y-cuantificación-de-la-relación",
    "href": "correlacion.html#observación-y-cuantificación-de-la-relación",
    "title": "12  Medidas de relación lineal",
    "section": "12.1 Observación y cuantificación de la relación",
    "text": "12.1 Observación y cuantificación de la relación\nVeamos los cuatro casos de la figura 12.2. El primero muestra la relación entre la presión atmosférica (en pulgadas de Hg) y la temperatura de ebullición del agua (en ºF). Los datos fueron tomados por el botánico Joseph D. Hookeren en distintos puntos de la cordillera del Himalaya a mediados del siglo XIX. Si la presión atmosférica, y a partir de ella la altitud, se podían evaluar a partir de la temperatura de ebullición del agua (muy fácil de medir) se podía evitar el uso de los frágiles y difíciles de transportar barómetros de la época. Fue un éxito, porque entre las dos variables se observa una relación casi perfecta.\nEl diagrama 2 muestra la relación entre la longitud de la circunferencia de los troncos de un determinado tipo de árbol y el volumen de madera que se puede obtener de ellos (Ryan, Joiner, y Ryan 1976). Se observa una estrecha relación entre ambas variables. El diagrama 3 se ha obtenido con datos de esos mismos árboles pero representa el volumen de madera en función de la altura del arbol. En este caso también se observa una relación, pero no tan clara como en el caso anterior.\nFinalmente, el diagrama 4 se ha realizado con los datos de un estudio publicado por Wilson y Mather (1974) citado por Draper y Smith (1998) donde se analiza la relación entre la edad al morir y la longitud de cierta línea de la mano a partir de una muestra de 50 personas fallecidas. A la vista del diagrama queda claro que no hay ninguna relación entre ambas variables.\n\n\n\nFigura 12.2: Cuatro situaciones que muestran diferentes grados de relación\n\n\nAunque la información fundamental queda reflejada en el diagrama bivariante, cuando a la vista del gráfico la relación es dudosa, o cuando interesa cuantificar la relación observada, disponemos de medidas de relación lineal. Las dos de uso más habitual son la covarianza y el coeficiente de correlación, mucho más esta última por las razones que veremos a continuación.\n\n\n\n\n\n\nNotación usada\n\n\n\nPara la covarianza no tenemos un símbolo específico. Cuando nos referimos a modelos teóricos, o a nivel poblacional, escribimos \\(\\text{Cov}(X,Y)\\). Para el valor calculado a partir de unos datos concretos (una muestra) escribimos \\(\\widehat{\\text{Cov}}(X,Y)\\) colocando un “sombrero” encima de \\(\\text{Cov}\\) para indicar que se trata de un estimador. Para el coeficiente de correlación utilizamos la regla general de asignar una letra latina al valor en la muestra, en este caso \\(r\\) y la letra griega correspondiente, \\(\\rho\\), para la población."
  },
  {
    "objectID": "correlacion.html#apéndice-1",
    "href": "correlacion.html#apéndice-1",
    "title": "9  Medidas de relación lineal",
    "section": "APÉNDICE 1",
    "text": "APÉNDICE 1\n\nCoeficiente de correlación cuando la relación lineal es perfecta\nSi todos los puntos están alineados tenemos que: \\(y_i =a+bx_i\\) y también: \\(\\sum y_i = \\sum (a+bx_i)\\), de donde \\(n\\bar{y} = na + bn \\bar{x}\\), es decir: \\(\\bar {y} =a+b \\bar{x}\\). Así pues, podemos escribir el numerador de la expresión de \\(r\\) de la forma:\n\\[\\begin{equation*}\n    \\begin{split}\n        \\sum_{i=1}^n \\left ( x_i - \\bar{x} \\right ) \\left ( y_i - \\bar{y} \\right ) &= \\sum_{i=1}^n \\left ( x_i - \\bar{x} \\right ) \\left ( a+bx_i - (a+b\\bar{x}) \\right ) \\\\\n        &= \\sum_{i=1}^n \\left ( x_i - \\bar{x} \\right )   b \\left ( x_i - \\bar{x} \\right ) = b \\sum_{i=1}^n \\left ( x_i - \\bar{x} \\right )^2\n    \\end{split}\n\\end{equation*}\\]\nCon un razonamineto similar, en el denominador podemos escribir el término en que aparecen los valores \\(y_i\\) de la forma: \\[\\begin{equation*}\n    \\begin{split}\n        \\sqrt{\\sum_{i=1}^n \\left ( y_i - \\bar{y} \\right )^2 } &= \\sqrt{\\sum_{i=1}^n \\left ( a+bx_i - ( a+b \\bar{x} ) \\right )^2 } =  b \\sqrt{ \\sum_{i=1}^n \\left ( x_i -  \\bar{x}  \\right )^2 } \\\\\n    \\end{split}\n\\end{equation*}\\]\nRecuperando el término correspondiente a los valores de \\(x\\), el denominador nos queda:\n\\[  \\sqrt {\\sum_{i=1}^n \\left ( x_i - \\bar{x} \\right )^2} \\cdot b \\sqrt{\\sum_{i=1}^n \\left ( x_i - \\bar{x} \\right )^2 } = b \\sum_{i=1}^n \\left ( x_i - \\bar{x} \\right )^2 \\]\nIgual que el numerador, aunque con la diferencia de que su valor seguro que es positivo (proviene de un producto de desviaciones típicas) mientras que el valor de \\(b\\) en el numerador será positivo o negativo según sea el signo de la pendiente de la recta.\nAsí pues, si los puntos se alinean según una recta, el valor del coeficiente de correlación será -1 o 1 según la pendiente sea negativa o positiva.\n\n\n\n\nDraper, N. R., y H. Smith. 1998. Applied Regression Analysis. 3.ª ed. USA: John Wiley & Sons, Inc.\n\n\nRyan, T. A., B. L Joiner, y B. F. Ryan. 1976. The Minitab Student Handbook. 1.ª ed. USA: Duxbury Press.\n\n\nWeisberg, S. 2014. Applied Linear Regression. 4.ª ed. USA: John Wiley & Sons, Inc."
  },
  {
    "objectID": "planteamientoGeneral.html",
    "href": "planteamientoGeneral.html",
    "title": "1  Plantemiento general",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n\nCódigo\n1 + 1\n\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. «Literate Programming». Comput. J. 27 (2): 97-111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "queEs.html",
    "href": "queEs.html",
    "title": "¿Qué es la estadística?",
    "section": "",
    "text": "Estoy haciendo pruebas.\n\nEstadística y matemáticas\ntexto\n\n\nEstadística y probabilidad\ntexto\n\n\nEstadística y Data Science\ntexto"
  },
  {
    "objectID": "estMatematicas.html",
    "href": "estMatematicas.html",
    "title": "Estadística y matemáticas",
    "section": "",
    "text": "Estoy haciendo pruebas."
  },
  {
    "objectID": "estProbabilidad.html",
    "href": "estProbabilidad.html",
    "title": "Estadística y probabilidad",
    "section": "",
    "text": "Estoy haciendo pruebas."
  },
  {
    "objectID": "estDataScience.html",
    "href": "estDataScience.html",
    "title": "Estadística y Data Science",
    "section": "",
    "text": "Estoy haciendo pruebas."
  },
  {
    "objectID": "regresionMultiple.html#las-cosas-no-son-como-parecen",
    "href": "regresionMultiple.html#las-cosas-no-son-como-parecen",
    "title": "14  Regresión Múltiple",
    "section": "14.1 Las cosas no son como parecen",
    "text": "14.1 Las cosas no son como parecen\nEjemplo con 3 variables. Ejemplo examen."
  },
  {
    "objectID": "regresionMultiple.html#fuerza-bruta.-aquí-va-en-serio.",
    "href": "regresionMultiple.html#fuerza-bruta.-aquí-va-en-serio.",
    "title": "14  Regresión Múltiple",
    "section": "14.2 Fuerza bruta. Aquí va en serio.",
    "text": "14.2 Fuerza bruta. Aquí va en serio.\nBest subsets"
  },
  {
    "objectID": "regresionMultiple.html#ojo-con-las-explicaciones-milagrosas.",
    "href": "regresionMultiple.html#ojo-con-las-explicaciones-milagrosas.",
    "title": "11  Regresión Múltiple",
    "section": "11.4 Ojo con las explicaciones milagrosas.",
    "text": "11.4 Ojo con las explicaciones milagrosas.\nTantos parámetros como datos"
  },
  {
    "objectID": "regresionMultiple.html#a-tener-en-cuenta",
    "href": "regresionMultiple.html#a-tener-en-cuenta",
    "title": "14  Regresión Múltiple",
    "section": "14.6 A tener en cuenta",
    "text": "14.6 A tener en cuenta\nAnálisis exploratoio más complicado Lo mismo con el análisis de los residuos\nOtras medidas de calidad del ajuste.\nLa regresión no sirve para todo"
  },
  {
    "objectID": "regresionMultiple.html#un-caso-sencillo-una-variable-cuantitativa-y-otra-cualitativa",
    "href": "regresionMultiple.html#un-caso-sencillo-una-variable-cuantitativa-y-otra-cualitativa",
    "title": "14  Regresión Múltiple",
    "section": "14.3 Un caso sencillo: Una variable cuantitativa y otra cualitativa",
    "text": "14.3 Un caso sencillo: Una variable cuantitativa y otra cualitativa\npeso, altura, sexo, y datos UFFI (creo)"
  },
  {
    "objectID": "regresionMultiple.html#ojo-con-las-explicaciones-milagrosas",
    "href": "regresionMultiple.html#ojo-con-las-explicaciones-milagrosas",
    "title": "14  Regresión Múltiple",
    "section": "14.4 Ojo con las explicaciones milagrosas",
    "text": "14.4 Ojo con las explicaciones milagrosas\nTantos parámetros como datos"
  },
  {
    "objectID": "regresionMultiple.html#modelos-explicativos-y-modelos-predictivos",
    "href": "regresionMultiple.html#modelos-explicativos-y-modelos-predictivos",
    "title": "14  Regresión Múltiple",
    "section": "14.5 Modelos explicativos y modelos predictivos",
    "text": "14.5 Modelos explicativos y modelos predictivos\ntexto"
  },
  {
    "objectID": "regresionSimple.html",
    "href": "regresionSimple.html",
    "title": "13  Regresión Simple",
    "section": "",
    "text": "Apéndice 10.1"
  },
  {
    "objectID": "Parte_Contraste.html",
    "href": "Parte_Contraste.html",
    "title": "CONTRASTE DE HIPÓTESIS",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n\nCódigo\n1 + 1\n\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. «Literate Programming». Comput. J. 27 (2): 97-111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "Conceptos_CH.html",
    "href": "Conceptos_CH.html",
    "title": "8  Conceptos",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n\nCódigo\n1 + 1\n\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. «Literate Programming». Comput. J. 27 (2): 97-111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "Proceso_CH.html",
    "href": "Proceso_CH.html",
    "title": "9  Esquema de razonamiento",
    "section": "",
    "text": "Todo provisional."
  },
  {
    "objectID": "tiposError_CH.html",
    "href": "tiposError_CH.html",
    "title": "10  Tipos de error",
    "section": "",
    "text": "Este título es provisional"
  },
  {
    "objectID": "regresionSimple.html#distribución-de-los-coeficientes",
    "href": "regresionSimple.html#distribución-de-los-coeficientes",
    "title": "13  Regresión Simple",
    "section": "13.7 Distribución de los coeficientes",
    "text": "13.7 Distribución de los coeficientes\nLa buena noticia es que si los datos cumplen unas ciertas condiciones –que en general se cumplirán– los valores de los coeficientes pertenecen a distribuciones Normales con una media igual al verdadero valor del parámetro estimado (el valor obtenido es un estimador insesgado, estamos de suerte) y una desviación típica que depende del número de datos (cuantos más datos menos incertidumbre y, por tanto, menos desviación típica) y también depende de la variabilidad de la respuesta (cuanto menos variabilidad menos incertidumbre y menos desviación típica).\n==Nos enfrentamos a esta situación realizando unas suposiciones sobre el comportamiento de los datos y si esas suposiciones se cumplen los coeficientes del modelo tienen unas propiedades conocidas que facilitan la interpretación del modelo.== texto alternativo.\nConocer la distribución de los coeficientes hace posible calcular intervalos de confianza para sus valores o realizar constrastes de hipótesis sobre sus valores. Tiene especial interés contrastar la hipótesis nula de que la pendiente de la recta (\\(\\beta_1\\)) es igual a cero.\n\n\n\nFigura 13.16: Distribución de los coeficientes.\n\n\nLo que pedimos respecto al comportamiento de los datos es:\nValores de \\(X\\): No hay ninguna exigencia sobre estos valores. Pueden corresponder a una variable discreta o continua y no importa cual sea su distribución.\nValores de \\(Y\\): Dado un valor de \\(X\\), los valroes de \\(Y\\) deben seguir una distribución Normal. Si \\(X\\) es la estatura e \\(Y\\) es el peso, no hace falta suponer que el peso sigue una distribución Normal, sino que los pesos para las personas de una determinada altura siguen una distribución Normal. Más claro: No todos los que miden 1,70 m pesan lo mismo, pues bien, suponemos que los pesos de los mioden 1,70 siguen una distribución Normal. Y quien dice 1,70 dice cualqueir otra altura. Obserque es to no es lo mismo que decir que los pesos -globalmente- siguen una distribución Normal. Formalmente se escribe:\nSobre la variabilidad: La variabilidad de Y no depende del valor de X. Es decir, suponemos que la variabilidad en el peso de las personas que miden 1,60 es la misma que para las personas que miden 1,80 m. Es posible que esto no sea exactamente así porque es habitual que cuando aumenta el nivel de la respuesta aumente también su variabilidad…\nAunque las hipótesis no se cumplan exactamente esperamos …\nA no ser que los datos pongan de manifiesto…\nTambién suponemos que los residuos son indepencientes, es decir, la desviación en un punto no da ninguna pista sobre la desviación en el siguiente. Esto no ocurre con las variables que evolucionan en el tiempo, como la temperatura o la cotización de acciones en la bolsa (Consejo: no crea que usando la estadística se hará rico en la bolsa).\nSi esas hipóstessi se cumplen los coeficientes siguen distribuciones Normales con parámetros conocidos.\n-Pruebas de significación para \\(b_1\\)\n-Intervalos de confianza para las predicciones.\n-IC para la recta.\n-IC para las observaciones.\n\n\n\n\n\n\nLigando las pruebas se significación para \\(r\\) y para \\(b_1\\)\n\n\n\nAquí texto\n\n\n\nCondiciones que deben reunir los datos\nCuanto más pedimos a los datos, más exigentes debemos ser con las condiciones que deben cumplir.\nNormalidad de la respuesta\nEstimación de los parámetros"
  },
  {
    "objectID": "regresionSimple.html#ajuste-a-una-recta",
    "href": "regresionSimple.html#ajuste-a-una-recta",
    "title": "13  Regresión Simple",
    "section": "13.1 Ajuste a una recta",
    "text": "13.1 Ajuste a una recta\nSi entre la respuesta y la variable regresora se observa una relación lineal se determina la ecuación de la recta que mejor se adapta a los puntos disponibles. Lo que significa “mejor” es discutible. Veamos algunas formas de hacerlo.\n\nA ojo\nSe traza la recta directamente sobre el papel o se identifican dos puntos de paso y a partir de ellos se calculan los coeficientes del modelo.\nA pesar de sus evidentes limitaciones, si solo se trata de tener la recta no es un método tan malo como parece. Con un poco de práctica el ajuste no será muy distinto del “perfecto” y no se cometeran errores de bulto debido a la presencia de valores anómalos, cosa que sí puede ocurrir si se tratan los datos de forma automática sin mnirarlos.\n\n\n\nFigura 13.2: Ajuste a ojo y el que minimiza la suma de los cuadrados de los residuos.\n\n\n\n\n\n\n\n\n\nPROS \n\nIntuitivo. Muy fácil de entender.\nNo se comenten errores de mucho bulto.\n\n\n\nCONS \n\nNo se logra el ajuste “perfecto” de acuerdo con el criterio establecido. |\nNo se tienen medidas de calidad del ajuste. |\nSolo sirve para regresión simple.\n\n\n\n\n\n\nMétodo de Ishikawa\nSe identifica el primer y el tercer cuartil de los valores de \\(X\\) \\((X_{Q1}\\) y \\(X_{Q3})\\), e igual para los valores de \\(Y\\) \\((Y_{Q1}\\) y \\(Y_{Q3})\\). Se traza la recta por los puntos \\((X_{Q1}\\) y \\(Y_{Q1})\\) y \\((X_{Q3}\\) y \\(Y_{Q3})\\). Se obtiene una recta muy razonable sin necesidad de realizar cálculos ni de aplicar fórmulas de las que se desconoce su lógica.\n\n\n\nFigura 13.3: Ajuste por el método de Ishikawa y el que minimiza la suma de los cuadrados de los residuos.\n\n\n\n\nTabla 13.1: Método de Ishikawa. Ventajas e inconvenientes\n\n\n\n\n\n\nPROS \n\nFácil de entender\nRobusto frente a la presencia de valores anómalos o con excesiva influencia\n\n\n\nCONS \n\nNo se tienen medidas de calidad del ajuste\nSolo sirve para regresión simple\n\n\n\n\n\n\n\n\n\n\n\nKaoru Ishikawa (1915-1989)\n\n\n\nFue un ingeniero japonés, considerado uno de los artífices del llamado “milagro japonés” que condujo los productos japoneses desde la mediocridad hasta arrasar en los mercados mundiales (electrónica, fotografía, automoción,…). Una de las claves del éxito fue el uso intensivo de técnicas estadísticas para el control y la mejora de la calidad. Ishikawa es conocido por proponer el uso de herramientas sencillas, que todos puedan entender y aplicar de forma habitual.\n\n\n\n\nHaciendo que la suma de los residuos sea igual a cero\nSe trata de obtener los valores de \\(b_0\\) y \\(b_1\\) que cumplen la expresión:\n\\[\\sum_{i=1}^n \\left[ Y_i - (b_0 - b_1 X_i) \\right]= 0\\] qye es equivalente a:\n\\[ n\\bar{Y} - nb_0 - b_1 n \\bar{X} = 0\\] Por tanto, con cualquier par de valores \\(b_0\\) y \\(b_1\\) que verifiquen la expresión \\(\\bar{Y} = b_0 + b_1 \\bar{X}\\), es decir, con cualquier recta que pase por (\\(\\bar{X}\\), \\(\\bar{Y}\\)) tendremos una suma de residuos igual a cero.\nQue haya infinitas rectas que cumplan esa condición es una mala señal, porque seguro que no todas son adecuadas. Para los valores representados en la figura 13.4 tenemos que \\(\\bar{X}= 6\\) y \\(\\bar{Y}= 9\\). Rectas que hacen que la suma de los residuos sea igual a cero son, por ejemplo, la que tiene coeficientes \\(b_0=9\\) y \\(b_1=0\\), es decir: \\(Y = 9\\), o también \\(b_0 = 12\\) y \\(b_1 = -0.5\\), es decir: \\(Y = 12 -0.5X\\) y ambos son claramente muy malos ajustes.\n\n\n\nFigura 13.4: Dos ajustes -claramente muy malos- con suma de residuos igual a cero.\n\n\n\n\nTabla 13.2: Suma de los residuos igual a cero. Ventajas e inconvenientes\n\n\n\n\n\n\nPROS \n\nNinguna\n\n\n\nCONS \n\nDa un número infinito de soluciones (una de ellas coincide con el ajuste por mínimos cuadrados)\n\n\n\n\n\n\n\nMinimizando la suma del valor absoluto de los residuos\nSe trata de minimizar:\n\\[S=\\sum_{i=1}^n \\left| Y_i - (b_0 - b_1 X_i) \\right|= 0\\]\nPuede no tener solución única, pero los resultados posibles son mucho más razonables que en el caso anterior. Un problema específico de este caso es que no existen expresiones analíticas para los coeficientes debido a las dificultades en el manejo de la función “valor absoluto”.\nLa figura 13.5 muestra dos diagramas con los mismos 4 puntos y ñas rectas que cumplen el criterio estableciso, en todas ellas la suma del valor absoluto de los residuos es igual a 2. La línea azul, que es la misma en los dos diagramas, es la que también minimiza la suma de los cuadrados de los residuos.\n\n\n\nFigura 13.5: Posibles opciones para minimizar la suma de los residuos en valor absoluto.\n\n\n\n\nTabla 13.3: Suma de los residuos igual a cero. Ventajas e inconvenientes\n\n\n\n\n\n\nPROS \n\nPoco sensible a la presencia de valores anómalos\n\n\n\nCONS \n\nNo da un ajuste equilibrado entre todos los puntos\nNo existe expresión analítica para el cálculo de los coeficientes\n\n\n\n\n\n\n\n\nMinimizando la suma de los cuadrados de los residuos\nElevamos los residuos al cuadrado en vez de usar su valor absoluto para evitar que al sumarlos se compensen los positivos y negativos. Ahora se trata de minimizar:\n\\[S=\\sum_{i=1}^n \\left[ Y_i - (b_0 - b_1 X_i) \\right]^2= 0\\]\nEn vez de decir que el criterio de ajuste ha sido “minimizar la suma de los cuadrados de los residuos”, decimos que hemos ajustado por “mínimos cuadrados”. Este es el método usado en la inmensa mayoría de los casos, produce un ajuste equilibrado de la nube de puntos y está en perfecta sintonía con otras técnicas y medidas, que se contruyen en torno a criterios similares. Un inconveniente de este método de ajuste es que el modelo obtenido es sensible a la presencia de valores anómalos, cosa que no ocurre si se minimiza la suma de valores absolutos.\nEn la primera fila de la figura 13.6 tenemos una situación típica en que el ajuste por mínimos cuadrados da un mejor resultado que minimizando la suma del valor absoluto. Sin embargo, en la segunda fila tenemos un cado de puntos perfectamente alineados excepto un que muy probablemente sería un valor anómalo. Si minimizamos el valor aboluto de los residuos el ajuste ignora el valor anómalo mientras que ajustado por mínimos cuadrados el valor anómalo tiene una notable influencia sobre la recta ajustada.\n\n\n\nFigura 13.6: Ajustes obtenidos minimizando la suma de valores absolutos y la suma de los cuadrados de los residuos\n\n\n\n\nTabla 13.4: Minimizar la suma de los cuadrados de los residuos. Ventajas e inconvenientes\n\n\n\n\n\n\nPROS \n\nProporciona un ajuste muy razonable. El que queremos hacer cuando ajustamos a ojo.\nEncaja perfectamente con el resto de técnicas estadísticas que utilizamos.\n\n\n\nCONS \n\nLos valores anómales (errores o valores singulares) pueden tener bastante influencia sobre el modelo estimado. Hay que estar atentos para tratar esos puntos adecuadamente"
  },
  {
    "objectID": "01_queEs.html",
    "href": "01_queEs.html",
    "title": "¿Qué es la estadística?",
    "section": "",
    "text": "Estoy haciendo pruebas.\n\nEstadística y matemáticas\ntexto\n\n\nEstadística y probabilidad\ntexto\n\n\nEstadística y Data Science\ntexto",
    "crumbs": [
      "¿Qué es la estadística?"
    ]
  },
  {
    "objectID": "10_Parte_Descriptiva.html",
    "href": "10_Parte_Descriptiva.html",
    "title": "ESTADÍSTICA DESCRIPTIVA",
    "section": "",
    "text": "Captar la información que contienen los datos solo a base de irlos mirando es, desde luego, misión imposible. No hace falta que el conjunto sea muy grande, nuestra mente no es hábil haciendo esa tarea. Cuando miramos un número se nos olvida otro y no somos capaces –aunque nos cueste reconocerlo– de hacernos una idea clara de todos los aspectos relevantes.\nSí somos buenos detectando patrones y analizando imágenes –en esto somos incluso mejores que los ordenadores, que nos piden que interpretemos una imagen para confirmar que somos personas y no máquinas–, por lo que analizar los datos a través de represetanciones gráficas es una excelente forma de hacerlo.\nTambién podemos resumir los datos en unos pocos valores que den una buena visión de los aspectos que interesa conocer. Es lo que llamamos síntesis numérica.\nTanto representaciones gráficas como valores de síntesis numérica los hay de varios tipos. Existen gráficos que son adecuados para representar la evolución de una característica, otros para mostrar su dispersión o la relación entre variables. Respecto a la síntesis numérica hay medidas que fijan su atención en diferentes aspectos de los datos y no hay que olvidar que la variabilidad también es muy importante.\nEn el siguiente capítulo tratamos la síntesis numérica de datos dando un repaso a las medidas de uso más habitual. En el siguiente tratamos sobre tipos de gráficos, cuales conviene usar en cada caso y caules deben evitarse."
  },
  {
    "objectID": "11_sintesisNumerica.html#medidas-de-tendencia-central",
    "href": "11_sintesisNumerica.html#medidas-de-tendencia-central",
    "title": "1  Síntesis numérica de datos",
    "section": "",
    "text": "Media aritmética\nTanto el cálculo como el significado de la media aritmética son bien conocidos por los estudiantes. Además de que la idea es sencilla, su cálculo tiene interés para saber si se aprobará una asignatura a la vista de las notas del curso. [pretendo empezar con un toque de humor pero no sé si se entiende]\nCuando los datos se presentan tabulados no hay que olvidar que cada uno se repite tantas veces como indica su frecuencia absoluta. En la Tabla 1.1, la variable considerada es el número de hijos por familia (\\(x\\)) y el número de familias para cada uno de esos valores es la frecuencia absoluta (\\(n\\)).\n\n\n\nTabla 1.1: Número de hijos por familia\n\n\n\n\n\nNúmero de hijos (\\(x\\)):\n0\n1\n2\n3\n4\n5\n\n\nNúmero de familias (\\(n\\)):\n13\n21\n15\n8\n1\n2\n\n\n\n\n\n\nEl valor medio (\\(\\bar{x}\\)) del número de hijos por famila es igual a:\n\\[ \\bar{x} = \\frac{\\sum_{i} n_i \\, x_i }{N} \\:  = \\:  1,48 \\]\nDonde \\(N\\) es el número total de datos (en este caso \\(N=60\\)) e \\(i\\) es el índice que aquí va de 1 a 6 para valores de \\(x\\) de 0 a 5.\nPara cada valor de \\(x_i\\) su frecuencia relativa es \\(f_i = n_i/N\\). También podemos calcular la media usando la expresión:\n\\[ \\bar{x} = \\sum_{i} f_i \\, x_i   =  1,48 \\] Esta expresión es análoga a la de la esperanza matemática (solo hay que cambiar frecuencia relativa por probabilidad) que veremos más adelante,\n\n\n\nTabla 1.2: Ajuste a ojo. Ventajas e inconvenientes\n\n\n\n\n\n\n\n\n\nPROS \n\nMedida de tendencia central más conocida y utilizada.\nFácil de interpretar\n\n\n\nCONS \n\nMuy influenciable por valores extremos\nPoco representativa si la distribución es muy asimétrica\n\n\n\n\n\n\n\n\n\n\n\n\n\nOjo con la media\n\n\n\nLa media es un concepto tan fácil que a veces lo tratamos con descuido y nos da sorpresas. Si usted pregunta la edad a un grupo de personas, en rigor la edad media no es el promedio de los valores que le diagan (aunque todos digan la verdad). Es el promedio más 0,5 años.\nTambién hay que estar atento a las medias que no está claro como se han calculado. Un ejemplo sencillo: ¿cómo se calcula la temperatura media de un día? ¿Se toman cada minuto y se hace el promedio? ¿o se toman cada hora o cada 6 horas? Se se hace el promedio de las temperaturas máxima y mínima no se le debería llamar temperatura media.\n\n\n\n\nMediana\nSe ordenan los valores y el que queda en centro es la mediana. Si el número de valores es par se toma como mediana el promedio de los dos centrales.\nLa mediana tiene unas propiedades de las que carece la media, por lo que es un buen complemento informativo e incluso puede ser más útil en algunos casos. Sus ventajas respecto a la media son:\n\nEs más robusta frente a la presencia de valores anómalos. Supongamos que nuestros datos son:\n\\[2, \\, 5, \\, 6, \\,7 \\,\\text{ y  }\\, 9\\] La media es 5,6 y la mediana es 6. Si al introducir los datos al ordenador nos equivocamos y en último lugar en vez de 9 introducimos 99, la media pasa a ser 23,8 mientras que la mediana sigue siendo 6. Esto hace que la mediana sea útil cuando nos enfrentamos a un conjunto de datos que puede contener valores anómalos (posibles errores, problemas con la importación…) ya que da una idea menos contaminada por esos valores anomálos, del valor en torno al cual se mueven los datos.\nPor su propia definición, la mediana deja un 50% de las observaciones por debajo y otro 50% por encima y esto le da unas ventajas que la media no tiene. Si queremos saber si en nuestra empresa estamos entre los que cobran más o entre los que cobran menos, debemos comparar nuestro salario con la mediana, no con la media. Si sólo hay 10 trabajadores y los salarios son (en las unidades que corresponda):\n\\[8, \\, 8, \\, 9, \\,9, \\, 10, \\, 10, \\, 11, \\,11, \\, 12 \\,\\text{ y  }\\, 100\\] todos menos uno (en este caso el 90%) están por debajo de la media, que es 18,8. Esto no pasa nunca con la mediana: si estamos por encima de la mediana, estamos con el 50% de los que más cobra. Otro ejemplo. Si en un examen las notas van de 0 a 10 y se aprueba sacando una nota igual o superior a 5, si la nota media es 5 no sabemos cuántos han aprobado. Si se han examinado 50 estudiantes, puede ser que 41 hayan suspendido con un 4; 8 hayan sacado un 10 y uno haya obtenido un 6. Esto da media 5, aunque el 82 % ha suspendido. Si la mediana es 5, seguro que la mitad han aprobado.\n\nSi la distribución de los datos es simétrica, la media y la mediana coinciden y entonces todo son ventajas. Por ejemplo, en una distribución Normal la media y la mediana son iguales, por tanto, si los valores que tenemos provienen de una Normal, la media y la mediana no andarán muy lejos una de otra. En cualquier caso, siempre podemos calcular las dos y aprovechar lo mejor de cada una.\nSegún publicó el diario El País (El País, 2024), el ejecutivo de las empresas cotizadas en la bolsa española mejor pagado en 2023 tuvo unos ingresos de 23,77 millones de euros. Esta empresa tenía ese año 2299 empleados en España, suponiendo que ese ejecutivo formara parte de la plantilla y que todos menos él cobraran solo el salario mínimo (15.120 €/año), se podría decir que en promedio cobran 25.453 €/año, un 68 % más de lo que cobrarían todos menos uno. [no sé si poner este párrafo, quizá se podría poner ejercicio y que busquen los datos]\n\n\n\nTabla 1.3: Ajuste a ojo. Ventajas e inconvenientes\n\n\n\n\n\n\n\n\n\nPROS \n\nInsensible a la presencia de valores extremos.\nMuy útil cuando la distribución de los datos es muy asimétrica.\n\n\n\nCONS \n\nNo tiene fórmula. No la dan las calculadoras de uso académico.\nSu uso no está tan popularizado como el de la media.\n\n\n\n\n\n\n\n\n\nModa\nDado un conjunto de valores, la moda es el que más se repite. A difencia de la media y la mediana puede no ser única y se puede aplicar también a varibles cualitativas (no numéricas). Si realizamos sobre el método de transporte que usan los estudiantes para ir a su centro de estudio la moda puede ser el autobús o ir andando. No es una medida muy relevante. Siempre aparece en los libros pero rara vez en los resúmenes estadísticos.\n\n\n\nTabla 1.4: Ajuste a ojo. Ventajas e inconvenientes\n\n\n\n\n\n\n\n\n\nPROS \n\nTambién se puede aplicar a datos cualitativos.\n\n\n\nCONS \n\nEn general tiene poco interés práctico y es poco usada.\n\n\n\n\n\n\n\nA modo de resumen de este apartado, la figura 1.1 muestra la distribución de los salarios en España en 2021. Tiene dos “Salarios más frecuentes” (observe que se evita el término “moda”, quizá porque se puede prestar a malas interpretaciones). Cuando se da esta circunstancia se dice que la distribución es bimodal. El salario medio es mayor que el mediano porque los salarios muy altos tiran de la media pero apenas afectan a la mediana. \n\n\n\n\n\n\nFigura 1.1: Distribución de los salarios en España en 2021. (Fuente: INE 2023).",
    "crumbs": [
      "ESTADÍSTICA DESCRIPTIVA",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Síntesis numérica de datos</span>"
    ]
  },
  {
    "objectID": "11_sintesisNumerica.html#medidas-de-dispersión",
    "href": "11_sintesisNumerica.html#medidas-de-dispersión",
    "title": "1  Síntesis numérica de datos",
    "section": "1.2 Medidas de dispersión",
    "text": "1.2 Medidas de dispersión\nQuizá lo más importante de este capítulo -y de todo el libro- es interiorizar la importancia de considerar la variabilidad para para describir datos, para analizarlos y para tomar decisiones.\nTodos hemos oido algún chiste que ridiculiza esa interpretación de la realidad basada solo en valores medios (pero eso no es buena estadística!):\n\nSi un señor se come un pollo y otro no come nada la estadística lo explica diciendo que han comido un promedio de medio pollo cada uno.\nSi usted va a la cocina de su casa, pone la cabeza en el horno y los pies en el frigorífico tendrá el cuerpo a la temperatura media ideal.\nAunque no sabía nadar se atrevió a cruzar el rio cuando le dijeron que la profundidad media era solo de un metro. Se ahogó.\n\nEn ocasiones la práctica habitual no está muy alejada de esas caricaturas. Estamos acostumbrados a clasificar los países por su renta per cápita y eso es el medio pollo que se come cada uno. La variabilidad en la renta también es un excelente indicador del nivel de desarrollo y bienestar de un país. Un caso similar en un terreno que nos queda cercano son los resultados de las pruebas PISA, estamos acostumbrados a ver la clasificación de los valores medios por países pero apenas se habla de la variabilidad dentro de cada país.\nEn el ámbito de la ingeniría y del control de calidad, la variabilidad suele ser el enemigo más importante al que hay que enfrentarse. En general, en los análisis estadísticos hay que saber distinguir entre esa variabilidad de fondo, inevitable, que muchas veces denominamos “ruido” de lo que es una variación debida a una causa concreta que conviene identificar, lo que llamamos “señal”. En fin, lo primero será saber como medir la variabilidad. Vamos a repasar las medidas más habituales.\n\nRango\nEs la diferencia entre los valores máximo y mínimo. Si el rango de edades de los asistentes a un concierto es de 5 años significa que todos son de edades similares, pero si es de 50 años es que ese tipo de música interesa a personas de varias generaciones.\n\n\n\nTabla 1.5: Rango. Ventajas e inconvenientes\n\n\n\n\n\n\n\n\n\nPROS \n\nMuy fácil de entender y de calcular.\n\n\n\nCONS \n\nSolo cuentan los valores extremos, que pueden ser anómalos o no representativos del conjunto de datos\n\n\n\n\n\n\n\n\n\nDesviación media\nInteresa una medida de dispersión en la que todos los valores tengan algo que decir, tal como ocurre con la media aritmética. En esta línea, una medida de dispersión podría ser el promedio de las distancias de cada valor respecto a la media, Pero una de las propiedades de la media aritmética es que equibra esas distancias de manera que esa expresión siempre será igual a cero. No importa que hay mucha o poca dispersión, siempre vale lo mismo, por tanto, está claro que no sirve para nada.\nExisten dos formas de resolver ese problema. Una de ellas es usar las distancias en valor aboluto. En este caso tenemos lo que llamamos Distancia Media, que sí es una medida de variabilidad (a más variabilidad, mayor desviación media). Si nuestros valores son: \\(x_1,\\, x_2, \\, \\dotsc \\, x_N\\) y su valor medio es \\(\\bar{x}\\), tendremos:\n\\[ DM = \\frac{\\sum_{i=1}^N |x_i - \\bar{x}|}{N} \\] Es interesante observar que la distancia media está relacionada de forma más natural con la mediana que con la media aritmética. Consideremos la función:\n\\[ f(a) =  \\frac{\\sum_{i=1}^N |x_i -a|}{N} \\] Como la distancia promedio solo depende de \\(a\\) le hemos llamado \\(f(a)\\). El valor que minimiza esta función y que, por tanto, puede considerarse el mejor representate de los datos con el criterio aplicado no es la media sinó la mediana.\nLa otra forma de resolver el problema de la anulación de las diferencias es elevándolas al cuadrado. Parece una complicación innecesaria pero tiene muchas ventajas, es lo que llamamos varianza.\n\n\n\nTabla 1.6: Desviación media. Ventajas e inconvenientes\n\n\n\n\n\n\n\n\n\nPROS \n\nFácil de explicar y de justificar.\n\n\n\nCONS \n\nTiene poco recorrido en la teoría estadística\nExiste otra medida –la desviación típica– con más posibilidades de aplicación y mejores propiedades\n\n\n\n\n\n\n\n\n\nVarianza\n\n\n\n\n\n\n¿Varianza o variancia?\n\n\n\nLas dos son válidas según el diccionario de la Real Academia Española. Nosotros usaremos varianza.\n\n\nSimplemente elevamos las diferencias al cuadrado en vez de usar su valor absoluto. Si tenemos un conjunto de \\(N\\) datos con media \\(\\mu\\) y queremos conocer la varianza de esos datos1 usamos la expresión:\n\\[ \\sigma^2 = \\frac{\\sum_{i=1}^N ( x_i - \\mu )^2}{N} \\] Repitiendo el análisis que hemos hecho para la \\(DM\\), vamos a elegir el valor de \\(a\\) que minimiza la función:\n\\[g(a) =  \\frac{\\sum_{i=1}^N ( x_i - a )^2}{N} \\] En este caso lo podemos deducir derivando \\(g(a)\\) con respecto a \\(a\\), igualando a cero y despejando su valor. Veamos:\n\\[\\frac{\\partial g(a)}{\\partial a} = \\frac{-2}{N} \\sum_{i=1}^{N}(x_i-a) = 0\\]\nPor tanto \\(\\sum_{i=1}^{N}(x_i-a) = 0\\), de donde se deduce que \\(\\sum x_i =N \\cdot a\\) y despejando \\(a\\) tenemos:\n\\[a = \\sum_{i=1}^{N} \\frac{x_i}{N} \\]\nEn este caso el valor de \\(a\\) sí coincide con la media aritmética (le llamamos \\(\\mu\\)). Si hacemos la segunda derivada vemos que siempre es positiva, lo cual confirma que el punto crítico es \\(a=\\mu\\) y que el valor mínimo de \\(g(a)\\) es la varianza de \\(X\\).\nEl principal problema de la varianza es que sus unidades son el cuadrado de las unidades de los datos. Esto dificulta su interpretación pero este problema se resuelve fácilmente usando como medida su raiz cuadrada, es lo que llamamos desviación típica\n\n¿Por qué se prefiere usar la varianza en vez de la distancia media?\nElevar al cuadrado las diferencias pudiendo trabajar con su valor absoluto parece una complicación innecesaria, pero la varianza tienes unas ventajas que la \\(DM\\) no tiene, veamos algunas:\n\nEn los desarrollos anteriores hemos visto que la media, medida descriptiva por excelencia, está asociada de forma más natural con la varianza que con la \\(DM\\).\nLa \\(DM\\) incluye en su expresión la función “valor absoluto” que se comporta mal desde un punto de vista matemático, mientras que la función cuadrática es muy fácilmente tratable. Observe, por ejemplo, que la demostración de que la media hace mínimo el promedio de los cuadrados se ha realizado de forma casi inmediata, mientras que probar que la mediana hace mínima la media de las distancias es bastante más complejo.\nLa varianza es una suma de cuadrados que se puede descomponer en diversos sumandos dando origen al llamado ``Análisis de la Varianza’’. El desarrollo de la teoría de los modelos lineales está basado en gran parte en el criterio de los mínimos cuadrados, que es el mismo en que está basada la varianza. Cuando la población origen de los datos es Normal, el cociente de varianzas muestrales sigue una distribución conocida, llamada \\(F\\) de Snedecor.\nLa varianza de una suma de variables aleatorias se calcula de una forma muy fácil, especialmente si las variables son independientes. Por ejemplo, en un proceso de envasado, si el peso del envase tiene una varianza \\(V(X)\\) y la varianza del contenido es \\(V(Y)\\), la varianza del conjunto es \\(V(X+Y) = V(X) + V(Y)\\).\nLa raiz cuadrada de la varianza –la desviación típica– es uno de los parámetros que definen la distribución Normal (el otro es la media). Esto posibilita la construcción de intervalos de confianza para estimar, por ejemplo, la media de la población, lo que sería mucho más complejo si se usara la \\(DM\\).\n\n\n\n¿Se divide por \\(n\\) o por \\(n-1\\)?\nCuando tenemos un conjunto de datos y nos interesa conocer la varianza de esos datos dividimos por el número de los que tenemos, pero aunque esta parece la situación más habitual, no es así. Lo habitual es que nuestro interés no sea tanto conocer la varianza de los datos dispobles como estimar la varianza de la población de la cual provienen y de la que solo tenemos unos representantes.\nEn este caso tampoco se conoce la media de la población de manera que debemos sustituir su valor por la media de la muestra (\\(\\bar{x}\\)). Esta sustitución tiene más influencia de la que parece ya que la media de de la muestra se adapta a los datos con los que se calcula y la variabilidad obtenida tiende a subestimar la varianza de la población. Puede demostrarse que se si en vez de dividir por el número de datos \\(n\\) (al número de elementos de la muestra le llamamos \\(n\\) minúscula) se divide por \\(n-1\\) esa subestimación –se llama sesgo– ya no se da. Por tanto, la fórmula que usamos en la práctica es:\n\\[ s^2 = \\frac{\\sum_{i=1}^n ( x_i - \\bar{x})^2}{n-1} \\]\nEsta corrección es especialmente importante cuando se tienen muestras pequeñas ya que puede haber una diferencia importante entre dividir por \\(n\\) o hacerlo por \\(n-1\\).\n\n\n\n\n\n\nCálculo de la varianza con calculadora u ordenador\n\n\n\nEn algunas calculadoras y en hojas de cálculo como Excel, existen las dos opciones para calcular la varianza: dividiendo por \\(N\\) o por \\(n-1\\) según se tenga una población o una muestra. En los paquetes de software estadístico cuando se piede la varianza siempre la dan dividiendo por \\(n-1\\) porque en la práctica siempre tenemos muestras. Si en algún caso interesa conocer el valor dividiendo por \\(n\\) el truco consiste en añadir la media como un dato más.\n\n\nComo este tema puede ser controvertido, le dedicamos un apéndice que profundiza en este tema sin abandonar la visión intuitiva.\n\n\n\nTabla 1.7: Varianza. Ventajas e inconvenientes\n\n\n\n\n\n\n\n\n\nPROS \n\nExcelentes propiedades que no tiene ninguna otra medida. |\nConstituye uno de los ejes centrales de muchos métodos estadísticos.\n\n\n\nCONS \n\nSus unidades son el cuadrado de las unidades de los datos, lo que dificulta su interpretación.\n\n\n\n\n\n\n\n\n\n\nDesviación típica\n\n\n\n\n\n\nOtros nombres para la desviación típica\n\n\n\nTambién se puede llamar desviación estándar, pero no de otra manera, aunque algunos textos se refieren a ella como desviación tipo o desvío típico.\n\n\nEs la raiz cuadrada de la varianza. En el caso más habitual de tener una muestra:\n\\[s = \\sqrt {\\frac{\\sum_{i=1}^n ( x_i - \\bar{x} )^2}{n-1}}\\]\nLa raiz cuadrada hace que sus unidades sean las mismas que las de los datos. El precio a pagar es la pérdida de las propiedades algebraicas que tiene la varianza, por lo que en los desarrollos teóricos en muy habitual que el protagonismo lo tenga esta última.\nEntre los muchos méritos de la desviación típica podemos decir que, junto con la media, forman una pareja perfecta para describir el comportamiento de muchas variables aleatorias. En particular, forman parte del “ADN” de la distribución Normal. Si una variable sigue esta distribución basta conocer su media y su desviación típica para calcular cualquier probabilidad relacionada con los valores que puede tomar. Si el peso de unos paquetes de azúcar sigue una distribución Normal con una media de 1000 g y una desviación típica de 15 g, podemos decir que –en números redondos– el 95% de los paquetes tendrán un peso comprendido entre 970 y 1030 g, y también podemos decir que el 68% tendrá un peso comprendido entre 985 y 1015. Además, podríamos responder cualquier pregunta similar, por ejemplo qué porcentaje de paquetes tendrá un peso por debajo de 980 g (será el 9%).\nTambién destaca su presencia en la estimación del valor de la media poblacional \\(\\mu\\). Lo hacemos tomando una muestra de tamaño \\(n\\) y calculando su media \\(\\bar{x}\\). El problema es que cada vez que tomemos una muestra, el valor de \\(\\bar{x}\\) cambiará, así que mejor que apostar por un valor concreto preferimos dar un intervalo de valores razonables para \\(\\mu\\). Para calcular ese intervalo necesitamos conocer la variabilidad que presentan los valores de \\(\\bar{x}\\). Pues bien, la desviación típica de \\(\\bar{x}\\) siempre es igual a la desviación típica de la población dividida por \\(\\sqrt{n}\\). Esto es verdad para todas las distribuciones, no solo para la Normal.\nEn definitiva, la desviación típica aparece en muchos contextos y con mucha relevancia. El calificativo ``típica’’ resulta en este caso apropiado y bien merecido.\n\n\n\n\n\n\n¿Qué desviación típica tienen las estaturas?\n\n\n\nSi un extraterrestre le pregunta como somos los terrícolas usted le puede decir que nuestra estatura media es de aproximadamente 1,70, pero solo con esa información el extraterrestre puede pensar que hay terrícolas de 40 cm y también de 3 m. Le podría decir que casi todos estamos entre 1,40 y 2 m, por poner números redondos, pero ¿y si le quiere dar la desviación típica?\nSi una variable sigue una distribución Normal –y la estatura podemos considerar que la sigue– se dan unas proporciones que siempre son las mismas, no importa si estamos hablando de estaturas, del peso de paquetes de azúcar o de las longitudes de los pétalos de un determinado tipo de flor. Estas proporciones son:\n\\[\\mu \\pm \\sigma: \\;\\; 68\\, \\%\\]\n\\[\\mu \\pm 2 \\sigma: \\;\\; 95\\, \\%\\]\n\\[\\mu \\pm 3 \\sigma: \\;\\; 99,7\\, \\%\\]\nDando por bueno 1,70 m como valor de la media y fijándonos en el intervalor \\(\\mu \\pm 3 \\sigma\\) ¿qué valor de la estutura será superado por el 1-2 por mil de los individuos? (el 3 por mil que queda fuera del intervalo lo repartimos entre los dos extremos). Si ese valor es 1,91 m la desviación típica será 7 cm. (1,70 + 3·0,07 = 1,91)\n\n\n\n\n\nTabla 1.8: Desviación típica. Ventajas e inconvenientes\n\n\n\n\n\n\n\n\n\nPROS \n\nEs la medida de dispersión más utilizada.\nCon la media forman una pareja perfecta. Son los parámetros que definen la distribución Normal.\n\n\n\nCONS \n\nMalas propiedades algebraicas.\nSu interpretación no es intuitiva.\n\n\n\n\n\n\n\n\n\nEl coeficiente de variación\nSuponga que tiene delante 4 gatos con los siguientes pesos: 1,5; 2,0; 6,0; 6,5 kg. Y ahora piense en 4 vacas cuyos pesos son: 490, 495, 505, 510 kg. ¿En que grupo de animales hay más variabilidad? Seguramente pensará que en el del los gatos, donde uno pesa más 4 veces más que otro, sin embargo verá las vacas practicamente iguales. Pero si calcula las desviaciones típicas obtendrá:\n\\[ s_{gatos} = 2,61\\, kg\\] \\[ s_{vacas} = 9,13\\, kg\\] Es mayor la desviación típica del peso de las vacas. Esto es así porque las diferencias respecto a la media (4 en el caso de los gatos y 500 en el de las vacas) son para los gatos: 2,5; 2,0; 2,0; 2,5 y para las vacas: 10, 5, 5, 10. Como estas diferencia son mayores en el caso de las vacas, su desviación típica es mayor.\nEn un caso como este lo que interesa es la variabilidad respecto a la media, y para esto usamos el coeficiente de variación \\(CV\\) que se define como:\n\\[CV = \\frac{s}{\\bar{x}}\\] Con frecuentcia ese valor se multiplica por 100 para darlo como porcentaje. Ennuestro ejemplo, para los gatos tenemos un \\(CV\\) del 65,35% mientras que para las vacas es solo del 1,83%.\nPara comaprar la variabilidad de conjuntos de datos con valores medios muy disitntos es mejor utilizar el coeficiente de variación.\n\n\n\nTabla 1.9: Coeficiente de variación. Ventajas e inconvenientes\n\n\n\n\n\n\n\n\n\nPROS \n\nPermite interpretar la variabilidad en el contexto del nivel de respuesta (valor medio)\nEs adimensional. Permite comparar situaciones medidas con diferentes unidades\n\n\n\nCONS \n\nTiene poco juego en la descripción de variables aleatorias y en de la estimación de característica de la población",
    "crumbs": [
      "ESTADÍSTICA DESCRIPTIVA",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Síntesis numérica de datos</span>"
    ]
  },
  {
    "objectID": "11_sintesisNumerica.html#medidas-de-posición",
    "href": "11_sintesisNumerica.html#medidas-de-posición",
    "title": "1  Síntesis numérica de datos",
    "section": "1.3 Medidas de posición",
    "text": "1.3 Medidas de posición\nSirven para establecer unas parcas que delimitan zonas en el conjunto de los datos. Así, dado un valor se sabe a qué zona pertenerce, si está entre los mayores o entre los menores.\n\nCuartiles\nOrdenados los datos de menor a mayor, la mediana es el que los separa en dos mitades. Pues bien, el primer cuartil (Q1) es la mediana de la primera mitad dejando, por tanto, el 25% de valores por debajo y el 75% por encima. La mediana de la segunda mitad es el tercer cuartil (Q3), que deja el 75% por debajo y el 25% por encima (figura 1.2).\n\n\n\n\n\n\nFigura 1.2: Esquema de obtención de la mediana y los cuartiles en un conjunto de 30 datos ===pensar en poner color y en mejorar visualmente===\n\n\n\nSi usted conoce la mediana y los cuartiles de los salarios de su empresa, puede posicionar facilmente el suyo. Si Q1 = 1.300€, la mediana 1.500€ y Q3 = 1.800€, si usted cobra 1.400€ está entre el 25% que menos gana. Si su salario es de 1.600€ está en entre la mitad de los que más ganan pero como mínimo el 25% de los empleados gana más que usted. Si cobra 2.000€ está entre el 25% de privilegiados que más ganan.\nUna forma fácil de determinar el valor de los cuartiles consiste en calcular primero su posición y después su valor. Si los datos son (ya los hemos ordenado):\n\\[2, \\; 3, \\; 5, \\; 7, \\; 8, \\; 13, \\; 14, \\; 16\\]\nDeterminamos las posiciones mediante las expresiones:\n\\[P_{Q_1} = 0.25(n+1)\\] \\[P_{Q_3} = 0.75(n+1)\\]\nComo en este caso \\(n=8\\) tenemos que \\(P_{Q_1} = 2.25\\) y \\(P_{Q_3} = 6.75\\)\nComo las posiciones son números decimales, siendo \\(x_k\\) es el valor en la posición \\(k\\), interpolamos de la forma:\n\\[Q_1 = x_2 + 0.25(x_3 - x_2) = 3 + 0,25(5-3) = 3.5\\] \\[Q_3 = x_6 + 0.75(x_7 - x_6) = 13 + 0,75(14-13) = 13.75\\] Existen otras formas de determinar el valor de los cuartiles y no todas dan exactamente el mismo resultado (para sorpresa y preocupación…).\nPor ejemplo, Excel dispone de la función CUARTIL que identifica la posición de los cuartiles mediante las expresiones: (0,25(n-1)+1) y (0,75(n-1)+1) y los calcula interpolando igual que hace Minitab. Seguramente no satisfechos con su forma de identificar los cuartiles, en las últimas versiones se ha mantenido esa función (se indica que por compatibilidad con versiones anteriores) y se han añadido:\n\nCUARTIL.INC: Coincide con la función CUARTIL.\nCUARTIL.EXC: Identifica los cuartiles de la misma forma que Minitab.\n\nEn la figura 1.3 se muestran los cuartiles de nuestros datos con las funciones de Excel (versión 2019).\n\n\n\n\n\n\nFigura 1.3: Cálculo de los cuartiles con Excel\n\n\n\nOtros criterios para calcular los cuartiles pueden verse en Wolfram MathWorld y también la Wikipedia. Esta diversidad de criterios que además dan resultados distintos desconcierta a los estudiantes. En realidad el problema no es grave porque los cuartiles nos interesan cuando tenemos muchos datos o para describir poblaciones, nunca con tan pocos datos como en nuestros ejemplo. Con muchos datos, las dieferencias entre los valores obtenidos con los diferentes criterios no son relevantes a efectos prácticos.\n\n\n\n\n\n\nLos cuartiles como zona\n\n\n\nAunque un cuartil es un número y no una zona, a veces se dice que un valor pertenece al primer o al tercer cuartil y lo que eso significa no siempre está claro. Podria pensarse que pertenecer al primer cuartil significa que es menor que \\(Q_1\\) y que pertenece al tercero cuando es mayor que la mediana y menor que \\(Q_3\\), pero no siempre es así. La relevancia de las revistas científicas se mide por su “factor de impacto”, un valor relacionado con el número de citas que tienen los artículos que publican. Para cada ámbito de conocimiento se realizan rankings de revistas según su factor de impacto y todos queremos publicar en las que lo tienen más alto, que no son las del cuarto, seguido por las del tercer cuartil, sino en del primero y el segundo. El ranking se hace de más a menos.\n\n\n\n\nPercentiles\nSe usan para identificar la posición de un valor en el conjunto al que pertenece. Si la estatura de un niño está en el percentil del 46% significa que el 46% de aquellos con los que se comparara (los de su edad y sexo) tienen una estatura menor que la suya, el 54% la tienen más mayor.\nEn un test de inteligencia o de otras habilidades, o en concursos de matemáticas a los que se presentan muchos estudiantes, se informa mejor del resultado obtenido dando el percentil en el que se ha quedado que dando una nota, especialmente si no está clara la escala que se usa ni si es fácil o difícil obtener notas altas. Si se dice que ha quedado en el percentil del 98% está claro que su puntución ha sido muy buena ya que solo ha sido superada por el 2%.\nTambién en la valoración de méritos para la admisión en cursos de postgrado, muchas universidades están más interesadas por el percentil en que quedó el aspirante entre los de su promoción en los estudios de grado que en las calificciones obtenidas, dificilmente comparables entre varios tipos de estudio y distintas universidades.\nAl igual que ocurre con los cuartiles, existen diferentes criterios para determinar los percentiles. Una forma sencilla y razonable es identificar primero su posición mediante la expresión \\(p(N+1)\\) siendo \\(p\\) el percentil en escala de 0 a 1 y \\(N\\) el número total de datos y si es. un número decimal interpolar tal como hemos hecho con los cuartiles.\n\n\n\n\n\n\nDeciles\n\n\n\nSon los percentiles del 10, 20,… , 100%",
    "crumbs": [
      "ESTADÍSTICA DESCRIPTIVA",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Síntesis numérica de datos</span>"
    ]
  },
  {
    "objectID": "11_sintesisNumerica.html#porcentajes",
    "href": "11_sintesisNumerica.html#porcentajes",
    "title": "1  Síntesis numérica de datos",
    "section": "1.4 Porcentajes",
    "text": "1.4 Porcentajes\nMuchas veces son preferibles a los valores absolutos aunque tampoco hay que olvidar estos últimos. Después de una negociación laboral se puede decir que los salarios han aumentado 0,5 €/hora o que la masa salarial aumentará 2 millones de euros. Si se dice que los salarios aumentarán un 5% queda todo más claro.\nSe utilizan mucho para dar y también para resumir información numéricaQuizá porque parecen simples y no hay mucho que decir sobre ellos no forman parte del elenco de medidas estadísticas. Sin embargo, conviene tenerlos presentes por su utilidad para describir datos y también porque a veces se se prestan a confusiones y malas interpretaciones.\n\nCálculo de procentajes\n\nEl porcentaje siempre se debe referir al valor inicial. Si el año pasado las naranjas costaban 4 €/kg y este año cuestan 5, su precio ha aumentado un 25%. Si pasa de 5 a 2 habrá disminuido un 20%. Observe que no hay simetría al aumentar y disminuir.\nLas operaciones con porcentajes no son triviales. Hacer un 50% de descuento y después otro 20% no es lo mismo que hacer el 70%. Si el valor inicial era 100€, con el 50% de descuento queda en 50€ y al hacer el 20% sobre esa cantidad queda 40. Si hubiéramos hemos el 70% de descuento el precio final sería de 30€. A veces se dan situaciones paradójicas: si usted está vendiendo al mismo precio que la competencia puede hacer un 33% de descuento y decir que la competencia está vendiendo un 50% más caro.\n\n\n\n\n\n\n\nParadoja de las patatas\n\n\n\nSupongamos que tenemos 100 kg de patatas cuyo peso está compuesto por agua en un 99%. Con el paso del tiempo las patatas pierden humedad ¿Cuanto pesarán cuando el porcentaje de humedad sea del 98%? En la Wikipedia puede ver si si sus calculos són correctos.\n\n\n\n\nPorcentajes y puntos porcentuales\nSi los beneficios han pasado del 2 al 4% de la facturación, si esta se ha mantedo constante no han aumentado un\n\n\n\n\n\n\nParadoja de Simpson\n\n\n\nUna empresa crea 250 nuevos puestos de trabajo en sus departamentos de comparas, fabricación y ventas. En total se presentan 355 hombres y 325 mujres de los cuales son admitidos 190 hombres (el 53,5%) y solo 60 mujeres (el 18,5%). Se comprueba que el nivel de preparación de hombres y mujeres es similar entre los aspirantes a cada departamento. ¿Podemos asegurar que se ha discriminado a las mujeres? La respuesta es no. Los datos son los siguientes:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDepartamento\nPlazas\nAspirantes - Admitidos\nHombres               Mujeres\n% Admitidos\nHombres               Mujeres\n\n\nCompras\nFabricación\nVentas\n\n30\n200\n20\n25 - 5\n250 - 180\n80 - 5\n100 - 25\n25 - 20\n200 - 15\n20 %\n72 %\n6,25 %\n25 %\n80 %\n7,5 %\n\n\nTOTAL\n250\n355 - 190\n325 - 60\n53,5 %\n18,5 %\n\n\n\n\n \nEn realidad han sido las mujeres las quehan tenido maor proporción de admitidos en los tres departamentos. La clave está en que al departamento que ofrece más plazas se han presentado muchos hombres y pocas mujeres, mientras que ocurre lo contrario en los departamentos en que se ofrecen menos plazas.",
    "crumbs": [
      "ESTADÍSTICA DESCRIPTIVA",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Síntesis numérica de datos</span>"
    ]
  },
  {
    "objectID": "12_graficos.html",
    "href": "12_graficos.html",
    "title": "2  Representaciones gráficas",
    "section": "",
    "text": "2.1 Forma de la distribución, valro central y dispersión\nEl tipo de gráfico que hemos usado para analizar los datos de la panadería",
    "crumbs": [
      "ESTADÍSTICA DESCRIPTIVA",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Representaciones gráficas</span>"
    ]
  },
  {
    "objectID": "20_Parte_Variabilidad.html",
    "href": "20_Parte_Variabilidad.html",
    "title": "SOBRE LA VARIABILIDAD",
    "section": "",
    "text": "Importancia de saberse mover en un contexto de variabilidad. No todas las variabilidades son iguales.\nEstoy pensando en empezar planteando el tema de la fecha de nacimiento de los futbolistas profesionales y a partir de ahí introducir la distribución binomial y su utilidad para separar señal y ruido.\nSiguiendo con el mundo de futbol, podría introducir la distribución de Poisson con el ejemplo del número de goles por partido.\nLa distribución Normal se puede introducir como límite de histograma. También partiendo de la distribución Normal.\nNo creo que -al menos aquí- haya que hablar de distribuciones de referencia teóricas: t-Student, Chi-cuadrado, F de Snededor."
  },
  {
    "objectID": "32_estimacionMedias.html",
    "href": "32_estimacionMedias.html",
    "title": "6  Estimación de medias",
    "section": "",
    "text": "Similar a estimación de proporciones."
  },
  {
    "objectID": "31_estimacionProporciones.html",
    "href": "31_estimacionProporciones.html",
    "title": "5  Estimación de proporciones",
    "section": "",
    "text": "Lo típico. Libro de respuestas.\nAnexo sobre sondeos electorales.\nComo hacer una pregunta indiscreta: Se pueden hacer preguntas de manera que ni el que recibe la respuesta sepa cual es esta."
  },
  {
    "objectID": "21_variablesAleatorias.html",
    "href": "21_variablesAleatorias.html",
    "title": "3  Variables aleatorias",
    "section": "",
    "text": "Importancia, tipos, propiedades."
  },
  {
    "objectID": "22_distribucionesProbabilidad.html",
    "href": "22_distribucionesProbabilidad.html",
    "title": "4  Distribuciones de probabilidad",
    "section": "",
    "text": "Binomial, Poisson, Normal, otras (uniforme, equiprobable, curiosidades: unif+unif = triangular)"
  },
  {
    "objectID": "30_Parte_Estimacion.html",
    "href": "30_Parte_Estimacion.html",
    "title": "ESTIMACIÓN",
    "section": "",
    "text": "Lo típico. Como estimar las características de una población a partir de los datos de una muestra.\nPropiedades que deseamos tener en los estimadores\nEstimación de proporciones. Intervalo de confianza, margen de error, etc.\nEstimación de medias\nEstimación del tamaño de una población (peces y taxis)\nAnexo: Sondeos electorales."
  },
  {
    "objectID": "33_estimacionTamañoPoblacion.html",
    "href": "33_estimacionTamañoPoblacion.html",
    "title": "7  Estimación del tamaño de la población",
    "section": "",
    "text": "Peces y taxis."
  },
  {
    "objectID": "40_Parte_Contraste.html",
    "href": "40_Parte_Contraste.html",
    "title": "CONTRASTE DE HIPÓTESIS",
    "section": "",
    "text": "No tengo claros los detalles de lo que habría que poner aquí.\nLas ideas clave están en el libro de Preguntas Frecuentes."
  },
  {
    "objectID": "50_Parte_Experimentos.html",
    "href": "50_Parte_Experimentos.html",
    "title": "DISEÑO DE EXPERIMENTOS",
    "section": "",
    "text": "Anécdota de la catadora de te.\nCreo que un capítulo en torno a las flores y la Aspirina y otro en torno a la duración de pilas caras y baratas."
  },
  {
    "objectID": "60_Parte_Corre_Regre.html",
    "href": "60_Parte_Corre_Regre.html",
    "title": "CORRELACIÓN Y REGRESIÓN",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n\nCódigo\n1 + 1\n\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. «Literate Programming». Comput. J. 27 (2): 97-111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "61_correlacion.html",
    "href": "61_correlacion.html",
    "title": "13  Medidas de relación lineal",
    "section": "",
    "text": "13.1 Observación y cuantificación de la relación\nVeamos los cuatro casos de la figura 13.2. El primero muestra la relación entre la presión atmosférica (en pulgadas de Hg) y la temperatura de ebullición del agua (en ºF). Los datos fueron tomados por el botánico Joseph D. Hookeren en distintos puntos de la cordillera del Himalaya a mediados del siglo XIX. Si la presión atmosférica, y a partir de ella la altitud, se podían evaluar a partir de la temperatura de ebullición del agua (muy fácil de medir) se podía evitar el uso de los frágiles y difíciles de transportar barómetros de la época. Fue un éxito, porque entre las dos variables se observa una relación casi perfecta.\nEl diagrama 2 muestra la relación entre la longitud de la circunferencia de los troncos de un determinado tipo de árbol y el volumen de madera que se puede obtener de ellos (Ryan, Joiner, y Ryan 1976). Se observa una estrecha relación entre ambas variables. El diagrama 3 se ha obtenido con datos de esos mismos árboles pero representa el volumen de madera en función de la altura del arbol. En este caso también se observa una relación, pero no tan clara como en el caso anterior.\nFinalmente, el diagrama 4 se ha realizado con los datos de un estudio publicado por Wilson y Mather (1974) citado por Draper y Smith (1998) donde se analiza la relación entre la edad al morir y la longitud de cierta línea de la mano a partir de una muestra de 50 personas fallecidas. A la vista del diagrama queda claro que no hay ninguna relación entre ambas variables.\nAunque la información fundamental queda reflejada en el diagrama bivariante, cuando a la vista del gráfico la relación es dudosa, o cuando interesa cuantificar la relación observada, disponemos de medidas de relación lineal. Las dos de uso más habitual son la covarianza y el coeficiente de correlación, mucho más esta última por las razones que veremos a continuación.",
    "crumbs": [
      "CORRELACIÓN Y REGRESIÓN",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Medidas de relación lineal</span>"
    ]
  },
  {
    "objectID": "61_correlacion.html#observación-y-cuantificación-de-la-relación",
    "href": "61_correlacion.html#observación-y-cuantificación-de-la-relación",
    "title": "13  Medidas de relación lineal",
    "section": "",
    "text": "Figura 13.2: Cuatro situaciones que muestran diferentes grados de relación\n\n\n\n\n\n\n\n\n\n\nNotación usada\n\n\n\nPara la covarianza no tenemos un símbolo específico. Cuando nos referimos a modelos teóricos, o a nivel poblacional, escribimos \\(\\text{Cov}(X,Y)\\). Para el valor calculado a partir de unos datos concretos (una muestra) escribimos \\(\\widehat{\\text{Cov}}(X,Y)\\) colocando un “sombrero” encima de \\(\\text{Cov}\\) para indicar que se trata de un estimador. Para el coeficiente de correlación utilizamos la regla general de asignar una letra latina al valor en la muestra, en este caso \\(r\\) y la letra griega correspondiente, \\(\\rho\\), para la población.",
    "crumbs": [
      "CORRELACIÓN Y REGRESIÓN",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Medidas de relación lineal</span>"
    ]
  },
  {
    "objectID": "61_correlacion.html#covarianza",
    "href": "61_correlacion.html#covarianza",
    "title": "13  Medidas de relación lineal",
    "section": "13.2 Covarianza",
    "text": "13.2 Covarianza\nAparece como en las calculadoras con funciones estadísticas, en los paquetes de software y también en las hojas de cálculo, aunque en la práctica resulta poco útil como medida de relación lineal. Aquí la incluimos porque su expresión es fácil de justificar y ayuda a entender la fórmula del coeficiente de correlación.\n\nDeducción de la fórmula\nLa figura 13.3 muestra la relación entre dos variables \\(X\\) e \\(Y\\). En la derecha el diagrama se ha dividido en cuatro cuadrantes trazando una línea vertical que pasa por la media de los valores de \\(X\\) y una horizontal por la media de los valores de \\(Y\\). A estos valores medios los designamos \\(\\bar{x}\\) e \\(\\bar{y}\\) respectivamente. Los cuadrantes van del I al IV en el sentido de las agujas del reloj.\n\n\n\n\n\n\nFigura 13.3: Deducción de la fórmula de la covarianza\n\n\n\nEn todos los puntos del primer cuadrante la distancia \\(x - \\bar{x}\\) es positiva, ya que todos se encuentran a la derecha de \\(\\bar{x}\\). También será positiva la distancia \\(y - \\bar{y}\\) ya que todos están por encima de \\(\\bar{y}\\). Por tanto, el producto de ambas distancias \\((x - \\bar{x})(y - \\bar{y})\\) será positivo para todos los puntos que se hayan en el primer cuadrante.\nPara los del segundo cuadrante este producto es negativo ya que la distancia \\(x - \\bar{x}\\) sigue siendo positiva (todos los puntos se encuentran a la derecha de \\(\\bar{x}\\)), pero \\(y - \\bar{y}\\) será negativo (todos están por debajo de \\(\\bar{y}\\)).\nEn el tercer cuadrante el producto de las distancias es positivo porque ambas distancias son negativas y en el cuarto vuelve a ser negativo ya que \\(y - \\bar{y}\\) es positivo pero \\(x - \\bar{x}\\) es negativo.\nCon \\(n\\) puntos, la suma de todos estos productos será \\(\\sum_{i=1}^{n} (x_i -\\bar {x})(y_i -\\bar {y})\\). Si la mayoría se encuentra en los cuadrantes I y III, tal como ocurre en la figura 13.3, el resultado del sumatorio será un valor positivo, mientras que si están en los cuadrantes II y IV el resultado será negativo. Si no existe ninguna relación entre \\(X\\) e \\(Y\\) los puntos se repartiran de forma más menos equilibrada, tendiendo a compensarse los productos positivos con los negativos y dando un resultado alrededor de cero.\nLa covarianza es el valor de ese sumatorio dividido por el número de puntos que intervienen en su cálculo, algo así como el promedio de los productos \\((x_i -\\bar {x})(y_i -\\bar {y})\\). Si nuestro interés no es conocer la covarianza de los datos disponibles, sino estimar su valor en la población, dividimos por \\(n-1\\) en vez de por \\(n\\), por la misma razón que lo hacemos cuando estimamos el valor de la varianza. Como lo habitual es esto último, escribimos la fórmula de la forma:\n\\[ \\widehat{\\text{Cov}}(X,Y) = \\frac{\\sum_{i=1}^{n} (x_i -\\bar {x})(y_i -\\bar {y})}{n-1} \\]\n\n\nPropiedades\nLa covarianza tiene un gran protagonismo en el terreno de los modelos teóricos, pero apenas se usa para valorar la relación lineal en un conjunto de datos. Para este menester tiene el inconveniente de que su valor depende de las unidades utilizadas.\nSi se calcula la covarianza entre la estatura de madres e hijas con los datos representados en la figura 13.1 cuyas unidadess son pulgadas (in) se obtiene un valor de 3,005 in2. Sin embargo, si cambiamos las unidades a cm (1 pulgada = 2,54 cm) el gráfico tiene el mismo aspecto y el grado de relación sigue siendo exactamente el mismo, pero ahora el valor obtenido es 19,39 cm2, y si las estaturas se expresan en metros tenemos que la covarianza es igual a 0,0019 m2.\nPor otra parte, para su valoración no tenemos ningún marco de referencia que nos permita evaluar si el valor obtenido es grande o pequeño. Todos estos problemas quedan resueltos con el uso del coeficiente de correlación.\n\n\n\n\n\n\nMalas noticias para la covarianza\n\n\n\nDados unos valores de \\(X\\), la máxima covarianza no se obtiene cuando los valores de \\(Y\\) se alinean según una recta. Por ejemplo, sean los valores de \\(X\\) = 1, 2, 3, 4 y 5, si los de \\(Y\\) son: 2, 4, 6, 8, y 10 (relación lineal perfecta) la covarianza entre \\(X\\) e \\(Y\\) es igual a 5 pero si sustuimos el último 10 por 15, la covarianza aumenta y pasa a valer 7,5. Esto no deja en muy buen lugar a la covarianza como medida de relación lineal.",
    "crumbs": [
      "CORRELACIÓN Y REGRESIÓN",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Medidas de relación lineal</span>"
    ]
  },
  {
    "objectID": "61_correlacion.html#coeficiente-de-correlación",
    "href": "61_correlacion.html#coeficiente-de-correlación",
    "title": "13  Medidas de relación lineal",
    "section": "13.3 Coeficiente de correlación",
    "text": "13.3 Coeficiente de correlación\nPara calcular el coeficiente de correlación, \\(r\\), entre dos variables \\(X\\) e \\(Y\\) basta con calcular su covarianza y dividirla por el producto de las desviaciones típicas de \\(X\\) e \\(Y\\), es decir:\n\\[ r  = \\frac{\\frac{\\sum_{i=1}^{n} (x_i -\\bar {x})(y_i -\\bar {y})}{n-1}}\n        {\\sqrt \\frac {{\\sum_{i=1}^n \\left ( x_i - \\bar{x} \\right )^2}}{n-1} \\sqrt{ \\frac {\\sum_{i=1}^n \\left ( y_i - \\bar{y} \\right )^2 }{n-1}}} \\]\nEs fácil comprobar que desaparecen los denominadores tanto de la covarianza como de las desviaciones típicas, quedando:\n\\[ r  = \\frac{\\sum_{i=1}^n \\left ( x_i - \\bar{x} \\right ) \\left ( y_i - \\bar{y} \\right ) }\n        {\\sqrt {\\sum_{i=1}^n \\left ( x_i - \\bar{x} \\right )^2}  \\sqrt{\\sum_{i=1}^n \\left ( y_i - \\bar{y} \\right )^2 }} \\]\nCon esta sencilla transformación se resuelven los problemas de la covarianza:\n\nEs un valor adimensional y, por tanto, no depende de las unidades utilizadas.\nSu valor está acotado entre -1 y 1 (correlación perfecta negativa y positiva repectivamente).\n\nQue es adimensional es evidente, puesto que el numerador tiene las mismas unidades que el denominador. Que es igual a 1 o -1 cuando la relación lineal es perfecta lo demostramos en un apéndice de este capítulo usando álgebra elemental. Que está acotado entre -1 y 1 no es trivial, pero lo demostramos en un apéndice del siguiente capítulo usando el concepto de coeficiente de determinación de la recta ajustada (también se puede demostrar como consecuencia directa de la desigualdad de Cauchy-Schwarz, pero eso no son matemáticas elementales) .\n\n\n\n\n\n\nCoeficiente de correlación “de Pearson”\n\n\n\nA la denominación del coeficiente de correlación a veces se le añade “de Pearson” porque fue este estadístico el que lo desarrolló. Aunque existen otros coeficientes de correlación de mucho menor uso, no es necesario el añadido. Si no se dice de que tipo es siempre entendemos que se refiere al de Pearson.\n\n\n\nCoeficiente de correlación y diagrama bivariante\nEl valor del coeficiente de correlación no sustituye la información que proporciona el diagrama bivariante. Un mismo coeficiente de correlación puede corresponder a situaciones muy distitnas y si solo nos dan el valor de \\(r\\) es imposible saber a cual de ellas corresponde.\nUna demostración de la importancia de no descuidar el análisis gráfico de los datos lo constituye el llamado “cuarteto de Anscombe”, formado por cuatro conjuntos de datos que presentan el mismo coeficiente de correlación y la misma recta ajustada pero que al analizarlos gráficamente muestran situaciones claramente distintas (figura 13.4).\n\n\n\n\n\n\nFigura 13.4: Cuarteto de Anscombe. Cuatro situaciones muy distintas pero todas ellas con el mismo coeficiente de correlación (\\(r = 0,816\\)) y la misma recta ajustada (\\(y = 3+0,5x\\))\n\n\n\n\n\nCorrelación estadísticamente significativa\nEl diagrama bivariante de la figura 13.5 está construido con los datos de 29 plantas y muestra la relación entre el peso de los frutos obtenidos y el tiempo transcurrido entre la plantación y la recolección. Se ha añadido la recta de regresión ajustada a estos puntos.\n\n\n\n\n\n\nFigura 13.5: Relación entre el peso de los frutos recogidos en 22 plantas y el tiempo transcurrido desde su plantación hasta la recolección\n\n\n\nParece dar la sensación de que cuanto más se tarda en recoger los frutos mayor peso se obtiene. El coeficiente de correlación es positivo y está bastante alejado de cero, \\(r=0,323\\). ¿Quiere esto decir que para maximizar el peso de la cosecha vale la pena esperar a los 150 días?\nSi dos variables son totalmente independientes, como dos conjuntos de números aleatorios, no por ello hay que esperar que su coeficiente de correlación sea igual a cero. Para que esto ocurra también la covarianza debe ser igual a cero y para ello se debe dar un equilibrio perfecto en los puntos de cada cuadrante para que se compensen perfectamente los productos de las distancias, lo cual es muy difícil que se dé en la práctica.\nPor tanto, cuando tenemos dos conjuntos de datos que provienen de poblaciones independientes, no hay que esperar que su coeficiente de correlación sea exactamente igual a cero. Estará en torno a cero.\n¿Qué significa “en torno a”? La distancia que exigimes respecto a cero para tomarnos en serio la correlación depende del número de datos de que se disponga. Si solo tenemos dos datos (dos puntos sobre el diagrama) el coeficiente de correlación valdrá -1 o 1 con independencia de la relación que haya entre esas variables, por tanto, ese resultado no tiene ningún valor. Si se tienen pocos datos se exige más distancia que si se tienen muchos porque es más fácil que -por casualidad- se obtengan valores extremos.\nEn nuestro caso de 22 datos ¿cuál es la distancia exigida? Vamos a generar 22 números aleatorios de una distribución Normal con media \\(\\mu = 137\\) y \\(\\sigma = 6.5\\) que podemos considerar que son los parámetros de la población de la que provienen los valores de los pesos, y otros 22 números aleatorios, totalmente independientes de los anteirores, en este caso también de una distribución Normal, pero con parámetros \\(\\mu = 6\\) y \\(\\sigma = 0.5\\) para simular los valores del tiempo hasta la recogida. Cuando se calcula el coefiente de correlación con ese conjunto de datos simulados se obtiene un valor que corresponde a muestras de poblaciones independientes. Este proceso se puede repetir muchas veces y cada vez se obtiene un valor del coeficiente de correlación que corresponde a una situación de variables independientes.\nHemos repetido este proceso 100.000 veces, de manera que hemos obtenido 100.000 valores del coefiente de correlación entre dos conjuntos de datos de origen similar a los nuestros y que son absolutamente independientes. Los resultamos obtenidos se resumen en el histograma de la figura 13.6 ===Esto hay que explicarlo mejor===\n\n\n\n\n\n\nFigura 13.6: Valores del coeficiente de correlación obtenidas por simulación\n\n\n\nA la vista de este histograma, podemos afirmar que si nos hubiera salido un coeficiente de correlación de, por ejemplo 0,8, podríamos afirmar con un riesgo de equivocarnos muy pequeño que nuestras variables estan correlacionadas porque si fueran independientes un valor como ese o mayor prácticamente no se da nunca. Sin embargo, si nuesto valor fuera \\(r=0,2\\) no podríamos decir que existe correlación porque valores como ese, e incluso mayores, son muy habituales entre variables independientes cuando se calcula con muestras de \\(n=22\\) observaciones. ===todo esto hay que redactarlo mejor===\nEn nuestro caso tenemos \\(r=0,323\\) se trata de una distancia de cero “normal” si no hay relación entre ambas variables…\nHablar de las tablas, de sus características básicas y de que trataremos de como se han construido en el siguiente capítulo.\n===Esto hay que explicarlo mejor===\n\n\nCorrelación no implica relación causa-efecto\n===empezar comentando el gráfico===\nQue dos variable presenten un coeficiente de correlación estadísticamente significativo (esten correlacionadas) no significa que el cambio en una provoque -sea la causa- del cambio en la otra.\nPuede ocurrir que haya una tercera variable no considerada relacionada con las dos que se observan, por ejemplo, se dice que hay una alta correlación entre el número de bomberos que acuden a apagar un incendio y los daños que ese incendio causa, pero, naturalmente, a nadie se le ocurre enviar menos bomberos para que haya menor daños porque estas dos variables, aunque están correlacionadas y en el diagrama bivariante se observe una nube de puntos que marca una clara tendencia de que al aumentar el número de bomberos aumentan los daños, en este caso la variable oculta relacionada con las dos que observamos es la magnitud del incencdio, relacionada con los daños y con el número de bomberos. Existen numerosos ejemplos chistosos de este tipo de situaciones…\n\n\n\n\n\n\nFigura 13.7: Cuatro situaciones que muestran diferentes grados de relación\n\n\n\nTambién puede ocurrir que la relación sea debida al azar. Si exploramos muchos pares de variables, seguro que algunas apareceran con una relación estrecha, aunque en realidad no tengan nada que ver. La página web https://www.tylervigen.com/spurious-correlations contiene muchos ejemplos de este tipo.\n\n\nCuriosidad sobre el coeficiente de correlación\nSi solo tenemos n = 2 puntos sobre el diagrama bivariante, el coeficiente de correlación solo puede tomar los valores -1 y 1, ambos con la misma probabilidad . Si tenemos n = 3 aparece una distribución muy rara tanto para explicar la variabidad ligada a fenómenos naturales como en los modelos teóricos que usamos habitualmente: los valores más frecuentes están en los extremos (-1 y 1) mientras que en torno al centro (alrededor de cero) se dan los de menor probabilidad.Para n = 4 todos los valores del coeficiente de correlación son igualmente probables , para n = 5 la distribución de probabilidad tiene forma de semielipse, y a media que aumenta el valor de n va apareciendo la típica forma de campana. (figura).\n\n\n\n\n\n\nFigura 13.8: Distribución del coeficiente de correlación según el tamaño, \\(n\\), de la muestra considerada\n\n\n\nLas distribuciones de la figura +++ se puede reproducir por simulación o directamente usando la función densidad de probabilidad de coefiente de correlación, aunque su expresión es un poco aparatosa:\n\\[ f(r \\mid \\rho =0) = \\frac{ \\Gamma \\left [\\frac{1}{2} (n-1) \\right ]} { \\Gamma \\left [\\frac{1}{2} (n-2) \\right ] \\sqrt{\\pi}\n} (1-r^2)^{\\frac{1}{2}(n-4)} \\]\nAclarar la notación Esta función no converge a la distribución Normal cuando n se hace grande, ya que está definida solo entre -1 y 1 mientras que el dominio de la distribución Normal no está acotado.",
    "crumbs": [
      "CORRELACIÓN Y REGRESIÓN",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Medidas de relación lineal</span>"
    ]
  },
  {
    "objectID": "62_regresionSimple.html",
    "href": "62_regresionSimple.html",
    "title": "14  Regresión Simple",
    "section": "",
    "text": "Apéndice 10.1"
  },
  {
    "objectID": "62_regresionSimple.html#ajuste-a-una-recta",
    "href": "62_regresionSimple.html#ajuste-a-una-recta",
    "title": "14  Regresión Simple",
    "section": "14.1 Ajuste a una recta",
    "text": "14.1 Ajuste a una recta\nSi entre la respuesta y la variable regresora se observa una relación lineal se determina la ecuación de la recta que mejor se adapta a los puntos disponibles. Lo que significa “mejor” es discutible. Veamos algunas formas de hacerlo.\n\nA ojo\nSe traza la recta directamente sobre el papel o se identifican dos puntos de paso y a partir de ellos se calculan los coeficientes del modelo.\nA pesar de sus evidentes limitaciones, si solo se trata de tener la recta no es un método tan malo como parece. Con un poco de práctica el ajuste no será muy distinto del “perfecto” y no se cometeran errores de bulto debido a la presencia de valores anómalos, cosa que sí puede ocurrir si se tratan los datos de forma automática sin mnirarlos.\n\n\n\nFigura 14.2: Ajuste a ojo y el que minimiza la suma de los cuadrados de los residuos.\n\n\n\n\nTabla 14.1: Ajuste a ojo. Ventajas e inconvenientes\n\n\n\n\n\n\nPROS \n\nIntuitivo. Muy fácil de entender.\nNo se comenten errores de mucho bulto.\n\n\n\nCONS \n\nNo se logra el ajuste “perfecto” de acuerdo con el criterio establecido. |\nNo se tienen medidas de calidad del ajuste. |\nSolo sirve para regresión simple.\n\n\n\n\n\n\n\nMétodo de Ishikawa\nSe identifica el primer y el tercer cuartil de los valores de \\(X\\) \\((X_{Q1}\\) y \\(X_{Q3})\\), e igual para los valores de \\(Y\\) \\((Y_{Q1}\\) y \\(Y_{Q3})\\). Se traza la recta por los puntos \\((X_{Q1}\\) y \\(Y_{Q1})\\) y \\((X_{Q3}\\) y \\(Y_{Q3})\\). Se obtiene una recta muy razonable sin necesidad de realizar cálculos ni de aplicar fórmulas de las que se desconoce su lógica.\n\n\n\nFigura 14.3: Ajuste por el método de Ishikawa y el que minimiza la suma de los cuadrados de los residuos.\n\n\n\n\nTabla 14.2: Método de Ishikawa. Ventajas e inconvenientes\n\n\n\n\n\n\nPROS \n\nFácil de entender\nRobusto frente a la presencia de valores anómalos o con excesiva influencia\n\n\n\nCONS \n\nNo se tienen medidas de calidad del ajuste\nSolo sirve para regresión simple\n\n\n\n\n\n\n\n\n\n\n\nKaoru Ishikawa (1915-1989)\n\n\n\nFue un ingeniero japonés, considerado uno de los artífices del llamado “milagro japonés” que condujo los productos japoneses desde la mediocridad hasta arrasar en los mercados mundiales (electrónica, fotografía, automoción,…). Una de las claves del éxito fue el uso intensivo de técnicas estadísticas para el control y la mejora de la calidad. Ishikawa es conocido por proponer el uso de herramientas sencillas, que todos puedan entender y aplicar de forma habitual.\n\n\n\n\nHaciendo que la suma de los residuos sea igual a cero\nSe trata de obtener los valores de \\(b_0\\) y \\(b_1\\) que cumplen la expresión:\n\\[\\sum_{i=1}^n \\left[ Y_i - (b_0 - b_1 X_i) \\right]= 0\\] qye es equivalente a:\n\\[ n\\bar{Y} - nb_0 - b_1 n \\bar{X} = 0\\] Por tanto, con cualquier par de valores \\(b_0\\) y \\(b_1\\) que verifiquen la expresión \\(\\bar{Y} = b_0 + b_1 \\bar{X}\\), es decir, con cualquier recta que pase por (\\(\\bar{X}\\), \\(\\bar{Y}\\)) tendremos una suma de residuos igual a cero.\nQue haya infinitas rectas que cumplan esa condición es una mala señal, porque seguro que no todas son adecuadas. Para los valores representados en la figura 14.4 tenemos que \\(\\bar{X}= 6\\) y \\(\\bar{Y}= 9\\). Rectas que hacen que la suma de los residuos sea igual a cero son, por ejemplo, la que tiene coeficientes \\(b_0=9\\) y \\(b_1=0\\), es decir: \\(Y = 9\\), o también \\(b_0 = 12\\) y \\(b_1 = -0.5\\), es decir: \\(Y = 12 -0.5X\\) y ambos son claramente muy malos ajustes.\n\n\n\nFigura 14.4: Dos ajustes -claramente muy malos- con suma de residuos igual a cero.\n\n\n\n\nTabla 14.3: Suma de los residuos igual a cero. Ventajas e inconvenientes\n\n\n\n\n\n\nPROS \n\nNinguna\n\n\n\nCONS \n\nDa un número infinito de soluciones (una de ellas coincide con el ajuste por mínimos cuadrados)\n\n\n\n\n\n\n\nMinimizando la suma del valor absoluto de los residuos\nSe trata de minimizar:\n\\[S=\\sum_{i=1}^n \\left| Y_i - (b_0 - b_1 X_i) \\right|= 0\\]\nPuede no tener solución única, pero los resultados posibles son mucho más razonables que en el caso anterior. Un problema específico de este caso es que no existen expresiones analíticas para los coeficientes debido a las dificultades en el manejo de la función “valor absoluto”.\nLa figura 14.5 muestra dos diagramas con los mismos 4 puntos y ñas rectas que cumplen el criterio estableciso, en todas ellas la suma del valor absoluto de los residuos es igual a 2. La línea azul, que es la misma en los dos diagramas, es la que también minimiza la suma de los cuadrados de los residuos.\n\n\n\nFigura 14.5: Posibles opciones para minimizar la suma de los residuos en valor absoluto.\n\n\n\n\nTabla 14.4: Suma de los residuos igual a cero. Ventajas e inconvenientes\n\n\n\n\n\n\nPROS \n\nPoco sensible a la presencia de valores anómalos\n\n\n\nCONS \n\nNo da un ajuste equilibrado entre todos los puntos\nNo existe expresión analítica para el cálculo de los coeficientes\n\n\n\n\n\n\n\n\nMinimizando la suma de los cuadrados de los residuos\nElevamos los residuos al cuadrado en vez de usar su valor absoluto para evitar que al sumarlos se compensen los positivos y negativos. Ahora se trata de minimizar:\n\\[S=\\sum_{i=1}^n \\left[ Y_i - (b_0 - b_1 X_i) \\right]^2= 0\\]\nEn vez de decir que el criterio de ajuste ha sido “minimizar la suma de los cuadrados de los residuos”, decimos que hemos ajustado por “mínimos cuadrados”. Este es el método usado en la inmensa mayoría de los casos, produce un ajuste equilibrado de la nube de puntos y está en perfecta sintonía con otras técnicas y medidas, que se contruyen en torno a criterios similares. Un inconveniente de este método de ajuste es que el modelo obtenido es sensible a la presencia de valores anómalos, cosa que no ocurre si se minimiza la suma de valores absolutos.\nEn la primera fila de la figura 14.6 tenemos una situación típica en que el ajuste por mínimos cuadrados da un mejor resultado que minimizando la suma del valor absoluto. Sin embargo, en la segunda fila tenemos un cado de puntos perfectamente alineados excepto un que muy probablemente sería un valor anómalo. Si minimizamos el valor aboluto de los residuos el ajuste ignora el valor anómalo mientras que ajustado por mínimos cuadrados el valor anómalo tiene una notable influencia sobre la recta ajustada.\n\n\n\nFigura 14.6: Ajustes obtenidos minimizando la suma de valores absolutos y la suma de los cuadrados de los residuos\n\n\n\n\nTabla 14.5: Minimizar la suma de los cuadrados de los residuos. Ventajas e inconvenientes\n\n\n\n\n\n\nPROS \n\nProporciona un ajuste muy razonable. El que queremos hacer cuando ajustamos a ojo.\nEncaja perfectamente con el resto de técnicas estadísticas que utilizamos.\n\n\n\nCONS \n\nLos valores anómales (errores o valores singulares) pueden tener bastante influencia sobre el modelo estimado. Hay que estar atentos para tratar esos puntos adecuadamente"
  },
  {
    "objectID": "62_regresionSimple.html#mínimos-cuadrados.-cálculo-de-los-coeficientes",
    "href": "62_regresionSimple.html#mínimos-cuadrados.-cálculo-de-los-coeficientes",
    "title": "14  Regresión Simple",
    "section": "14.2 Mínimos cuadrados. Cálculo de los coeficientes",
    "text": "14.2 Mínimos cuadrados. Cálculo de los coeficientes\nExiste una fórmula cerrada y con solución única para cada coeficiente, pero vamos a empezar identificando el valor de los coeficientes sin hacer uso de las fórmulas. Naturalmente, es mucho más rápido y más práctico usarlas o -mejor todavía- usar un paquete de software estadístico o una hoja de cálculo, pero hacerlo sin fórmulas permite entender perfectamente qué es lo que se está haciendo, y también descubrir algún detalle interesante.\n\nSin fórmulas\nRealizamos a ojo una primera estimación del valor de los coeficientes. A continuación, mediante un pequeño programa -o también usando una hoja de cálculo-, hacemos un barrido de los valores de \\(b_0\\) y \\(b_1\\) en torno a los estimados, identidicando el par que minimiza la suma de los cuadrados de los residuos.\nVayamos al diagrama de la figura 14.7 (izquierda) que ya habíamos visto en las figuras 14.2 y 14.3. La recta ajustada a ojo pasa por los puntos (-4,75; 0) y (5,75, 60) por lo que sus coeficientes son: \\(b_1\\) = 5,71 y \\(b_0\\) = 27,14. Sería mucha casualidad que esos fueran los valores exactos que estamos buscando, pero no andarán muy lejos. Vamos a crear una malla de valores de \\(b_0\\) y \\(b_1\\). Los valores de \\(b_0\\) variarán de 2 a 8 con incrementos de 0,1 y para cada uno de esos, los de \\(b_0\\) irán de 20 a 35 también en saltos de 0,1. A cada combinación de esos dos valores corresponde a una recta, y a cada recta una suma de los cuadrados de los residuos. El par de valores que minimizan esa suma de cuadrados son: \\(b_0\\) = 27,0 y \\(b_1\\) = 4,8.\n\n\n\nFigura 14.7: Recta ajustada a ojo (izq.) y suma de los cuadrados de los residuos para cada par de valores \\(b_0\\) y \\(b_1\\). En rojo, valores que la minimizan (der.).\n\n\n\n\n\n\n\n\nParaboloide de la suma de cuadrados\n\n\n\nCon los datos de nuestro ejemplo, la superficie que representa la suma de los cuadrados de los residuos es un paraboloide donde la localización del mínimo es visulamente muy clara. Pero lo nomal es que las curvas de nivel sean muy elípticas de manera que la representación no queda tan clara. Nosotros hemos logrado esa forma regular haciendo que la media de los valores de \\(X\\) sea igual a cero. De esta forma, los coeficientes son independientes y las curvas de nivel apararecen como círculos prácticamente concéntricos quedando más clara la idea que queremos representar.\n\n\n\n\nUsando las fórmulas\nEn el diagrama que representa la relación entre \\(X\\) e \\(Y\\) cada punto puede ser identificado por sus coordenadas \\((x_i, y_i)\\) con \\(1 \\leq i \\leq n\\) siendo \\(n\\) el número total de puntos. [creo que esto es redundante y habría que mejorarlo]\nCada uno de los puntos tiene un residuo asociado \\(e_i\\) y ese residuo es la diferencia entre el valor real de \\(y\\), es decir, \\(y_i\\) y su valor estimado \\(\\hat{y}_i\\), el que estará sobre la recta y que será igual a \\(b_0 + b_1 x_i\\). Por tanto, el valor del residuo asociado al punto \\(i\\) lo podemos escribir de la forma:\n\\[ e_i = y_i - \\left( b_0 + b_1 x_i \\right) \\] Por tanto, la suma de los cuadrados de los residuos, \\(S\\), será:\n\\[ S = \\sum_{í=1}^n \\left(y_i - b_0 - b_1 x_i \\right )^2 \\]\nTanto los valores de \\(y_i\\) como los de \\(x_i\\) vienen dados. La suma de cuadrados \\(S\\) es función de los valores de \\(b_0\\) y de \\(b_1\\). Se trata de hallar los valores de \\(b_0\\) y de \\(b_1\\) que minimizan esa suma de cuadrados. El mínimo lo tendremos en el punto en que la derivada de \\(S \\left(b_0, b_1 \\right )\\) respecto a \\(b_0\\) y respecto a \\(b_1\\) es igual a cero. Seguro que es un mínimo porque el máximo no está definido.\n\\[ \\frac{\\partial S}{\\partial b_0} = -2 \\sum_{í=1}^n \\left(y_i - b_0 - b_1 x_i \\right ) \\]\n\\[ \\frac{\\partial S}{\\partial b_1} = -2 \\sum_{í=1}^n \\left(y_i - b_0 - b_1 x_i \\right ) x_i \\]\nIgualando a cero estas expresiones:\n\\[ \\sum_{í=1}^n y_i - nb_0 - b_1 \\sum_{í=1}^n x_i = 0  \\tag{14.1}\\]\n\\[ \\sum_{í=1}^n x_i y_i - b_0 \\sum_{í=1}^n x_i - b_1 \\sum_{í=1}^n  x_i^2  = 0  \\tag{14.2}\\]\nDividiendo por \\(n\\) todos los términos de la ecuación 14.1 tenemos:\n\\[ b_0 = \\bar{y} - b_1 \\bar{x} \\]\n\n\n\n\n\n\nLa recta ajustada pasa por el punto \\((\\bar{x}, \\bar{y})\\)\n\n\n\nDe la anterior expresón para \\(b_0\\) también se decude que \\(\\bar{y} = b_0 + b_1\\bar{x}\\). Es decir, la recta ajustada minimizando la suma de los cuadrados de los residuos siempre pasa por el punto \\((\\bar{x}, \\bar{y})\\) .\n\n\nSustituyendo la expresión de \\(b_0\\) en la ecuación 14.2 tenemos:\n\\[ \\sum_{í=1}^n x_i y_i - \\bar{y} \\sum_{í=1}^n x_i +  b_1\\bar{x} \\sum_{í=1}^n x_i- b_1 \\sum_{í=1}^n  x_i^2  = 0 \\]\nPara aligerar la notación no pondremos los límites a los sumatorios, que siempre son desde \\(i=1\\) hasta \\(n\\). Despejando \\(b_1\\) llegamos a:\n\\[ b_1 = \\frac{\\sum x_i y_i - \\bar{y} \\sum x_i}{\\sum x_i^2 - \\bar{x} \\sum x_i} \\] También la expresión de \\(b_1\\) se suele dar de la forma (ver Apéndice 10.1):\n\\[ b_1 = \\frac{\\sum (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum (x_i - \\bar{x})^2}  \\tag{14.3}\\]\nA partir de la ecuación 14.3 y recordando las expresiones de la covarianza y del coeficiente de correlación, llegamos a una expresión que también se ve con frecuencia en los libros de texto, seguramente porque una calculadora sencilla da directamente los tres valores que intervienen:\n\\[ b_1 = \\frac{Cov(XY)}{s_X^2} = \\frac{r_{XY} s_X s_Y}{s_X^2} = r_{XY} \\frac{s_Y}{s_X} \\] Calculando los coeficientes que corresponden a los datos de la figura 14.7 se obtiene:\n\\[ b_0 = 26,9615 \\qquad  \\qquad b_1 = 4,8616 \\] Ahora sí, con todos los decimales que queramos, aunque dar más decimales de los que tienen los datos es añadir números que no aportant ninguna información, dan una falsa sensación de precisión y complican la lectura del resultado.\n\n\n\n\n\n\n\nPor qué le llamamos modelo de regresión\n\n\n\nSean, por ejemplo, los puntos: (4; 3), (6; 8), (8; 12), (10; 10), (12; 12). La recta ajustada es: \\(y = 1+x\\). Si en vez de ajustar \\(y = f(x)\\) se ajusta \\(x=f(y)\\) ¿se obtendrá la ecuación resultante de despejar \\(x\\) en \\(y=f(x)\\), es decir: \\(x = -1 + y\\)? Si ajustamos \\(x=f(y)\\) la ecuación será: \\(x=1,57+0,714x\\). No es lo mismo minimizar la suma de los cuadrados de los residuos medidos en dirección vertical que en dirección horizontal (esto último no son los residuos)."
  },
  {
    "objectID": "62_regresionSimple.html#calidad-del-ajuste",
    "href": "62_regresionSimple.html#calidad-del-ajuste",
    "title": "14  Regresión Simple",
    "section": "14.3 Calidad del ajuste",
    "text": "14.3 Calidad del ajuste\nEl gráfico de la izquierda de la figura 14.8 muestra la relación entre la longitud de la circunferencia (X) de los troncos de un determinado tipo de árbol y el volumen de madera (Y) que se puede obtener de ellos (Fuente: Wolfram_Data_Repository 2016). Se observa que a más circunferencia mayor volumen de madera, tal como era de esperar, y la ecuación de la recta ajustada es útil para estimar cuanta madera se obtendrá de un tronco de determinado diámetro. Sin embargo, el gráfico de la derecha se ha realizado con los datos de un estudio publicado por Wilson y Mather (1974) citado por Draper y Smith (1998) donde se analiza la relación entre la edad al morir y la longitud de cierta línea de la mano a partir de una muestra de 50 personas fallecidas. A la vista del diagrama queda claro que no hay ninguna relación entre ambas variables. En este caso el modelo ajustado no sirve absolutamente para nada. Pero los dos modelos tienen el mismo aspecto y solo a la vista del valor de sus coeficientes es imposible saber cual de los dos es útil.\n\n\n\nFigura 14.8: Relación muy clara y relación inexistent, situaciones que no pueden distinguirse solo a la vista del modelo ajustado.\n\n\nEs necesario, por tanto, completar el modelo con una medida que informe de la calidad del ajuste obtenido. Esa medida es el coeficiente de determinación \\(R^2\\).\nPara calcular el valor de \\(R^2\\) empezamos poniéndonos en el peor de los casos: suponemos que \\(X\\) e \\(Y\\) son independientes, es decir, que el valor de \\(X\\) no aporta ninguna información sobre el valor de \\(Y\\). En este caso, la recta que muestra la relación entre ambas variables es una recta horizontal: la estimación del valor de \\(Y\\) es siempre la misma, sin importar el valor de \\(X\\), y la mejor apuesta para ese valor de \\(Y\\) -a falta de cualquier otra información- es su valor medio \\(\\bar{y}\\). A la suma de los cuadrados de los residuos correspondientes a esa recta horizontal que pasa por \\(\\bar{y}\\) le llamamos \\(Q_Y\\).\nA continuación calculamos la suma de los cuadrados de los residuos correspondientes a nuestra recta ajustada (la que minimiza la suma de los cuadrados de los residuos) y le llamaremos \\(Q_R\\). Cuanto mejor sea el ajuste menor será el valor de \\(Q_R\\) y mayor la diferencia entre \\(Q_Y\\) y \\(Q_R\\).\nEl valor de \\(R^2\\) es igual a la proporción de \\(Q_Y\\) explicada por \\(X\\), es decir, la proporción en que disminuye \\(Q_Y\\) gracias a la introducción de \\(X\\) como variable explicativa, es decir:\n\\[ R^2 = \\frac{Q_Y - Q_R}{Q_Y} \\]\nVeamos este cálculo en un ejemplo con datos sencillos. En la figura 14.9 tenemos 5 puntos que podrían representar la relación entre el peso y la estatura de 5 individuos. Si, ignorando la información aportada por la estatura, siempre damos una estimación del peso igual a su valor medio, será como ajustar a una recta horizontal y tendremos una suma de los cuadrados de los residuos \\(Q_Y = 56\\). Sin embargo, si utilizamos la información que aporta la estatura y realizamos el ajuste minimizando la suma de los cuadrados de los residuos tenemos \\(Q_R = 16\\).\n\n\n\nFigura 14.9: Múltiples opciones para minimizar la suma de los residuos en valor absoluto.\n\n\nHemos reducido la suma de los cuadrados de los residuos de 56 a 16, por tanto:\n\\[ R^2 = \\frac{Q_Y - Q_R}{Q_Y} = \\frac{56 - 16}{56} = 0.7143 \\]\nNormalmente nos referimos a este valor como un porcentaje. En este caso sería el 71.43%. En los ejemplos de la figura 14.8 estos valores son del 93,5% (volumen de madera) y 1,5% (edad al morir).\n\n\n\n\n\n\n\\(R^2\\) es el cuadrado del coeficiente de correlación \\(r\\)\n\n\n\nEfectivamente, en el caso que estamos considerando de regresión simple, el coeficiente de determinación \\(R^2\\) es igual al cuadrado del coeficiente de correlación \\(r\\). Este último puede variar entre \\(-1\\) y \\(1\\) por lo que, obviamente, \\(R^2\\) varía entre 0 y 1. La demostración es corta y fácil de encontrar en internet. Por ejemplo en:"
  },
  {
    "objectID": "62_regresionSimple.html#relación-no-lineal-entre-x-e-y",
    "href": "62_regresionSimple.html#relación-no-lineal-entre-x-e-y",
    "title": "14  Regresión Simple",
    "section": "14.4 Relación no lineal entre \\(X\\) e \\(Y\\)",
    "text": "14.4 Relación no lineal entre \\(X\\) e \\(Y\\)\nSi a la vista del diagrama bivariante se observa que la relación entre \\(X\\) e \\(Y\\) no es lineal, se puede utilizar el aspecto de la nube de puntos y el conocimiento del fenómeno que se estudia para plantear un modelo que se ajuste a los datos. Los modelos polinómicos de segundo grado son muy versátiles y pueden ser una buena opción. También se puede ajustar a modelos linealizables transformando los valores de \\(X\\), los de \\(Y\\), o ambos. Si nuestros datos se ajustan a una función del tipo \\(y = \\beta_0 e^{\\beta_1 x}\\), podemos realizar el cambio \\(y' = \\ln y\\) obteniendo el modelo lineal: \\(y' = \\ln \\beta_0 + \\beta_1 x\\) a partir del cual se deducen de forma inmediata los coeficientes del modelo original. Interesados en este tipo de transformaciones para linealizar la dependencia pueden consultar Montgomery y Peck (1992) pág. 90. o Peña (2002) pág. 314.\nLa figura 14.10 (izquierda) muestra los datos de producción de electricidad de un aerogenerador según sea la velocidad del viento (datos en: Montgomery y Peck (1992), pág. 92). Se observa una relación no lineal ya que cuando la velocidad del viento es baja, pequeños incrementos en la velocidad tienen un impacto importante en la producción de electricidad, mientras que para velocidades altas la producción tiende a estabilizarse. Ajustando a una parábola se obtiene \\(y = -1,156 + 0,7229x -0,03812x^2\\) con un coeficiende de determinación \\(R^2 = 96,8%\\), lo cual no está nada mal.\nOtra opción es estudiar la producción de electricidad en función de la inversa de la velocidad del viento (figura de la derecha). Creamos la variable \\(X' = 1/X\\) y obtenemos el ajuste: \\(y = 2,979 - 6,935/x\\) con un \\(R^2 = 97,9%\\) que es también un valor excelente y, además, con un modelo más compacto. En general, trabajar con la inversa de \\(X\\) puede ser una buena alternativa al modelo cuadrático.\n\n\n\nFigura 14.10: Texto figura.\n\n\nHay que tener en cuenta que el modelo más adecuado no necesariamente es el que tiene el \\(R^2\\) más elevado. Nos interesa que el modelo sea compacto y que pueda interpretarse y sea coherente con nuestro conocimiento del fenómeno en estudio. Si vamos aumentando el grado del polinomio ajustado cada vez tendremos un mayor valor de \\(R^2\\) incluso, si tenemos pocos datos, podemos llegar a un \\(R^2\\) del 100% siendo el modelo obtenido totalmente inútil.\nVolviendo a los datos de la figura 14.9 donde a partir de los pesos de 5 personas (efectivamente son muy pocas, es solo un ejemplo) queremos modelar la relación entre peso y estatura, el modelo lineal es el más razonable. Si ajustamos los datos a un modelo cuadrático se tiene un máximo de peso en torno a una estatura de 175 cm que no tiene sentido. El polinomio de tercer grado presenta una forma que tampoco parece razonable y el de cuarto grado es un modelo con 5 parámetros (los 4 coeficientes y la ordenada en el origen) y como tenemos 5 puntos ajusta perfectamente, pero ni es un modelo razonable ni sirve en absoluto para estimar el peso de un individuo a partir de su altura (sí lo explica para los 5 individuos usados para construir el modelo, pero para esos ya lo sabíamos). Recuerde que dos puntos se ajustan perfectamente a un modelo con dos parámetros (una recta) tres puntos a un modelo con tres parámetros, … etc. Estos son modelos que explican muy bien lo que ya se sabe, pero son totalmente inútiles para hacer predicciones que es lo que -en general- se pretende.\n\n\n\nFigura 14.11: Aumentando el grado del polinomio la curva de adapta a los puntos pero solo explica lo que ya sabemos."
  },
  {
    "objectID": "62_regresionSimple.html#transformación-logarítmica",
    "href": "62_regresionSimple.html#transformación-logarítmica",
    "title": "14  Regresión Simple",
    "section": "14.5 Transformación logarítmica",
    "text": "14.5 Transformación logarítmica\nEn algunos casos, los valores de \\(X\\), los de \\(Y\\), o ambos, siguen una distribución asimétrica, con valores que aparecen agrupados cerca del origen y muy dispersos hacia los valores altos. Un ejemplo típico de esta situación se da al analizar la relación entre el peso del cerebro y el peso de cuerpo en 62 especies de mamíferos (Weisberg 2014, pág. 186). La mayoria de esos mamíferos pesan poco –la mediana es de 3,34 kg– pero algunos, como los elefantes, pesan varias toneladas y algo similar ocurre con el peso de los cerebros. Al realizar el diagrama bivariante del peso del cerebro (\\(Y\\)) frente al peso de cuerpo (\\(X\\)) prácticamente todos los puntos aparecen amontonados en la zona próxima al origen, En estas condiciones ajustar un modelo de regresión no tiene sentido, porque la mayoría de datos actúan como un solo punto y los que estan alejados tienen una gran influencia sobre la recta ajustada.\n\n\n\nFigura 14.12: Relación entre el peso del cerebro y el peso del cuerpo en 62 especies de mamíferos.\n\n\nUno puede caer en la tentación de considerar a los elefantes como valores anómalos y eliminarlos, pero esa no es una buena decisión por dos razones:\n\nRestringe la validez del modelo, ya no valdrá para todos los mamíferos considerados.\nAl eliminar esos valores y reescalar el gráfico aparecen otros valores anómalos: la persona humana (que da más reparo eliminar), la jirafa, el caballo, la vaca… y al final nos vamos quedando sin puntos.\n\nEn casos como este, la transformación logarítmica “estira” los datos permitiendo un ajuste en el que todos los puntos tienen una influencia similar. Realizando esta transformación en nuestros datos se obtiene -casi parece un milagro- una nube de puntos tal como esperamos tener cuando ajustamos a una recta.\n\n\n\nFigura 14.13: Peso del cerebro frente al peso del cuerpo antes y después de la transformación logarítmica.\n\n\nEl modelo obtenido es:\n\\[\\log(Y) = 0,9271 + 0,7517 \\log(X) \\quad \\text{con} \\quad R^2 = 91,95\\%\\] Volviendo a las variable soriginales nos queda (el cuerpo está en kg y el del cerebro en g):\n\\[Y = 8,45 · X^{3/4}\\] La transformación logarítmica de los datos es, sin duda, una buena opción en casos como este, pero también tiene efectos secundarios no deseados.\nEn primer lugar hay que tener en cuenta que los residuos (diferencia entre el valor real y el valor previsto) también están en escala logarítmica. POr ejemplo, para el elefante africano (el mayor, parece que la recta pasa por el punto) el valor real del peso del cerebro es de 5712 g y la previsión es de 6229 (+9%) y para el elefante asiático el valor real es de 4603 g mientras que el valor previsto es de 3031 g (-34%). El mamífero que presenta mayor residuo positivo es la persona humana (valor real: 1320, previsto: 185, -86%) mientras que el de mayor residuo negativo corresponde al Yapok (en inglés: Water opossum). Seguramente más interesante que el modelo en sí es conocer qué animales se separan más -por encima y por debajo- del patrón general. Sobre este tema existen muchas publicaciones. Los interesados pueden empezar explorando la Wikipedia y las referencias que incluye.\n\n\n\n\n\n\nTransformación logarítmica: No importa la base\n\n\n\nEn efecto, sea \\(y = \\ln (x)\\) y \\(z = \\log_{10}(x)\\). Tendremos que \\(e^y = x\\) y también que \\(10^z = x\\), luego \\(e^y = 10^z\\). Por tanto, \\(\\ln(e^y) = \\ln(10^z)\\) y es inmediato que: \\(y = \\ln(10)·z\\).\nPor tanto, cambiar la base del logaritmo equivale a multiplicar por una constante. En particular, para pasar del logaritmo neperiano al decimal basta con multiplicar por \\(\\ln(10)\\). El aspecto del diagrama bivariante es el mismo con independencia de la base utilizada para la transformación logarítmica, solo cambian las escalas, aunque para que al volver a las variables originales la expresión sea más compacta puede interesar elegir una base u otra.\n\n\nPosibilidad de usar los datos de Hooker, parece relación lineal pero no lo es y la transformación logarítmica da buen resultado"
  },
  {
    "objectID": "62_regresionSimple.html#las-cosas-se-complican-lo-que-tenemos-es-una-muestra",
    "href": "62_regresionSimple.html#las-cosas-se-complican-lo-que-tenemos-es-una-muestra",
    "title": "14  Regresión Simple",
    "section": "14.6 Las cosas se complican: Lo que tenemos es una muestra",
    "text": "14.6 Las cosas se complican: Lo que tenemos es una muestra\nLa interpretación de los resultados se complica cuando caemos en la cuenta de que los datos disponibles son solo una muestra de la población de interés. Supongamos que deseamos estudiar la relación entre peso y estatura en los jóvenes de cierta edad (haríamos bien en separar hombres y mujeres, pero aquí vamos a ignorar ese aspecto que trataremos en el siguiente capítulo) y que disponemos de una muestra de -pongamos- 20 jóvenes. Con los datos de esa muestra ajustamos una recta pero, en realidad, esa no es la recta que andamos buscando. Si hubiéramos tomado otra muestra la recta sería otra -distitnta- pero tan válida como la primera. Entonces, ¿cómo se interpreta la recta obtenida?\nComo en otros casos, una forma de ver lo que ocurre es simulando. En los diagramas de la figura 14.14 las estaturas (\\(X\\)) se han generado aleatoriamente de una distribución N(170; 8) y a cada estatura se le ha asignado un peso (\\(Y\\)) mediante la expresión \\(Y = X -100 +e\\), donde \\(e\\) un valor también generado aleatoriamente de una distribución N(0; 5). Tanto los valores de la estatura (en cm) como los obtenidos para los pesos (en kg) son valores razonables para una población joven. Hemos repetido la simulación 6 veces y, como es natural, cada vez hemos obtenido unos datos distintos y, por tanto, también una recta ajustada distinta.\n\n\n\nFigura 14.14: Rectas ajustadas a partir de muestras de n=20 datos de una misma población. La línea negra representa el modelo teórico\n\n\nEn la figura 14.15 (izq.) se han superpuesto los 6 diagramas anteriores pudiéndose observar el haz de rectas que se obtiene. A la derecha tenemos la misma situación superponiendo 50 simulaciones (cada una con 20 datos) añadiendo, de color verde, la recta que representa el modelo teórico, es decir, la población.\n\n\n\nFigura 14.15: Superposición de 6 (izq.) y 50 (der.) simulaciones de conjuntos de 20 datos del modelo representado con una línea verde en el gráfico de la derecha.\n\n\n\nDistribución de los coeficientes\nLa buena noticia es que si los datos cumplen unas ciertas condiciones –que en general se cumplirán– los valores de los coeficientes pertenecen a distribuciones Normales con parámetros conocidos. Siguiendo con el ejemplo anterior hemos repetido 10.000 veces la simulación obteniendo otras tantas rectas ajustadas. La 14.16 muestra los histogramas de los 10.000 valores obtenidos para \\(b_0\\) y \\(b_1\\).\n\n\n\nFigura 14.16: Distribución de los coeficientes.\n\n\nObserve que las medias de las distribuciones coinciden con verdadero valor del parámetro estimado (estamos de suerte). Las desviaciones típicas dependen de:\n\nNúmero de datos: Cuanto más datos mayor información y menos incertidumbre, por tanto, menos desviación típica en la distribución de los coeficientes.\nDesviación típica de la respuesta: A mayor variabilidad de la respuesta mayor incertidumbre y mayor variabilidad en la distribución del los coeficientes.\nEl rango de variación de los valores de la variable regresora: Si los valores de \\(x\\) están muy próximos a su media habrá mayor variabilidad en los distribución de los coeficientes. Quizá este aspecto no es tan intuitivo como los anteriores, pero se entiende muy bien a la vista de un gráfico como el de la figura 14.16. En la izquierda tenemos el mismo gráfico que en la figura 14.15 con valores de X generados de una distribución N(170; 8) mientras que en el de la derecha se ha construido de la misma forma pero los valores de X se han generadod de una N(170; 3). Al tener menos variabilidad los valores de X tenemos mayor variabilidad en los valroes de los coeficientes.\n\n\n\n\nFigura 14.17: Distribución de los coeficientes.\n\n\nConocer la distribución de los coeficientes hace posible calcular intervalos de confianza o realizar constrastes de hipótesis sobre sus valores.\n\n\nCondiciones que deben reunir los datos\nPara que los coeficientes tengan las distribuciones descritas los datos utilizados para ajustar el modelo deben cumplir las siguientes condiciones:\n\nDistribución de \\(Y\\): Dado un valor de \\(X\\), los valores de \\(Y\\) deben seguir una distribución Normal. Si \\(X\\) es la estatura e \\(Y\\) es el peso, no hace falta suponer que el peso –globalmente– sigue un distribución Normal, pero sí que los pesos para las personas de una determinada estatura siguen esa distribución.\n\n\n\nVariabilidad de \\(Y\\): La variabilidad de \\(Y\\) no depende del valor de \\(X\\). En nuestro ejemplo sería suponer que la variabilidad en el peso de las personas que miden 1,60 es la misma que en las personas que miden 1,80 m. Es posible que esto no sea exactamente así porque es habitual que cuando aumenta el nivel de la respuesta aumente también su variabilidad. Si esto ocurre lo veremos en el diagrama bivariante: la nube de puntos se irá ensanchando a medida que aumenta el valor de \\(X\\). En este caso quizá convenga transformar los datos, aunque ya estaríamos ante una situación más complicada que las que pretendemos tratar aquí.\nValores de \\(X\\): No hay ninguna exigencia especial sobre estos valores. Solo es necesario que la variable sea cuantitativa. Es decir, el día de la semana, codificado como: lunes = 1, martes = 2, … no puede ser una variable regresora porque el modelo entedería que el domingo es igual a 7 veces el lunes. Aun así, también hay formas de incluir este tipo de variables. Lo veremos en el próximo capítulo en el caso de que solo puedan tomar dos valoros posibles.\nIndependencia de los residuos: La desviación respecto al valor previsto (valor sobre la recta) en en un punto no da ninguna pista sobre la desviación en el punto siguiente. Esto no ocurre con las variables que evolucionan en el tiempo, como la temperatura o la cotización de acciones en la bolsa, en que el valor de un día está influenciado por el valor de día anterior.\n\nCuando se ajustan modelos de regresión simple, la observación del diagrama bivariante de \\(Y\\) frente a \\(X\\) ya permite valorar si es razonable suponer que se cumplen los supuestos requeridos. Si nada hace suponer lo contrario, supondremos que se cumplen. En realidad nunca se cumpliran “exactamente” pero si el comportamiento de los datos no se aleja mucho de los supuestos realizados, los intervalos de confianza y las pruebas de significación en que estamos interesdos seguirán siendo válidos a efectos prácticos.\n\n\nSignificación de los coeficientes. Visión intuitiva\nUsaremos los datos que ya vimos (apartado 14.3 ) sobre el volumen de madera que se obtiene de un árbol en función del diámetro de su tronco y sobre la edad al morir en función de la longitud de una línea de la mano. La figura 14.18 contiene las rectas ajustadas y también los valores que usaremos para la simulación.\n===No sé si esto se puede meter en algún sitio: Aunque a la vista de los gráficos ya se ve muy claro que el caso del volumen de madera la pendiente es significativa y en el de la línea de la mano seguramente no lo es, vamos a comprobar por simulación que, efectivametne, es así===\n\n\n\nFigura 14.18: Modelos ajustados. Se indica el número de datos (\\(n\\)), la desviación típica de los residuos (\\(s_R\\)), la media y la desviación típica de los valores de \\(X\\) (\\(\\bar{x}\\) y \\(s_X\\)) y la media de los valores de Y (\\(\\bar{y}\\)).\n\n\nSi no hay ninguna relación entre la variable regresora (\\(X\\)) y la respuesta (\\(Y\\)), la pendiente de la recta estará en torno a cero (será igual a cero en la población, pero no disponemos de esos datos que –además– son solo un modelo teórico). Para ver lo que significa “en torno a cero” en los casos que estamos tratando, podemos simular nubes de puntos manteniendo las características de \\(X\\) e \\(Y\\) de forma independiente, suponiendo que no existe ninguna relación entre ellas.\nEn el caso del volumen de madera empezamos generando 31 números aleatorios (una cantidad igual a nuestro tamaño de muestra) que asignamos al diámetro de los troncos. Para que estos datos se puedan considerar del mismo tipo de los que tenemos en la muestra es razonable generarlos de una distribución Normal con la media \\((\\bar{x} = 13.25)\\) y la desviación típica \\((s_X = 3.2)\\) de los valores que aparecen en la muestra, es decir: \\(X \\sim N(13.25; 3.2)\\). A continuación, a cada valor de \\(X\\) le hacemos corresponder un valor de \\(Y\\) igual a la media de los valores disponibles \\((\\bar{y} = 30.2)\\) añadiendo un número aleatorio de una distribución Normal con media cero (ni sube ni baja de forma sistemática el valor de la respuesta) y una desviación típica igual a la que presentan los residuos del modelo ajustado \\((s_R = 4.25)\\). Por tanto, tendremos: \\(Y = 30.2 + N(0; 4.25)\\).\nPara el modelo de la edad al morir hacemos exactamente lo mismo con los valores que corresponden. La tabla 14.6 contiene los usados en cada caso.\n\n\nTabla 14.6: Valores usados para la simulación.\n\n\n\n\\(n\\)\nValores de \\(X\\)\nValores de \\(Y\\)\n\n\n\n\nVolumen de madera:\n31\n\\(N(13.25; 3.2)\\)\n\\(30.2 + N(0; 4.25)\\)\n\n\nEdad al morir\n50\n\\(N(13.25; 3.2)\\)\n\\(66.7 + N(0; 14.15)\\)\n\n\n\n\nPara cada conjunto de puntos simulados se ha calculado la recta ajustada. En los dos casos la simulación se ha repetido 50 veces y en los diagramas de la figura 14.19 se han ido acumulando tanto los puntos como las rectas ajustadas. También se ha añadido, de color verde, la línea correspondiente a los datos de la muestra. Está muy claro que en el caso del volumen de madera, la recta ajustada con los datos de la muestra no se puede confundir con los generados aleatoriamente suponiendo que no hay relación entre ambas variables. Sin embargo, en el caso de la edad al morir, la recta que corresponde a los datos disponibles se confunde con las que hemos simulado, por tanto, el valor de la pendiente queda explicado por la variabilidad intrínseca de los datos, diremos que esa diferencia no es estadísticamente significativa.\n\n\n\nFigura 14.19: Distribución de los coeficientes.\n\n\n\n\n\nPruebas de significación formales\nAunque pueden no ser necesarias en casos tan claros como los que acabamos de ver, conocer la distribución de los coeficientes nos permite realizar pruebas de significación de manera más directa, sin necesidad de realizar simulaciones.\n\n\n\n\n\n\nPruebas de significación y contraste de hipótesis\n\n\n\nUna prueba de significación es un caso particular de contraste de hipótesis donde se contrasta que el valor del parámetro es igual a cero. Significación equivale a “significativamente distinto de cero” es decir, que la variabilidad aleatoria no justifica la diferencia respecto a cero.\n\n\nLo habitual es contrastar que el coeficiente, ya sea \\(\\beta_0\\) o \\(\\beta_1\\) es igual a cero frente a la alternativa de que es distinto de cero.\n\nSobre el valor de la ordenada en el origen, \\(\\beta_0\\)\nTiene interés cuando hay razones para suponer que la recta pasa por el origen de coordenadas. Permite verificar que los resultados obtenidos no están en contradicción con ese supuesto.\nSi los datos cumplen las condiciones que antes hemos comentado tendremos:\n\\[b_0 \\sim N \\left(\\beta_0; \\; \\sigma_{b_0} \\right)\\] luego si \\(\\beta_0 = 0\\):\n\\[ \\frac{b_0-0}{\\sigma_{b_0}} \\sim N (0; 1) \\]\nPero como no conocemos \\(\\sigma_{b_0}\\) y usamos su estimación \\(s_{b_0}\\), el estadístico de prueba es:\n\\[ T = \\frac{b_0}{s_{b_0}} \\] y su distribución de referencia es una \\(t\\)-Student con \\(n-2\\) grados de libertad, siendo \\(n\\) el número de datos disponibles. Los 2 grados de libertad que se pierden tienen que ver con las restricciones que presentan los residuos cuando el modelo se ha ajustado por el método de los mínimos cuadrados \\(\\left ( \\sum e_i = 0 \\; \\text{y} \\; \\sum e_ix_i = 0 \\right )\\).\nComo regla general, si \\(|T| &gt; 2\\), es decir, el valor obtenido está a más de dos desviaciones típicas de cero, se rechaza la hipótesis nula. Por supuesto, también se puede calcular el \\(p\\)-valor exacto y tomar la decisión de acuerdo con el nivel de significación establecido.\nSi se decide eliminar \\(b_0\\) del modelo es necesario recalcular el valor de \\(b_1\\) con una fórmula específica para esta situación puesto que ya no estamos aplicando el criterio de los mínimos cuadrados. En el apéndice 10.4 se comentan algunas peculiaridades de este caso particular.\n\n\nSobre el valor de la pendiente de la recta, \\(\\beta_1\\)\nEste contraste siempre tiene interés. Se trata de verificar que la pendiente de la recta es significativamente distinta de cero. Si no lo es, una recta horizontal es compatible con los datos por lo que no se puede afirmar que haya relación entre la variable regresora y la respuesta.\nEl procedimiento es idéntico que para \\(\\beta_0\\). El estadístico de prueba ahora es:\n\\[ T = \\frac{b_1}{s_{b_1}} \\sim t-\\text{Student} \\;\\text{con} \\; n-2 \\; \\text{grados de libertad} \\]\n\n\n\n\n\n\nLigando las pruebas se significación para \\(r\\) y para \\(b_1\\)\n\n\n\nAquí texto\n\n\n\n\nResultados presentados por los paquetes de software estadístico\nEn general, los paquetes de software estadístico además de presentar los coeficientes del modelo también presentan los \\(p\\)-valores asociados a los contrastes que hemos comentado. La figura 14.19 muestra parte de la salida que proporciona el paquete de software estadístico Minitan en los dos casos que estamos considerando. Los coeficientes se calculan con las fórmulas que hemos deducido en el apartado 14.2 y sus desviaciones típicas con las que aparecen en el apéndice 10.2. Tal como hemos visto, el T-value que aparece en el listado es simplemente el cociente entre el coeficiente (Coef) y su desviación típica (SE Coef) y el p-valor (P-Value) es el área de cola -multiplicado por 2, ya que es una prueba bilateral- que deja ese T-Value en una distribución t-Student con \\(n-2\\) grados de libertad, siendo \\(n\\) el número de puntos usados en cada caso.\n\n\n\nFigura 14.20: Salida del paquete de software estadístico Minitab al ajustar modelos de regresión en los dos ejemplos que hemos visto.\n\n\nTambién puede interesar contrastar otros valores para la pendiente de la recta. Para verificar que un aparato mide correctamente la concentración de monoxido de carbono (CO) en el aire, se mide la concentración de 11 muestras con valores conocidos. Los resultados obtenidos son los que se indican en la tabla 14.7 (Navidi 2010, pág. 585).\n\n\nTabla 14.7: Concentración de CO. Valores reales y valores medidos (ppm)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nValor real\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\n\n\nValor medido\n1\n11\n21\n28\n37\n48\n56\n68\n75\n86\n96\n\n\n\n\nLa figura 14.21 (izq.) muestra el diagrama bivariante de los valores medidos frente a los reales con su recta ajustada. El aparato estará bien calibrado si -en promedio- el valor de la concentración medida es igual a la concentración real. Es decir, si los datos se ajustan al modelo: \\(y = x\\).\n\n\n\nFigura 14.21: Recta ajustada de la concentración medida frente a la real (izq.). Rectas simuladas suponiendo que -en promedio- la concentración medida es igual a la real (der.)\n\n\nUsando Minitab tenemos los coeficientes del modelo y la prueba de significación para sus valores (figura 14.22).\n\n\n\nFigura 14.22: Salida del paquete de software estadístico Minitab al ajustar modelos de regresión en los dos ejemplos que hemos visto.\n\n\nVemos que la ordenada en el origen (Minitab le llama “Constant” pero ya dijimos que esta no nos parece una denominación adecuada) no es significativamente distinta de cero por lo que hemos recalculado el modelo sin ese término. En el nuevo modelo el valor de \\(b_1\\) (coeficiente de la concentración real) es claramente significativo (significativamente distinto de cero) pero no es eso lo que nos preocupa. Lo que queremos saber es si es significativamente distinto de 1. Minitab no lo hace automaticamente pero es muy fácil hacerlo a mano:\n\\[  T =  \\frac{b_1-1}{s_{b_1}} = \\frac{0.95351-1}{0.00598} = -7.77\\] Si efectivamente \\(\\beta_1 = 1\\) el valor de \\(T\\) pertenece a una distribución \\(t\\)-Student, pero si lo fuera su valor estaría comprendido aproximadamente entre -2 y 2, y el valor que hemos obtenido está muy lejos de este intervalo. Por tanto, la hipótesis nula de que \\(\\beta_1=1\\) queda descartada. El aparato no está bien calibrado.\nEn la figura 14.21 (der.) se han representado las rectas ajustadas (color azul) de valores de la concentración medida (\\(y\\)) en función de la concentración real (\\(x\\)) generados con el modelo \\(y = x + e\\) siendo \\(e\\) valores de una distribución Normal con media cero y una desviación típica igual a la que presentan los residuos del modelo obtenido. La recta ajustada con los datos reales aparece de color verde (es la misma que tenemos en el diagrama de la izquierda), claramente se ve que no se confunde con las generadas aleatoriamente suponiendo que el aparato está bien calibrado, a partir de una concentración de 50 tiende a dar valores menores que los reales.\n\n\n\n14.6.1 Intervalos de confianza para la respuesta\n-Intervalos de confianza para las predicciones.\nMas/menos dos sigmas de los residuos y listos.\n-IC para las observaciones."
  },
  {
    "objectID": "63_regresionMultiple.html#las-cosas-no-son-como-parecen",
    "href": "63_regresionMultiple.html#las-cosas-no-son-como-parecen",
    "title": "15  Regresión Múltiple",
    "section": "15.1 Las cosas no son como parecen",
    "text": "15.1 Las cosas no son como parecen\nEjemplo con 3 variables. Ejemplo examen."
  },
  {
    "objectID": "63_regresionMultiple.html#fuerza-bruta.-aquí-va-en-serio.",
    "href": "63_regresionMultiple.html#fuerza-bruta.-aquí-va-en-serio.",
    "title": "15  Regresión Múltiple",
    "section": "15.2 Fuerza bruta. Aquí va en serio.",
    "text": "15.2 Fuerza bruta. Aquí va en serio.\nBest subsets"
  },
  {
    "objectID": "63_regresionMultiple.html#un-caso-sencillo-una-variable-cuantitativa-y-otra-cualitativa",
    "href": "63_regresionMultiple.html#un-caso-sencillo-una-variable-cuantitativa-y-otra-cualitativa",
    "title": "15  Regresión Múltiple",
    "section": "15.3 Un caso sencillo: Una variable cuantitativa y otra cualitativa",
    "text": "15.3 Un caso sencillo: Una variable cuantitativa y otra cualitativa\npeso, altura, sexo, y datos UFFI (creo)"
  },
  {
    "objectID": "63_regresionMultiple.html#ojo-con-las-explicaciones-milagrosas",
    "href": "63_regresionMultiple.html#ojo-con-las-explicaciones-milagrosas",
    "title": "15  Regresión Múltiple",
    "section": "15.4 Ojo con las explicaciones milagrosas",
    "text": "15.4 Ojo con las explicaciones milagrosas\nTantos parámetros como datos"
  },
  {
    "objectID": "63_regresionMultiple.html#modelos-explicativos-y-modelos-predictivos",
    "href": "63_regresionMultiple.html#modelos-explicativos-y-modelos-predictivos",
    "title": "15  Regresión Múltiple",
    "section": "15.5 Modelos explicativos y modelos predictivos",
    "text": "15.5 Modelos explicativos y modelos predictivos\ntexto"
  },
  {
    "objectID": "63_regresionMultiple.html#a-tener-en-cuenta",
    "href": "63_regresionMultiple.html#a-tener-en-cuenta",
    "title": "15  Regresión Múltiple",
    "section": "15.6 A tener en cuenta",
    "text": "15.6 A tener en cuenta\nAnálisis exploratoio más complicado Lo mismo con el análisis de los residuos\nOtras medidas de calidad del ajuste.\nLa regresión no sirve para todo.\nEl valor de un coeficiente, si no va acompañado del valor de su desviación típica, no sirve prácticamente para nada."
  },
  {
    "objectID": "42_Proceso_CH.html",
    "href": "42_Proceso_CH.html",
    "title": "9  Esquema de razonamiento",
    "section": "",
    "text": "Todo provisional.\nDados de Wolf\nQuizá Apéndice sobre por qué este tipo de razonamiento es controvertido (libro respuestas).",
    "crumbs": [
      "CONTRASTE DE HIPÓTESIS",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Esquema de razonamiento</span>"
    ]
  },
  {
    "objectID": "41_Conceptos_CH.html",
    "href": "41_Conceptos_CH.html",
    "title": "8  Conceptos",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n\nCódigo\n1 + 1\n\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. «Literate Programming». Comput. J. 27 (2): 97-111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "43_tiposError_CH.html",
    "href": "43_tiposError_CH.html",
    "title": "10  Tipos de error",
    "section": "",
    "text": "Este título es provisional"
  },
  {
    "objectID": "51_floresAspirina.html",
    "href": "51_floresAspirina.html",
    "title": "11  ¿La Aspirina alarga la vida de las flores?",
    "section": "",
    "text": "Planteamiento de la pregunta de manera clara y concreta\nDiseño de la recogida de los datos\nAnálisis de los resultados (distribución binomial)"
  },
  {
    "objectID": "52_duracionPilas.html",
    "href": "52_duracionPilas.html",
    "title": "12  ¿Duran más las pilas caras?",
    "section": "",
    "text": "Pregunta clara y concreta\nDiseño de la recogida de los datos con todas sus vicisitudes.\nAnálisis de los datos. Prueba no paramétrica y t-Student."
  },
  {
    "objectID": "62_regresionSimple.html#calidadAjuste",
    "href": "62_regresionSimple.html#calidadAjuste",
    "title": "14  Regresión Simple",
    "section": "14.3 Calidad del ajuste",
    "text": "14.3 Calidad del ajuste\nEl gráfico de la izquierda de la figura 14.8 muestra la relación entre la longitud de la circunferencia (X) de los troncos de un determinado tipo de árbol y el volumen de madera (Y) que se puede obtener de ellos (Fuente: Wolfram_Data_Repository 2016). Se observa que a más circunferencia mayor volumen de madera, tal como era de esperar, y la ecuación de la recta ajustada es útil para estimar cuanta madera se obtendrá de un tronco de determinado diámetro. Sin embargo, el gráfico de la derecha se ha realizado con los datos de un estudio publicado por Wilson y Mather (1974) citado por Draper y Smith (1998) donde se analiza la relación entre la edad al morir y la longitud de cierta línea de la mano a partir de una muestra de 50 personas fallecidas. A la vista del diagrama queda claro que no hay ninguna relación entre ambas variables. En este caso el modelo ajustado no sirve absolutamente para nada. Pero los dos modelos tienen el mismo aspecto y solo a la vista del valor de sus coeficientes es imposible saber cual de los dos es útil.\n\n\n\nFigura 14.8: Relación muy clara y relación inexistent, situaciones que no pueden distinguirse solo a la vista del modelo ajustado.\n\n\nEs necesario, por tanto, completar el modelo con una medida que informe de la calidad del ajuste obtenido. Esa medida es el coeficiente de determinación \\(R^2\\).\nPara calcular el valor de \\(R^2\\) empezamos poniéndonos en el peor de los casos: suponemos que \\(X\\) e \\(Y\\) son independientes, es decir, que el valor de \\(X\\) no aporta ninguna información sobre el valor de \\(Y\\). En este caso, la recta que muestra la relación entre ambas variables es una recta horizontal: la estimación del valor de \\(Y\\) es siempre la misma, sin importar el valor de \\(X\\), y la mejor apuesta para ese valor de \\(Y\\) -a falta de cualquier otra información- es su valor medio \\(\\bar{y}\\). A la suma de los cuadrados de los residuos correspondientes a esa recta horizontal que pasa por \\(\\bar{y}\\) le llamamos \\(Q_Y\\).\nA continuación calculamos la suma de los cuadrados de los residuos correspondientes a nuestra recta ajustada (la que minimiza la suma de los cuadrados de los residuos) y le llamaremos \\(Q_R\\). Cuanto mejor sea el ajuste menor será el valor de \\(Q_R\\) y mayor la diferencia entre \\(Q_Y\\) y \\(Q_R\\).\nEl valor de \\(R^2\\) es igual a la proporción de \\(Q_Y\\) explicada por \\(X\\), es decir, la proporción en que disminuye \\(Q_Y\\) gracias a la introducción de \\(X\\) como variable explicativa, es decir:\n\\[ R^2 = \\frac{Q_Y - Q_R}{Q_Y} \\]\nVeamos este cálculo en un ejemplo con datos sencillos. En la figura 14.9 tenemos 5 puntos que podrían representar la relación entre el peso y la estatura de 5 individuos. Si, ignorando la información aportada por la estatura, siempre damos una estimación del peso igual a su valor medio, será como ajustar a una recta horizontal y tendremos una suma de los cuadrados de los residuos \\(Q_Y = 56\\). Sin embargo, si utilizamos la información que aporta la estatura y realizamos el ajuste minimizando la suma de los cuadrados de los residuos tenemos \\(Q_R = 16\\).\n\n\n\nFigura 14.9: Múltiples opciones para minimizar la suma de los residuos en valor absoluto.\n\n\nHemos reducido la suma de los cuadrados de los residuos de 56 a 16, por tanto:\n\\[ R^2 = \\frac{Q_Y - Q_R}{Q_Y} = \\frac{56 - 16}{56} = 0.7143 \\]\nNormalmente nos referimos a este valor como un porcentaje. En este caso sería el 71.43%. En los ejemplos de la figura 14.8 estos valores son del 93,5% (volumen de madera) y 1,5% (edad al morir).\n\n\n\n\n\n\n\\(R^2\\) es el cuadrado del coeficiente de correlación \\(r\\)\n\n\n\nEfectivamente, en el caso que estamos considerando de regresión simple, el coeficiente de determinación \\(R^2\\) es igual al cuadrado del coeficiente de correlación \\(r\\). Este último puede variar entre \\(-1\\) y \\(1\\) por lo que, obviamente, \\(R^2\\) varía entre 0 y 1. La demostración es corta y fácil de encontrar en internet. Por ejemplo en:"
  },
  {
    "objectID": "62_regresionSimple.html#sec-calidadAjuste",
    "href": "62_regresionSimple.html#sec-calidadAjuste",
    "title": "14  Regresión Simple",
    "section": "14.3 Calidad del ajuste",
    "text": "14.3 Calidad del ajuste\nEl gráfico de la izquierda de la figura 14.8 muestra la relación entre la longitud de la circunferencia (X) de los troncos de un determinado tipo de árbol y el volumen de madera (Y) que se puede obtener de ellos (Fuente: Wolfram_Data_Repository 2016). Se observa que a más circunferencia mayor volumen de madera, tal como era de esperar, y la ecuación de la recta ajustada es útil para estimar cuanta madera se obtendrá de un tronco de determinado diámetro. Sin embargo, el gráfico de la derecha se ha realizado con los datos de un estudio publicado por Wilson y Mather (1974) citado por Draper y Smith (1998) donde se analiza la relación entre la edad al morir y la longitud de cierta línea de la mano a partir de una muestra de 50 personas fallecidas. A la vista del diagrama queda claro que no hay ninguna relación entre ambas variables. En este caso el modelo ajustado no sirve absolutamente para nada. Pero los dos modelos tienen el mismo aspecto y solo a la vista del valor de sus coeficientes es imposible saber cual de los dos es útil.\n\n\n\nFigura 14.8: Relación muy clara y relación inexistent, situaciones que no pueden distinguirse solo a la vista del modelo ajustado.\n\n\nEs necesario, por tanto, completar el modelo con una medida que informe de la calidad del ajuste obtenido. Esa medida es el coeficiente de determinación \\(R^2\\).\nPara calcular el valor de \\(R^2\\) empezamos poniéndonos en el peor de los casos: suponemos que \\(X\\) e \\(Y\\) son independientes, es decir, que el valor de \\(X\\) no aporta ninguna información sobre el valor de \\(Y\\). En este caso, la recta que muestra la relación entre ambas variables es una recta horizontal: la estimación del valor de \\(Y\\) es siempre la misma, sin importar el valor de \\(X\\), y la mejor apuesta para ese valor de \\(Y\\) -a falta de cualquier otra información- es su valor medio \\(\\bar{y}\\). A la suma de los cuadrados de los residuos correspondientes a esa recta horizontal que pasa por \\(\\bar{y}\\) le llamamos \\(Q_Y\\).\nA continuación calculamos la suma de los cuadrados de los residuos correspondientes a nuestra recta ajustada (la que minimiza la suma de los cuadrados de los residuos) y le llamaremos \\(Q_R\\). Cuanto mejor sea el ajuste menor será el valor de \\(Q_R\\) y mayor la diferencia entre \\(Q_Y\\) y \\(Q_R\\).\nEl valor de \\(R^2\\) es igual a la proporción de \\(Q_Y\\) explicada por \\(X\\), es decir, la proporción en que disminuye \\(Q_Y\\) gracias a la introducción de \\(X\\) como variable explicativa, es decir:\n\\[ R^2 = \\frac{Q_Y - Q_R}{Q_Y} \\]\nVeamos este cálculo en un ejemplo con datos sencillos. En la figura 14.9 tenemos 5 puntos que podrían representar la relación entre el peso y la estatura de 5 individuos. Si, ignorando la información aportada por la estatura, siempre damos una estimación del peso igual a su valor medio, será como ajustar a una recta horizontal y tendremos una suma de los cuadrados de los residuos \\(Q_Y = 56\\). Sin embargo, si utilizamos la información que aporta la estatura y realizamos el ajuste minimizando la suma de los cuadrados de los residuos tenemos \\(Q_R = 16\\).\n\n\n\nFigura 14.9: Múltiples opciones para minimizar la suma de los residuos en valor absoluto.\n\n\nHemos reducido la suma de los cuadrados de los residuos de 56 a 16, por tanto:\n\\[ R^2 = \\frac{Q_Y - Q_R}{Q_Y} = \\frac{56 - 16}{56} = 0.7143 \\]\nNormalmente nos referimos a este valor como un porcentaje. En este caso sería el 71.43%. En los ejemplos de la figura 14.8 estos valores son del 93,5% (volumen de madera) y 1,5% (edad al morir).\n\n\n\n\n\n\n\\(R^2\\) es el cuadrado del coeficiente de correlación \\(r\\)\n\n\n\nEfectivamente, en el caso que estamos considerando de regresión simple, el coeficiente de determinación \\(R^2\\) es igual al cuadrado del coeficiente de correlación \\(r\\). Este último puede variar entre \\(-1\\) y \\(1\\) por lo que, obviamente, \\(R^2\\) varía entre 0 y 1. La demostración es corta y fácil de encontrar en internet. Por ejemplo en:"
  },
  {
    "objectID": "62_regresionSimple.html#sec-calculoCoeficientes",
    "href": "62_regresionSimple.html#sec-calculoCoeficientes",
    "title": "14  Regresión Simple",
    "section": "14.2 Mínimos cuadrados. Cálculo de los coeficientes",
    "text": "14.2 Mínimos cuadrados. Cálculo de los coeficientes\nExiste una fórmula cerrada y con solución única para cada coeficiente, pero vamos a empezar identificando el valor de los coeficientes sin hacer uso de las fórmulas. Naturalmente, es mucho más rápido y más práctico usarlas o -mejor todavía- usar un paquete de software estadístico o una hoja de cálculo, pero hacerlo sin fórmulas permite entender perfectamente qué es lo que se está haciendo, y también descubrir algún detalle interesante.\n\nSin fórmulas\nRealizamos a ojo una primera estimación del valor de los coeficientes. A continuación, mediante un pequeño programa -o también usando una hoja de cálculo-, hacemos un barrido de los valores de \\(b_0\\) y \\(b_1\\) en torno a los estimados, identidicando el par que minimiza la suma de los cuadrados de los residuos.\nVayamos al diagrama de la figura 14.7 (izquierda) que ya habíamos visto en las figuras 14.2 y 14.3. La recta ajustada a ojo pasa por los puntos (-4,75; 0) y (5,75, 60) por lo que sus coeficientes son: \\(b_1\\) = 5,71 y \\(b_0\\) = 27,14. Sería mucha casualidad que esos fueran los valores exactos que estamos buscando, pero no andarán muy lejos. Vamos a crear una malla de valores de \\(b_0\\) y \\(b_1\\). Los valores de \\(b_0\\) variarán de 2 a 8 con incrementos de 0,1 y para cada uno de esos, los de \\(b_0\\) irán de 20 a 35 también en saltos de 0,1. A cada combinación de esos dos valores corresponde a una recta, y a cada recta una suma de los cuadrados de los residuos. El par de valores que minimizan esa suma de cuadrados son: \\(b_0\\) = 27,0 y \\(b_1\\) = 4,8.\n\n\n\nFigura 14.7: Recta ajustada a ojo (izq.) y suma de los cuadrados de los residuos para cada par de valores \\(b_0\\) y \\(b_1\\). En rojo, valores que la minimizan (der.).\n\n\n\n\n\n\n\n\nParaboloide de la suma de cuadrados\n\n\n\nCon los datos de nuestro ejemplo, la superficie que representa la suma de los cuadrados de los residuos es un paraboloide donde la localización del mínimo es visulamente muy clara. Pero lo nomal es que las curvas de nivel sean muy elípticas de manera que la representación no queda tan clara. Nosotros hemos logrado esa forma regular haciendo que la media de los valores de \\(X\\) sea igual a cero. De esta forma, los coeficientes son independientes y las curvas de nivel apararecen como círculos prácticamente concéntricos quedando más clara la idea que queremos representar.\n\n\n\n\nUsando las fórmulas\nEn el diagrama que representa la relación entre \\(X\\) e \\(Y\\) cada punto puede ser identificado por sus coordenadas \\((x_i, y_i)\\) con \\(1 \\leq i \\leq n\\) siendo \\(n\\) el número total de puntos. [creo que esto es redundante y habría que mejorarlo]\nCada uno de los puntos tiene un residuo asociado \\(e_i\\) y ese residuo es la diferencia entre el valor real de \\(y\\), es decir, \\(y_i\\) y su valor estimado \\(\\hat{y}_i\\), el que estará sobre la recta y que será igual a \\(b_0 + b_1 x_i\\). Por tanto, el valor del residuo asociado al punto \\(i\\) lo podemos escribir de la forma:\n\\[ e_i = y_i - \\left( b_0 + b_1 x_i \\right) \\] Por tanto, la suma de los cuadrados de los residuos, \\(S\\), será:\n\\[ S = \\sum_{í=1}^n \\left(y_i - b_0 - b_1 x_i \\right )^2 \\]\nTanto los valores de \\(y_i\\) como los de \\(x_i\\) vienen dados. La suma de cuadrados \\(S\\) es función de los valores de \\(b_0\\) y de \\(b_1\\). Se trata de hallar los valores de \\(b_0\\) y de \\(b_1\\) que minimizan esa suma de cuadrados. El mínimo lo tendremos en el punto en que la derivada de \\(S \\left(b_0, b_1 \\right )\\) respecto a \\(b_0\\) y respecto a \\(b_1\\) es igual a cero. Seguro que es un mínimo porque el máximo no está definido.\n\\[ \\frac{\\partial S}{\\partial b_0} = -2 \\sum_{í=1}^n \\left(y_i - b_0 - b_1 x_i \\right ) \\]\n\\[ \\frac{\\partial S}{\\partial b_1} = -2 \\sum_{í=1}^n \\left(y_i - b_0 - b_1 x_i \\right ) x_i \\]\nIgualando a cero estas expresiones:\n\\[ \\sum_{í=1}^n y_i - nb_0 - b_1 \\sum_{í=1}^n x_i = 0  \\tag{14.1}\\]\n\\[ \\sum_{í=1}^n x_i y_i - b_0 \\sum_{í=1}^n x_i - b_1 \\sum_{í=1}^n  x_i^2  = 0  \\tag{14.2}\\]\nDividiendo por \\(n\\) todos los términos de la ecuación 14.1 tenemos:\n\\[ b_0 = \\bar{y} - b_1 \\bar{x} \\]\n\n\n\n\n\n\nLa recta ajustada pasa por el punto \\((\\bar{x}, \\bar{y})\\)\n\n\n\nDe la anterior expresón para \\(b_0\\) también se decude que \\(\\bar{y} = b_0 + b_1\\bar{x}\\). Es decir, la recta ajustada minimizando la suma de los cuadrados de los residuos siempre pasa por el punto \\((\\bar{x}, \\bar{y})\\) .\n\n\nSustituyendo la expresión de \\(b_0\\) en la ecuación 14.2 tenemos:\n\\[ \\sum_{í=1}^n x_i y_i - \\bar{y} \\sum_{í=1}^n x_i +  b_1\\bar{x} \\sum_{í=1}^n x_i- b_1 \\sum_{í=1}^n  x_i^2  = 0 \\]\nPara aligerar la notación no pondremos los límites a los sumatorios, que siempre son desde \\(i=1\\) hasta \\(n\\). Despejando \\(b_1\\) llegamos a:\n\\[ b_1 = \\frac{\\sum x_i y_i - \\bar{y} \\sum x_i}{\\sum x_i^2 - \\bar{x} \\sum x_i} \\] También la expresión de \\(b_1\\) se suele dar de la forma (ver Apéndice 10.1):\n\\[ b_1 = \\frac{\\sum (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum (x_i - \\bar{x})^2}  \\tag{14.3}\\]\nA partir de la ecuación 14.3 y recordando las expresiones de la covarianza y del coeficiente de correlación, llegamos a una expresión que también se ve con frecuencia en los libros de texto, seguramente porque una calculadora sencilla da directamente los tres valores que intervienen:\n\\[ b_1 = \\frac{Cov(XY)}{s_X^2} = \\frac{r_{XY} s_X s_Y}{s_X^2} = r_{XY} \\frac{s_Y}{s_X} \\] Calculando los coeficientes que corresponden a los datos de la figura 14.7 se obtiene:\n\\[ b_0 = 26,9615 \\qquad  \\qquad b_1 = 4,8616 \\] Ahora sí, con todos los decimales que queramos, aunque dar más decimales de los que tienen los datos es añadir números que no aportant ninguna información, dan una falsa sensación de precisión y complican la lectura del resultado.\n\n\n\n\n\n\n\nPor qué le llamamos modelo de regresión\n\n\n\nSean, por ejemplo, los puntos: (4; 3), (6; 8), (8; 12), (10; 10), (12; 12). La recta ajustada es: \\(y = 1+x\\). Si en vez de ajustar \\(y = f(x)\\) se ajusta \\(x=f(y)\\) ¿se obtendrá la ecuación resultante de despejar \\(x\\) en \\(y=f(x)\\), es decir: \\(x = -1 + y\\)? Si ajustamos \\(x=f(y)\\) la ecuación será: \\(x=1,57+0,714x\\). No es lo mismo minimizar la suma de los cuadrados de los residuos medidos en dirección vertical que en dirección horizontal (esto último no son los residuos)."
  },
  {
    "objectID": "11_sintesisNumerica.html",
    "href": "11_sintesisNumerica.html",
    "title": "1  Síntesis numérica de datos",
    "section": "",
    "text": "1.1 Medidas de tendencia central\nLa cantinela “media, mediana y moda” –medidas de tendencia central por excelencia– constitue para muchos el primer recuerdo de su recorrido por el curso de estadística. Vamos a repasar el significado, los peligros y lo que se puede esperar de cada una de estas medidas.",
    "crumbs": [
      "ESTADÍSTICA DESCRIPTIVA",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Síntesis numérica de datos</span>"
    ]
  },
  {
    "objectID": "11_sintesisNumerica.html#acknowledgments",
    "href": "11_sintesisNumerica.html#acknowledgments",
    "title": "1  Síntesis numérica de datos",
    "section": "1.5 Acknowledgments",
    "text": "1.5 Acknowledgments\ntexto\ntexto\ntexto\ntexto\ntexto\ntexto\ntexto\ntexto\n¿Qué hace esto aquí?"
  },
  {
    "objectID": "11_sintesisNumerica.html#apéndice-1.1-otras-medias",
    "href": "11_sintesisNumerica.html#apéndice-1.1-otras-medias",
    "title": "1  Síntesis numérica de datos",
    "section": "Apéndice 1.1: Otras medias",
    "text": "Apéndice 1.1: Otras medias\nCitar también la media ponderada y la media truncada.\n\nMedia geométrica\nSi una población tenía 10.000 habitantes en el año cero, creció el primer año a una tasa del 5 %, el segundo a una tasa del 20 % y el tercer año al 50 % ¿A que tasa promedio ha crecido en estos tres años?\n\n\n\nTabla 1.10: Evolución de la población\n\n\n\n\n\n\n\n\n\n\n\n\nAño\nPoblación inicial\nTasa de crecimiento\nFactor de expansión\nPoblación al final del año\n\n\n\n\n1\n10.000\n0,05\n1,05\n10.500\n\n\n2\n10.500\n0,20\n1,20\n12.600\n\n\n3\n12.600\n0,50\n1,50\n18.900\n\n\n\n\n\n\nSi calculamos la media aritmética de la tasa de crecimiento tenemos: \\((0,05 + 0,20 + 0,50)/3 = 0,25\\) y el factor medio de expansión sería \\(1,25\\). Pero si la población hubiera crecido los tres años de esta forma, no se llegaría al mismo resultado final:\n\n\n\nTabla 1.11: Evolución de la población\n\n\n\n\n\n\n\n\n\n\n\n\nAño\nPoblación inicial\nTasa de crecimiento\nFactor de expansión\nPoblación al final del año\n\n\n\n\n1\n10.000\n0,25\n1,25\n12.500\n\n\n2\n12.500\n0,25\n1,25\n15.625\n\n\n3\n15.625\n0,25\n1,25\n19.531\n\n\n\n\n\n\nPor tanto, la media aritmética no es un buen indicador de la tasa media de crecimiento.\nSi la población crece a una tasa constante \\(i\\), para que al final del tercer año tenga el mismo efecto que las tasas del ejemplo, se debe verificar que:\n\\[ 10\\,000(1+i)(1+i)(1+i)=10\\,000(1+0,05)(1+0,20)(1+0,50) \\] De donde:\n\\[(1+i)= \\sqrt[3]{1,05 \\cdot 1,20 \\cdot 1,50}=1,2364\\]\nSi se hubiera tenido este factor de expansión cada año (nótese que es la media geométrica), hubiera conducido a una población final igual a la que tenemos.\n\n\n\n\n\n\nCuriosidades sobre la media geométrica\n\n\n\n\nA diferencia de la media aritmética, la media geométrica sólo se define para números positivos.\nLa media geométrica nunca es mayor que la media aritmética. La demostración para el caso de 2 valores es fácil por reducción al absurdo. Supongamos que: \\(\\sqrt{ab} &gt; (a+b)/2\\), entonces \\(ab &gt; (a^2+2ab+b^2)/4\\), de donde: \\(0 &gt;a^2-2ab+b^2\\). Como \\(a^2-2ab+b^2=(a-b)^2\\) es imposible que este valor sea negativo, luego es imposible que \\(\\sqrt{ab}&gt;(a+b)/2\\).\n\n\n\n\n\nMedia armónica\nSe define la media armónica de \\(x_1, x_2, ..., x_N\\) como:\n\\[Mh = \\frac{N}{\\large{\\frac{1}{x_1}+\\frac{1}{x_2}+...+\\frac{1}{x_N}}}\\]\nParece que esto sea un retorcimiento sin ningún interés, pero no. Si un coche recorre cierta distancia a una velocidad de 100 km/h y vuelve por el mismo camino a 120 km/h, la velocidad media a que ha realizado el viaje es:\n\\[Mh = \\frac{2}{\\large{\\frac{1}{100}+\\frac{1}{120}}} = 109,1 \\text{ km/h}\\]\ny no 110 km/h como en principio se podría pensar.\nObserve que la velocidad es igual a la distancia recorrida dividida por el tiempo tardado en recorrerla, es decir \\(v=d/t\\) y por tanto \\(t=d/v\\). En nuestro caso, si la distancia a recorrer es \\(d\\), el tiempo tardado en la ida es \\(t_1 =d/100\\) y el tiempo tardado en el regreso es \\(t_2 =d/120\\). De esta manera el tiempo total invertido en todo el recorrido \\((2d)\\) será \\(t=t_1+t_2\\) y la velocidad media se calcula de la forma:\n\\[ \\text{Velocidad media} = \\frac{\\text{Distancia total recorrida}}{\\text{Tiempo total empleado}} = \\frac{2d}{\\large{\\frac{d}{100}+\\frac{d}{120}}} \\] Otro ejemplo: Un avión recorre 3000 km. Los 1000 primeros a 700 km/h, los 1000 siguientes a 800 km/h, y los 1000 restantes a 900 km/h ¿Cuál ha sido su velocidad media? No ha sido 800 km/h sino 791,6 km/h.",
    "crumbs": [
      "ESTADÍSTICA DESCRIPTIVA",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Síntesis numérica de datos</span>"
    ]
  },
  {
    "objectID": "11_sintesisNumerica.html#apéndice-a-otras-medias",
    "href": "11_sintesisNumerica.html#apéndice-a-otras-medias",
    "title": "1  Síntesis numérica de datos",
    "section": "Apéndice A: Otras medias",
    "text": "Apéndice A: Otras medias\n\nMedia geométrica\n\n\nMedia armónica"
  },
  {
    "objectID": "11_sintesisNumerica.html#varianza-o-variancia",
    "href": "11_sintesisNumerica.html#varianza-o-variancia",
    "title": "1  Síntesis numérica de datos",
    "section": "1.3 ¿Varianza o variancia?",
    "text": "1.3 ¿Varianza o variancia?\nLas dos son válidas según el diccionario de la Real Academia Española. Nosotros usaremos varianza.\n:::\ntexto\n\n\n\n\n\n\n¿Por qué se prefiere usar la varianza en vez de la distancia media?\n\n\n\nElevar al cuadrado las diferencias pudiendo trabajar con su valor absoluto parece una complicación innecesaria, pero la varianza tienes unas ventajas que la DM no tiene, por ejemplo:\n\nEn los desarrollos anteriores hemos visto que la media, medida descriptiva por excelencia, está asociada de forma más natural con la varianza que con la DM.\nLa \\(DM\\) incluye en su expresión la función “valor absoluto” que se comporta mal desde un punto de vista matemático, mientras que la función cuadrática es muy fácilmente tratable. Observe, por ejemplo, que la demostración de que la media hace mínimo el promedio de los cuadrados se ha realizado de forma casi inmediata, mientras que probar que la mediana hace mínima la media de las distancias es bastante más complejo.\nLa desviación estándar () de la población es usada para definir la distribución más famosa y útil, como es la Normal. Esto posibilita la construcción de intervalos de confianza para estimar, por ejemplo, la media de la población, lo que sería mucho más complejo si se usara la (DM).\nLa varianza es una suma de cuadrados que se puede descomponer en diversos sumandos dando origen al llamado ``Análisis de la Varianza’’. El desarrollo de la teoría de los modelos lineales está basado en gran parte en el criterio de los mínimos cuadrados, que es el mismo en que está basada la varianza. Cuando la población origen de los datos es Normal, el cociente de varianzas muestrales sigue una distribución conocida, llamada $ F $ de Snedecor.\nLa varianza de una suma de variables aleatorias se calcula de una forma muy fácil, especialmente si las variables son independientes. Por ejemplo, en un proceso de envasado, si el peso del envase tiene una varianza (V(X)) y la varianza del contenido es (V(Y)), la varianza del conjunto es (V(X+Y) = V(X) + V(Y)).\n\n\n\n\nDesviación típica\ntexto\ntexto\ntexto\ntexto\ntexto\ntexto\ntexto\ntexto"
  },
  {
    "objectID": "11_sintesisNumerica.html#la-variabilidad-en-relación-a-la-media-el-coeficiente-de-variación",
    "href": "11_sintesisNumerica.html#la-variabilidad-en-relación-a-la-media-el-coeficiente-de-variación",
    "title": "1  Síntesis numérica de datos",
    "section": "1.3 La variabilidad en relación a la media: El coeficiente de variación",
    "text": "1.3 La variabilidad en relación a la media: El coeficiente de variación\ntexto\ntexto"
  },
  {
    "objectID": "10_Parte_Descriptiva.html#footnotes",
    "href": "10_Parte_Descriptiva.html#footnotes",
    "title": "ESTADÍSTICA DESCRIPTIVA",
    "section": "",
    "text": "Incluso somo mejores que los ordenadores, que nos piden que interpretemos una imagen para confirmar que somos personas y no máquinas.↩︎"
  },
  {
    "objectID": "11_sintesisNumerica.html#apéndice-1.2-por-qué-dividimos-por-n-1",
    "href": "11_sintesisNumerica.html#apéndice-1.2-por-qué-dividimos-por-n-1",
    "title": "1  Síntesis numérica de datos",
    "section": "Apéndice 1.2: ¿Por qué dividimos por n-1?",
    "text": "Apéndice 1.2: ¿Por qué dividimos por n-1?\nVamos a trabajar con un ejemplo suponiendo que conocemos la población completa, lujo que no tendremos en la práctica. Los elementos que componen la población, junto con sus mediciones respectivas, son:\n\n\n\n(A)\n(B)\n(C)\n(D)\n(D)\n(E)\n\n\n2\n6\n8\n10\n10\n12\n\n\n\nEn primer lugar ilustraremos la propiedad de insesgamiento de un estimador para el caso de la media, con la cual estamos más familiarizados, y luego repetiremos la experiencia para el caso que nos ocupa de la varianza.\nLa media poblacional \\(\\mu\\), de los datos del ejemplo, es:\n\\[\\mu = \\frac{2+6+8+10+10+12}{6}=8\\] Supongamos que nosotros queremos estimar (“hacernos una idea”) el valor \\(\\mu\\), usando una muestra aleatoria de \\(n = 2\\) unidades. En este caso, en que la población consta sólo de 6 unidades, podemos hacer un listado de todas las muestras que pueden resultar al escoger dos unidades al azar. Estas muestras aparecen enumeradas en la siguiente tabla.\n\n    \n\n\n  \n\nMuestra nº\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n\nUnidades de  la muestra\nA  B\nA  C\nA  D\nA  E\nA  F\nB  C\nB  D\nB  E\nB  F\nC  D\nC  E\nC  F\nD  E\nD  F\nE  F\n\n\n   \n\nValores de  la muestra\n2  6\n2  8\n2  10\n2  10\n2  12\n6  8\n6  10\n6  10\n6  12\n8  10\n8  10\n8  12\n10  10\n10  12\n10  12\n\n\n\n \nMedia  muestral\n4 \n5 \n6 \n6 \n7 \n7 \n8 \n8 \n9 \n9 \n9 \n10 \n10 \n11 \n11 \n\n \n  \n\nCuando se seleccione al azar una muestra de dos unidades, el resultado será necesariamente alguna de estas 15 posibles combinaciones de 2 elementos, con su media \\(\\bar{x}\\) correspondiente.\nDecimos que \\(\\bar{x}\\) es un estimador insesgado de \\(\\mu\\) si el promedio de todas las posibles medias coincide exactamente con la media de la población. Para verificarlo, hagamos el promedio de nuestras 15 posibles medias:\n\\[ \\frac{4+5+6+6+7+7+8+8+9+9+9+10+10+11+11}{15}=8 \\]\nEl promedio coincide con \\(\\mu\\). Esto pasa en todos los casos, independientemente del tipo de población o del tamaño de la muestra, por eso decimos que \\(\\bar{x}\\) es un estimador insesgado de \\(\\mu\\).\nVeamos ahora si el estadístico:\n\\[  S_{n}^{2}= \\frac{ \\sum_{i=1}^{n}{(x_i-\\bar{x})^2} }{n} \\]\ndonde \\(n\\) es el tamaño de las muestras, es un estimador insesgado para la varianza \\(\\sigma_{N}^{2}\\), calculada como:\n\\[  \\sigma_{N}^{2}= \\frac{ \\sum_{i=1}^{N}{(x_i-\\mu)^2} }{N} \\]\ndonde \\(N\\) es el tamaño de la población. Queremos saber si el promedio de los valores de \\(S_{n}^{2}\\), para cada una de las posibles muestras, da el valor de \\(\\sigma_{N}^{2}\\) y para averiguarlo, en primer lugar vamos a calcular la varianza poblacional:\n\\[\\sigma_{N}^{2}= \\frac{(2-8)^2+(6-8)^2+(8-8)^2+...+(12-8)^2}{6} = 10,67 \\]\nAhora calculamos la varianza para cada muestra de 2 unidades, con la fórmula:\n\\[  S_{n}^{2}= \\frac{ (x_1 - \\bar{x})^2 + (x_2 - \\bar{x})^2 }{2} \\]\nobteniéndose los resultados que aparecen en la siguiente tabla:\n\n    \n\n\n  \n\nMuestra nº\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n   \n\nValores de  la muestra\n2  6\n2  8\n2  10\n2  10\n2  12\n6  8\n6  10\n6  10\n6  12\n8  10\n8  10\n8  12\n10  10\n10  12\n10  12\n\n\n\n \nVarianza  muestral\n4 \n9 \n16 \n16 \n25 \n1 \n4 \n4 \n9 \n1 \n1 \n4 \n0 \n1 \n1 \n\n \n  \n\nVeamos si el promedio de las posibles varianzas muestrales, coincide con 10,67 que es el valor obtenido para \\(\\sigma_{N}^{2}\\).\n\\[ \\bar{S}^2 = \\frac{4+9+16+16+25+1+4+4+9+...+1}{15} = 6,4 \\]\nNo coincide y, por tanto, \\(S_{n}^{2}\\) no es un estimador insesgado de \\(\\sigma_{N}^{2}\\). Sin embargo \\(S_{n-1}^{2}\\), definido de la forma:\n\\[S_{n-1}^{2}= \\frac{ \\sum_{i=1}^{n}{(x_i-\\bar{x})^2} }{n-1} \\]\naunque tampoco es un estimador insesgado para \\(\\sigma_{N}^{2}\\), sí lo es para \\(\\sigma_{N-1}^{2}\\) definido como:\n\\[\\sigma_{N-1}^{2}= \\frac{ \\sum_{i=1}^{N-1}{(x_i-\\mu)^2} }{N-1} \\]\nEfectivamente, \\(\\sigma_{N-1}^{2}\\) tiene el valor:\n\\[\\sigma_{N-1}^{2}= \\frac{(2-8)^2+(6-8)^2+(8-8)^2+...+(12-8)^2}{6-1} = 12,8 \\]\nY si calculamos \\(S_{n-1}^{2}\\) para cada una de nuestras muestras deberemos aplicar la fórmula:\n\\[S_{n-1}^{2}= \\frac{ (x_1 - \\bar{x})^2 + (x_2 - \\bar{x})^2 }{2-1} = \\frac{ (x_1 - \\bar{x})^2 + (x_2 - \\bar{x})^2 }{1}  \\]\nEs decir que todos los valores de la varianza que aparecen en la tabla anterior, quedan ahora multiplicados por 2 y por lo tanto la media de las varianzas queda también multiplicada por 2, es decir:\n\\[\\bar{S}_{n-1}^{2}= 2\\cdot 6,4 = 12,8 \\]\nQuizá este resultado decepcione, y hasta sorprenda, porque seguramente lo esperado era que \\(S_{n-1}^{2}\\) fuera un estimador insesgado de \\(\\sigma_{N}^{2}\\) y no de \\(\\sigma_{N-1}^{2}\\), pero no hay que preocuparse demasiado. A efectos prácticos es casi lo mismo cuando la población es grande, y nosotros no vamos a estimar a través de muestras las características de una población de 6 elementos (en nuestro ejemplo esta ha sido una población “de juguete” para entender lo que estábamos haciendo). Cuando estimemos la varianza de una población se tratará de una población grande, en la que \\(\\sigma_{N}^{2}\\) será prácticamente igual a \\(\\sigma_{N-1}^{2}\\). En realidad, el caso más frecuente es tener poblaciones teóricas (infinitas), en las que es exactamente lo mismo \\(\\sigma_{N}^{2}\\) que \\(\\sigma_{N-1}^{2}\\).",
    "crumbs": [
      "ESTADÍSTICA DESCRIPTIVA",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Síntesis numérica de datos</span>"
    ]
  },
  {
    "objectID": "11_sintesisNumerica.html#footnotes",
    "href": "11_sintesisNumerica.html#footnotes",
    "title": "1  Síntesis numérica de datos",
    "section": "",
    "text": "leyenda nota pie de página↩︎",
    "crumbs": [
      "ESTADÍSTICA DESCRIPTIVA",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Síntesis numérica de datos</span>"
    ]
  },
  {
    "objectID": "11_sintesisNumerica.html#apéndice-1.3-cómo-se-calculan-los-cuartiles",
    "href": "11_sintesisNumerica.html#apéndice-1.3-cómo-se-calculan-los-cuartiles",
    "title": "1  Síntesis numérica de datos",
    "section": "Apéndice 1.3: ¿Cómo se calculan los cuartiles?",
    "text": "Apéndice 1.3: ¿Cómo se calculan los cuartiles?\nAUnque el concepto está claro, existen diferentes criterios para determinar los cuartiles y no todos dan el mismo resultado.\nJohn Tukey, creador de muchas de las modernas técnicas de análisis exploratorio de datos, identifica los cuartiles buscando las medianas de los que quedan por encima y por debajo de la mediana global. Para los datos 2, 4, 6, 8 y 10 (número impar) tenemos:\n\n\n\n\n\nY si los datos son 2, 4, 6, y 8 (número par):\n\n\n\n\n\nDavid Moore y George McCabe en su libro “Introduction to the Practice of Statistics”, muy valorado por su carácter pedagógico e innovador, proponen un método similar al de Tukey pero sin incluir la mediana global en la determinación de las medianas de cada una de las mitades. Cuando el número de datos es par el valor de los cuartiles coincide con el método de Tukey, pero en general no coincide cuando el número de datos es impar.\n\n\n\n\n\nEl paquete de software estadístico Minitab utiliza las expresiones \\(0,25(n+1)\\) y \\(0,75(n+1)\\) para determinar las posiciones de \\(Q_1\\) y \\(Q_3\\) respectivamente. Si la posición obtenida para \\(Q_1\\) es, por ejemplo, 1,25, su valor estará comprendido entre \\(x_1\\) y \\(x_2\\) interpolando de la forma: \\(Q_1 = x_1 + 0,25(x_2-x_1)\\). Utilizando los mismos datos que en los ejemplos anteriores resulta:\n\n    \n    \n    \n  \n        \n            Datos\n            Posición Q1\n            Valor Q1\n            Posición Q3\n            Valor Q3\n        \n        \n        \n    \n        \n            2, 4, 6, 8 (n=4) 2, 4, 6, 8, 10 (n=5)\n            0.25·5=1.25 0.25·6=1.5\n            2+0.25(4-2) = 2.5 2+0.5(4-2) = 3\n            0.75·5=3.75 0.75·6  =4.5\n            6+0.75(8-6) = 7.5 8+0.5(10-8) = 9\n        \n        \n        \n   \n       \n  \n    \n\nExcel dispone de la función CUARTIL que identifica la posición de los cuartiles mediante las expresiones: (0,25(n-1)+1) y (0,75(n-1)+1) y los calcula interpolando igual que hace Minitab. Seguramente no satisfechos con su forma de identificar los cuartiles, en las últimas versiones se ha mantenido esa función (se indica que por compatibilidad con versiones anteriores) y se han añadido:\n\nCUARTIL.INC: Coincide con la función CUARTIL.\nCUARTIL.EXC: Identifica los cuartiles de la misma forma que Minitab.\n\nEn la figura \\(\\ref{Figura020704}\\) se muestran los cuartiles de nuestros datos con las funciones de Excel (versión 2019). –&gt;\n\n\n\n\n\n\nFigura 1.4: Cálculo de los cuartiles con Excel\n\n\n\nEn resumen, los valores obtenidos con los métodos comentados han sido:\n\n\n    \n\n\n\nItem 1\nItem 2\nItem 3\nItem 4\n\n\nItem 5\nItem 6\nItem 7\n\n\n\n\n\n  \n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n=====================================\nFormas de calcular los cuartiles\nhttps://mathworld.wolfram.com/Quartile.html\n\n\n\n\nEl País, 2024. https://elpais.com/economia/negocios/2024-05-04/mi-jefe-cobra-77-veces-mas-que-yo-estas-son-las-empresas-espanolas-con-mayor-desigualdad-salarial-entre-directivos-y-empleados.html.\n\n\nINE. 2023. «Encuesta Anual de Estructura Salarial. Año 2021». Instituto Nacional de EStadística (INE), España. https://www.ine.es/prensa/ees_2021.pdf.",
    "crumbs": [
      "ESTADÍSTICA DESCRIPTIVA",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Síntesis numérica de datos</span>"
    ]
  },
  {
    "objectID": "11_sintesisNumerica.html#los-cuartiles-como-zona",
    "href": "11_sintesisNumerica.html#los-cuartiles-como-zona",
    "title": "1  Síntesis numérica de datos",
    "section": "1.4 Los cuartiles como zona",
    "text": "1.4 Los cuartiles como zona\n\n\n\n\n\n\nNota\n\n\n\nAunque un cuartil es un número y no una zona, a veces se dice que un valor pertenece al primer o al tercer cuartil y lo que eso significa no siempre está claro. Podria pensarse que pertenece al primer cuartil cuando es menor que Q1 y al tercero cuando es mayor que la mediana y menor que Q3, pero no siempre es así. La relevancia de las revistas científicas se mide por su “factor de impacto”, un número relacionado con las citas en otras revistas de los artículos que publican. Para cada ámbito de conocimiento se realizan rankins de revistas según su factor de impacto y todos queremos publicar en las que lo tienen más alto, que no son las del cuarto, seguido por las del tercer cuartil, sino en del primero y el segundo. El ranking se hace de más a menos.\n\n\n\nDeciles. Percentiles\ntexto\ntexto",
    "crumbs": [
      "ESTADÍSTICA DESCRIPTIVA",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Síntesis numérica de datos</span>"
    ]
  },
  {
    "objectID": "11_sintesisNumerica.html#html-td-height-attribute",
    "href": "11_sintesisNumerica.html#html-td-height-attribute",
    "title": "1  Síntesis numérica de datos",
    "section": "2.1 HTML td height Attribute",
    "text": "2.1 HTML td height Attribute\n\n\n\nNAME\nAGE\nBRANCH\n\n\nBITTU\n22\nCSE\n\n\nRAKESH\n25\nEC",
    "crumbs": [
      "ESTADÍSTICA DESCRIPTIVA",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Síntesis numérica de datos</span>"
    ]
  },
  {
    "objectID": "11_sintesisNumerica.html#apéndice-1.3-porcentajes",
    "href": "11_sintesisNumerica.html#apéndice-1.3-porcentajes",
    "title": "1  Síntesis numérica de datos",
    "section": "Apéndice 1.3: Porcentajes",
    "text": "Apéndice 1.3: Porcentajes\nSon de uso habitual para presentar información numérica pero no forman parte del elenco de medidas estadísticas quizá porque parecen simples y no hay mucho que decir sobre ellos. Sin embargo, conviene tenerlos presentes porque se prestan a confusiones y malas interpretaciones.\n\nCálculo del porcentaje\niempre se debe referir al valor inicial. Si el año pasado las naranjas costaban 4 €/kg y este año cuestan 5, su precio ha aumentado un 25%. Si pasan de 5 a 4 habrán disminuido un 20%. o hay simetría al aumentar y disminuir.\n\n\nOperaciones con procentajes\nLas operaciones con porcentajes no son triviales. Hacer un 50% de descuento y después otro 20% no es lo mismo que hacer el 70%. Si el valor inicial era 100€, en el primer caso queda en 40 € mientras que el segundo el valor final es de 30 €. Si el IVA es del 21%, vender sin IVA no es hacer un 21% de descuento. A veces se dan situaciones paradójicas: si usted está vendiendo al mismo precio que la competencia puede hacer un 33% de descuento y decir que la competencia está vendiendo un 50% más caro.\nLos problemas con porcentajes pueden pareer triviales y no serlo. Uno de los más famosos es la llamada “paradoja de las patatas”: Supongamos que tenemos 100 kg de patatas cuyo peso está compuesto por agua en un 99%. Con el paso del tiempo las patatas pierden humedad ¿Cuanto pesarán cuando el porcentaje de humedad sea del 98%? En la Wikipedia puede ver si si sus calculos són correctos.\n\n\nPorcentajes y puntos porcentuales\nSi los beneficios han pasado del 2 al 4% no han aumentado un 2% sino el 100% (suponiendo que la base sobre la que se calculan se haya mantenido constante). También podemos decir que han aumentado 2 puntos porcentuales. Es necesario cuidar el lenguaje y no confundir una cosa con otra.\nCuriosidad: Si los beneficios se han multiplicado por 5 no han aumentado un 500% sino un 400%. En efecto, si se doblan han aumentado un 100%, si se triplican habrán aumentado un 200%, y así sucesivamente.\n\n\nPorcentajes basados en niveles y en cambios de nivel\nUn vendedor vendió el año pasado por valor de 10 millones de euros. Su objetivo para este año era aumentar su factruración un 6%, es decir, vender por valor de 10,6 millones. El vendedor solo ha logrado vender por valor de 10,3 millones, ¿qué porcentaje de objetivo ha logrado? Si el objetivo era el incremento, se ha quedado en la mitad y por tanto solo ha conseguido el 50%, pero si era vender 10,6 millones y ha vendido 10,3 se ha quedado en el 97,2%. En general, los objetivos siempre son sobre el incremento, no sobre el valor absoluto, y esto debe quedar claro.\n\n\nNo olvidar los valores a partir de los cuales se calculan los porcentajes\nSi se realiza un estudio y resulta que 66,7% de los consumidores prefiere el producto X puede ser que se haya consultado a 3 y lo prefieran 2 o que se haya entrevistado a 3.000 y lo hayan preferido 2.000. La información que da ese porcentaje no es la misma en un caso y en otro.\nEl porcetaje global para un colectivo formado por varios grupos puede sugerir unas conclusiones que no se dan en ningno de los grupos, es lo que se conoce como “Paradoja de Simpson”: Una empresa crea 250 nuevos puestos de trabajo en sus departamentos de compras, fabricación y ventas. En total se presentan 355 hombres y 325 mujeres de los cuales son admitidos 190 hombres (el 53,5%) y solo 60 mujeres (el 18,5%). Se comprueba que el nivel de preparación de hombres y mujeres es similar entre los aspirantes a cada departamento. ¿Podemos asegurar que se ha discriminado a las mujeres? La respuesta es no. Los datos son los siguientes:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDepartamento\nPlazas\nAspirantes - Admitidos\nHombres               Mujeres\n% Admitidos\nHombres               Mujeres\n\n\nCompras\nFabricación\nVentas\n\n30\n200\n20\n25 - 5\n250 - 180\n80 - 5\n100 - 25\n25 - 20\n200 - 15\n20 %\n72 %\n6,25 %\n25 %\n80 %\n7,5 %\n\n\nTOTAL\n250\n355 - 190\n325 - 60\n53,5 %\n18,5 %\n\n\n\n\n \nEn realidad han sido las mujeres las que han tenido mayor proporción de admitidos en los tres departamentos. La clave está en que al departamento que ofrece más plazas se han presentado muchos hombres y pocas mujeres, mientras que ocurre lo contrario en los departamentos en que se ofrecen menos plazas.\n\n\nPorcentaje ¿de qué?\nAnte un porcentaje siempre conviene preguntarse qué significa y cómo se han medido los valores con los que se ha calculado. Ya sabemos que en el mundo de la publidad esas preguntas no suelen tener respuesta: si una crema reduce las arrugas un 33% no está claro si elimina una de cada tres o si reduce un tercio la profundidad de todas ellas. El problema es que estas ambiguedades se presentan también en otros ámbitos, quizá también en los porcentajes que nosotros manejamos. Es necesario que esté claro a qué nos estamos refiriendo.\n\n\n\n\nEl País, 2024. https://elpais.com/economia/negocios/2024-05-04/mi-jefe-cobra-77-veces-mas-que-yo-estas-son-las-empresas-espanolas-con-mayor-desigualdad-salarial-entre-directivos-y-empleados.html.\n\n\nINE. 2023. «Encuesta Anual de Estructura Salarial. Año 2021». Instituto Nacional de EStadística (INE), España. https://www.ine.es/prensa/ees_2021.pdf.",
    "crumbs": [
      "ESTADÍSTICA DESCRIPTIVA",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Síntesis numérica de datos</span>"
    ]
  },
  {
    "objectID": "12_graficos.html#valor-central-dispersión-y-forma-de-la-distribución.",
    "href": "12_graficos.html#valor-central-dispersión-y-forma-de-la-distribución.",
    "title": "2  Representaciones gráficas",
    "section": "",
    "text": "2.1.1 Histograma\nNúmero de intervalos\nNúmeros redondos, al marcar los ejes y en la anchura de los intervalos\nSi hay valro objetivo y límites es una buena idea ponerlos.\n\n\n2.1.2 Diagrama de puntos\ntexto\n\n\n2.1.3 Boxplot\ntexto",
    "crumbs": [
      "ESTADÍSTICA DESCRIPTIVA",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Representaciones gráficas</span>"
    ]
  },
  {
    "objectID": "12_graficos.html#evolución",
    "href": "12_graficos.html#evolución",
    "title": "2  Representaciones gráficas",
    "section": "2.2 Evolución",
    "text": "2.2 Evolución\ntexto\n\n2.2.1 Diagrama en serie de tiempo\nEvolución de la esperanza de vida en los países donde tienen más y donede tienen menos.\n\n\n\n\n\n\nFigura 2.3: Esquema de obtención de la mediana y los cuartiles en un conjunto de 30 datos\n\n\n\nAsia: Afganistan, Japón. Menor de áfrica y otro con EV muy alta.\nTambién hay buenos datos en web de comunidd de Madrid: Indicadores de nacimientos.\n Que los nombres salgan por orden alfabético.",
    "crumbs": [
      "ESTADÍSTICA DESCRIPTIVA",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Representaciones gráficas</span>"
    ]
  },
  {
    "objectID": "12_graficos.html#relación-entre-dos-variables",
    "href": "12_graficos.html#relación-entre-dos-variables",
    "title": "2  Representaciones gráficas",
    "section": "2.3 Relación entre dos variables",
    "text": "2.3 Relación entre dos variables\ntexto\n\n2.3.1 Las dos son cuantitativas: Diagramas bivariantes\ntexto\n\n\n2.3.2 Una es cuantitatica y la otra cualitativa: Boxplots estratificados\ntexto",
    "crumbs": [
      "ESTADÍSTICA DESCRIPTIVA",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Representaciones gráficas</span>"
    ]
  },
  {
    "objectID": "12_graficos.html#frecuencias",
    "href": "12_graficos.html#frecuencias",
    "title": "2  Representaciones gráficas",
    "section": "2.4 Frecuencias",
    "text": "2.4 Frecuencias\ntexto\n\n\n\n\n\n\nFigura 2.4: Esquema de obtención de la mediana y los cuartiles en un conjunto de 30 datos\n\n\n\ntexto\n\n2.4.1 Diagramas de barras\ntexto\n\n\n2.4.2 Gráficos de donut\ntexto en la figura 2.12. Recortar arriba y abajo con programa de manipulación de imágenes.\n\n\n\n\n\n\nFigura 2.5: Diagrama de donut y de pastel\n\n\n\nInformación más clara y mejor uso de la tinta.\n\n\n\n\n\n\nFigura 2.6: Esquema de obtención de la mediana y los cuartiles en un conjunto de 30 datos\n\n\n\nEn el recuadro se incluyen 90 países, casi la mitad del total de paises considerados (196), pero solo representa el ***% de la poblaicón mundial.\nPosible polígono de frecuencias y diagrama de Pareto.",
    "crumbs": [
      "ESTADÍSTICA DESCRIPTIVA",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Representaciones gráficas</span>"
    ]
  },
  {
    "objectID": "12_graficos.html#relación-entre-variables",
    "href": "12_graficos.html#relación-entre-variables",
    "title": "2  Representaciones gráficas",
    "section": "2.3 Relación entre variables",
    "text": "2.3 Relación entre variables\ntexto\n\n2.3.1 Las dos son cuantitativas: Diagramas bivariantes\ntexto\nV \ntexto\n Reflexión sobre esperanza de vida y ratios de mortalidad infantil.\nLa esperanza de vida está más relacionada con la mortalidad infantil que con alargar la vida de los ancianos.\nUna es cuantitatica y la otra cualitativa: ejemplo de Boxplots estratificados del principio.",
    "crumbs": [
      "ESTADÍSTICA DESCRIPTIVA",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Representaciones gráficas</span>"
    ]
  },
  {
    "objectID": "12_graficos.html#gráficos-a-evitar",
    "href": "12_graficos.html#gráficos-a-evitar",
    "title": "2  Representaciones gráficas",
    "section": "2.5 Gráficos a evitar",
    "text": "2.5 Gráficos a evitar\nveamos algunas tentaciones que conviene evitar, especialmente en trabajos académicos donde el objetivo debe ser transmitir la información de la forma más clara y directa posible.\n\nGráficos con tres dimensiones\nDeben evitarse porque la profundidad no aporta ninguna información y dificulta la interpretación de las escalas. Algunas veces se utilizan en contextos publicitarios en los que se prioriza el impacto visual.\n\n\n\n\n\n\nFigura 2.7: Tres dimensiones\n\n\n\n\n\nDiagramas de pastel, especialmente con tres dimensiones\nEstos diagramas no son muy aprecidos en contextos científico-técnicos donde -en general- se prefieren los diagramas de barras. Si se representan en tres dimensiones y desgajando un sector que se quiere destacar ya entramos en el terreno de los gráficos tendenciosos. Un gráfico similar que transmite la información de forma más clara son los diagramas de donut.\n===Comentar que en el gráfico 3d no es lo que parece===\n\n\n\n\n\n\nFigura 2.8: Tres dimensiones\n\n\n\n\n\nGráficos que ocupan mucho espacio y contienen poca información\nUtilizamos los gráficos para resumir de forma visual la información que contienen los datos. Construir un gráfico para representar un solo dato no parece -en general- una buena . Así pues, contruir -por ejemplo- un gran diagrama de pastel para decir que la proporción de mujeres en un determinado ámbito es del 53% no parece una buena idea. Es más grave si en un informe o en una presentación oral se van presentando este tipo de gráficos de forma repetitiva. ===no caeremos en nuestra propia trampa poniendo un ejemplo===\n\n\nGráficos con escalas inapropiadas\nUno de los recursos más utilizados para que el gráfico dé la impresión que interesa es adaptar la escala vertical para exagerar o disimular las diferencias, según convenga. La figura +++++ prodría representar las medidas de audiencia de cuatro cadenas de televisión, en el gráfico de la izquierda se observan unas diferencias muy claras y TV1 parece tener la mitad de la audiencia que TV4 sin embargo, si la escala parte de cero -que es lo correcto cuando se hacen comparaciones- apenas se aprecian esad diferencias.\n\n\n\n\n\n\nFigura 2.9: Diagrama de donut y de pastel\n\n\n\nNo hay que dejarse engañar con añadidos como el de la figura ++++\n\n\n\n\n\n\nFigura 2.10: Diagrama de donut y de pastel\n\n\n\nYa sabemos que si el eje horizontal representa el tiempo es mejor utilizar gráficos de líneas y estos son también muy sensibles a la escala vertical. Los dos gráficos de la figura ++++ representan los mismos datos:\n\n\n\n\n\n\nFigura 2.11: Diagrama de donut y de pastel\n\n\n\ntexto\nUna buena opción\n\n\n\n\n\n\nFigura 2.12: Diagrama de donut y de pastel\n\n\n\n\n\n2.5.1 Comparar situaciones usando distintas escalas\ntexto\n\n\n2.5.2 Rectas de tendencia cuando los puntos están muy agrupados en una parte del diagrama\ntexto",
    "crumbs": [
      "ESTADÍSTICA DESCRIPTIVA",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Representaciones gráficas</span>"
    ]
  },
  {
    "objectID": "12_graficos.html#malos-usos-y-manipulaciones",
    "href": "12_graficos.html#malos-usos-y-manipulaciones",
    "title": "2  Representaciones gráficas",
    "section": "2.6 Malos usos y manipulaciones",
    "text": "2.6 Malos usos y manipulaciones\ntexto\n\n\n\n\n\n\nOjo con ir a la búsqueda del gazapo\n\n\n\npuede ser muy instructivo buscar ejemplos de gráficos que por falta de habilidad o por mala fe transmiten una información falsa, pero tampoco hay que transmitir la idea de que todo el mundo nos quiere engañar. En la prensa seria la mayoría de los gráficos -que pueden ser más o menos afortunados- se hacen de buena fe, con el ánimo de informar con",
    "crumbs": [
      "ESTADÍSTICA DESCRIPTIVA",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Representaciones gráficas</span>"
    ]
  },
  {
    "objectID": "12_graficos.html#forma-de-la-distribución-valro-central-y-dispersión",
    "href": "12_graficos.html#forma-de-la-distribución-valro-central-y-dispersión",
    "title": "2  Representaciones gráficas",
    "section": "",
    "text": "2.1.1 Histograma\nNúmero de intervalos\nNúmeros redondos, al marcar los ejes y en la anchura de los intervalos\nSi hay valro objetivo y límites es una buena idea ponerlos.\nNo hay que esperar que cuando proviene de una distribución normal tengan formade campana\n\n\n2.1.2 Diagrama de puntos\ntexto\n\n\n2.1.3 Boxplot\ntexto\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOrden\nValores\n1\n5\n2\n7\n3\n7\n4\n9\n5\n9\n6\n9\n7\n9\n8\n9\n9\n9\n10\n9\n11\n10\n12\n11\n13\n11\n14\n11\n15\n11\n16\n11\n17\n14\n18\n15\n19\n16\n20\n18\n\n\n\n\ntexto deduciendo los valores de la mediana y los cuartiles. Podría poner antes el rango intercuartílico.\n\n\n\n\n\n\nFigura 2.1: Esquema de obtención de la mediana y los cuartiles en un conjunto de 30 datos\n\n\n\ntexto\n\n\n\nHola\n\n\n\n\n\n\n\n\nFigura 2.2: Esquema de obtención de la mediana y los cuartiles en un conjunto de 30 datos\n\n\n\ntexto\ntexto",
    "crumbs": [
      "ESTADÍSTICA DESCRIPTIVA",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Representaciones gráficas</span>"
    ]
  }
]